{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e493825",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b423f1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Incremental Training with Different Learning Rates and Layer-Freezing\n",
    "\n",
    "This notebook is created using the latest stable [merlin-tensorflow](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags) container. \n",
    "\n",
    "In this example, we fine-tune a model by setting different learning rates to different layers and freezing embedding tables. Incremental training of a model is a common practice allows models to continuously learn and extend the existing model's knowledge by adjusting model parameters that has been learned previously using new examples. Another scenario to do incremental training is to resume a training job that was stopped. Here, we first showcase how to incrementally train the same model architecture with different hyperparameter settings (adjusting the learning rates) and using different datasets. Then, in a new scenario, we showcase how one can freeze certain layers of the model such as pretrained embedding layers and perform training.\n",
    "\n",
    "**Learning objectives**\n",
    "- Training a model with multiple learning rates\n",
    "- Fine-tune a model by freezing embedding tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381c615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2022-10-20 20:26:21.720796: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-20 20:26:24.477686: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-10-20 20:26:24.477886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8080 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:0a:00.0, compute capability: 7.0\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "from merlin.datasets.synthetic import generate_data\n",
    "import merlin.models.tf as mm\n",
    "from merlin.schema import Schema, Tags\n",
    "from merlin.io.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7339a9e-6efa-48f5-ab59-54f98d9394c8",
   "metadata": {},
   "source": [
    "## Building a Two-Tower Model with Merlin Models\n",
    "\n",
    "We choose Two-Tower model architecture for this example. To learn more about a Two-Tower model you can visit this [notebook](https://github.com/NVIDIA-Merlin/models/blob/main/examples/05-Retrieval-Model.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a197d69",
   "metadata": {},
   "source": [
    "### Generate Synthetic Dataset\n",
    "\n",
    "Let's create three datasets. To generate the synthetic dataset for our example, we can use `generate_data()` function. We can assume that each dataset here was collected at a different day. Therefore, below we show how we can do incremental training with Merlin Models. We generate three datasets synthetically and we name them as `day_1, day_2, day_3` for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e08919-08d9-401c-ad9c-476890d616b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NUM_ROWS = 10000\n",
    "day_1, day_2, day_3 = generate_data(\"e-commerce-large\", int(NUM_ROWS), set_sizes=(0.33, 0.33, 0.34))\n",
    "schema = day_1.schema.without(['click', 'conversion'])\n",
    "day_1.schema = schema\n",
    "day_2.schema = schema\n",
    "day_3.schema = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912649bd-1388-4fac-9830-941b624d8e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_categories</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_shops</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>116741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_brands</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>58015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_intentions</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>33786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_profile</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user_group</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_gender</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>user_age</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>user_consumption_1</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user_consumption_2</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>user_is_occupied</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_geography</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user_id</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL, Tags.USER_ID, Ta...</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>294736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>item_category</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>8581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>item_shop</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>604498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>item_intention</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>96258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>item_brand</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>208179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>item_id</td>\n",
       "      <td>(Tags.ITEM, Tags.ITEM_ID, Tags.CATEGORICAL, Ta...</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3078306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>user_item_categories</td>\n",
       "      <td>(user_item, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>7735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>user_item_shops</td>\n",
       "      <td>(user_item, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>384343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>user_item_brands</td>\n",
       "      <td>(user_item, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>142632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>user_item_intentions</td>\n",
       "      <td>(user_item, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>74317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>position</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.CONTEXT)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'user_categories', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 6086}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_shops', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 116741}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_brands', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 58015}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_intentions', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 33786}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_profile', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 98}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_group', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 14}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_gender', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 3}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_age', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 8}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_consumption_1', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 4}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_consumption_2', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 4}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_is_occupied', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 3}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_geography', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 5}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_id', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.USER_ID: 'user_id'>, <Tags.ID: 'id'>}, 'properties': {'domain': {'min': 0, 'max': 294736}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_category', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 8581}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_shop', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 604498}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_intention', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 96258}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_brand', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 208179}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_id', 'tags': {<Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ID: 'id'>}, 'properties': {'domain': {'min': 0, 'max': 3078306}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_item_categories', 'tags': {'user_item', <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 7735}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_item_shops', 'tags': {'user_item', <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 384343}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_item_brands', 'tags': {'user_item', <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 142632}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_item_intentions', 'tags': {'user_item', <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 74317}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'position', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.CONTEXT: 'context'>}, 'properties': {'domain': {'min': 0, 'max': 4}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_1.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d2952-5737-40a2-917e-1e7b865f2b83",
   "metadata": {},
   "source": [
    "### Iteration 1: Using Different Learning Rates\n",
    "At first, we train the model on the first day's data and evaluate it on the second day's data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147d9115-5e58-4527-ae14-c96ccdd5635d",
   "metadata": {},
   "source": [
    "Define the embeddings for features in the item and query towers using `Embedddings` class. By setting `infer_embedding_sizes` to True, we can automatically define the embedding dimension from the feature cardinality in the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a87040-d3fe-41cd-a111-803b2a532e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings = mm.Embeddings(schema.select_by_tag(Tags.ITEM), infer_embedding_sizes=True)\n",
    "query_embeddings = mm.Embeddings(schema.select_by_tag(Tags.USER), infer_embedding_sizes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c80e3-847d-4af9-b370-3f87213972c7",
   "metadata": {},
   "source": [
    "Build the Two-Tower model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43af3239-f332-4cd6-bd3d-fd0d2a1a2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mm.TwoTowerModel(schema, \n",
    "                         query_tower=mm.InputBlockV2(schema.select_by_tag(Tags.USER), categorical=query_embeddings).connect(mm.MLPBlock([128, 64])), \n",
    "                         item_tower=mm.InputBlockV2(schema.select_by_tag(Tags.ITEM), categorical=item_embeddings).connect(mm.MLPBlock([128, 64])),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82d988-82cd-48a8-8703-da99a0f257cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training the model with first day's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791e06ec-c0cb-4c0f-9e41-7e5c8fa1dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7faf75b91a60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7faf75b91a60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 17s 113ms/step - loss: 6.8098 - recall_at_10: 0.0211 - mrr_at_10: 0.0186 - ndcg_at_10: 0.0192 - map_at_10: 0.0186 - precision_at_10: 0.0021 - regularization_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faad6c11fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "model.fit(day_1, batch_size=1024, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59174a-c32c-4808-aa75-14695d5d8c2b",
   "metadata": {},
   "source": [
    "**Evaluate the data using day_2 dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149c864-b745-4382-81f1-f1f80954873d",
   "metadata": {},
   "source": [
    "Training model on a certain period of time, and then evaluating on a dataset which is closer to the test set time period make sense and is a common practice. However, please note that in this example the data is randomly seperated, thus we dont really expect a temporal sequence in day_1, day_2, and day_3. Therefore the evaluation metrics might not \"make sense\", since this is a hypotetical example to showcase the functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e88f906-3174-4be3-a77d-e84ac8ff089d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 12ms/step - loss: 6.8096 - recall_at_10: 0.0245 - mrr_at_10: 0.0217 - ndcg_at_10: 0.0223 - map_at_10: 0.0217 - precision_at_10: 0.0024 - regularization_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 6.809643268585205,\n",
       " 'recall_at_10': 0.025151515379548073,\n",
       " 'mrr_at_10': 0.021524891257286072,\n",
       " 'ndcg_at_10': 0.022327682003378868,\n",
       " 'map_at_10': 0.021524891257286072,\n",
       " 'precision_at_10': 0.0025151518639177084,\n",
       " 'regularization_loss': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics = model.evaluate(day_2, batch_size=1024, return_dict=True)\n",
    "eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c222dcb6-3e69-4283-ad80-5e7395b3fe78",
   "metadata": {},
   "source": [
    "#### Training the model with second day's data \n",
    "\n",
    "Now we continue to train the model on the second day's data but using different strategies. We can use different learning rate for different layers of the model, i.e. a smaller learning rate for embedding tables while a bigger learning rate for two towers. If we want small updates to the weights of embedding tables, we can set the small learning rate value. Here we choose `0.001` as the learning rate for embedding tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d50639a-515c-44f1-b9b6-13fdb68ef669",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = mm.MultiOptimizer(\n",
    "            default_optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "            optimizers_and_blocks=[mm.OptimizerBlocks(tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                                                      [item_embeddings, query_embeddings])]\n",
    ")                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d738c20c-29a8-43fc-8af7-4616467026a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 8s 315ms/step - loss: 6.8098 - recall_at_10: 0.0250 - mrr_at_10: 0.0211 - ndcg_at_10: 0.0219 - map_at_10: 0.0211 - precision_at_10: 0.0025 - regularization_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faad4db85b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer)\n",
    "model.fit(day_2, batch_size=1024, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923636d-0189-460c-a55c-3c42b7aed8c5",
   "metadata": {},
   "source": [
    "**Evaluate on the third day's data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd42c5a1-8021-477f-ab82-1158e18f670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 12ms/step - loss: 6.8036 - recall_at_10: 0.0290 - mrr_at_10: 0.0246 - ndcg_at_10: 0.0256 - map_at_10: 0.0246 - precision_at_10: 0.0029 - regularization_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = model.evaluate(day_3, batch_size=1024,  return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a5c8634-8e51-44b7-8f5d-9d01fc08d72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 6.803572654724121,\n",
       " 'recall_at_10': 0.028823530301451683,\n",
       " 'mrr_at_10': 0.022923553362488747,\n",
       " 'ndcg_at_10': 0.024233652278780937,\n",
       " 'map_at_10': 0.022923553362488747,\n",
       " 'precision_at_10': 0.002882353262975812,\n",
       " 'regularization_loss': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c589a4e-7654-46a6-84cb-1e012cc7852c",
   "metadata": {},
   "source": [
    "### Iteration 2: Training with Freezing Layers\n",
    "\n",
    "\"Let's consider a new situation. Suppose we have trained the model on all previous data and achieved a good performance. Now there is incoming new data, but we do not want to change the pretrained embedding tables and only want to train the top MLP layers. We can use `model.freeze_blocks()`. When we call `freeze_blocks`, what do we actually do? Each layer maintains a variable called `trainable`. When a layer is created, this variable is set. The default value is `True`, which means all the weights in this layer can be updated. If you change `trainable` into `False`, the weights would not be changed anymore, unless its `trainable` variable becomes `True` again. So when `freeze_blocks` is called, the `trainable` of the layer is set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6994177d-60fb-4657-80f6-4f40b2d1dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_blocks([item_embeddings, query_embeddings])\n",
    "\n",
    "# recompile your model after making any changes\n",
    "# to the `trainable` attribute of any inner layer, so that your changes\n",
    "# are taken into account\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c8e62f5-842e-4caa-85ac-5fa4ec418c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 22ms/step - loss: 6.7985 - recall_at_10: 0.0319 - mrr_at_10: 0.0265 - ndcg_at_10: 0.0277 - map_at_10: 0.0265 - precision_at_10: 0.0032 - regularization_loss: 0.0000e+00\n",
      "Model: \"retrieval_model\"\n",
      "___________________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                    Param #     Trainable  \n",
      "===========================================================================================\n",
      " two_tower_block (TwoTowerBlock)    multiple                        340774200   Y          \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| tower_block (TowerBlock)         multiple                        21941120    Y          |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| sequential_block_3 (SequentialBloc  multiple                   21941120    Y          ||\n",
      "|| k)                                                                                    ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| parallel_block (ParallelBlock)  multiple                     21902016    Y          |||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||| embeddings (ParallelBlock)  multiple                       21902016    N          ||||\n",
      "|||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||||\n",
      "||||| user_categories (EmbeddingTable)  multiple               146088      N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_shops (EmbeddingTable)  multiple                    4669680     N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_brands (EmbeddingTable)  multiple                   1856512     N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_intentions (EmbeddingTable)  multiple               1081184     N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_profile (EmbeddingTable)  multiple                  792         N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_group (EmbeddingTable)  multiple                    120         N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_gender (EmbeddingTable)  multiple                   32          N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_age (EmbeddingTable)  multiple                      72          N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_consumption_1 (EmbeddingTable  multiple             40          N          |||||\n",
      "||||| )                                                                               |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_consumption_2 (EmbeddingTable  multiple             40          N          |||||\n",
      "||||| )                                                                               |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_is_occupied (EmbeddingTable)  multiple              32          N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_geography (EmbeddingTable)  multiple                48          N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_id (EmbeddingTable)  multiple                       14147376    N          |||||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| sequential_block_2 (SequentialBloc  multiple                 39104       Y          |||\n",
      "||| k)                                                                                  |||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||| private__dense_3 (_Dense)  multiple                        30848       Y          ||||\n",
      "||||                                                                                   ||||\n",
      "|||| private__dense_4 (_Dense)  multiple                        8256        Y          ||||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| model_context (ModelContext)   multiple                        0           N          ||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| tower_block_1 (TowerBlock)       multiple                        318833080   Y          |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| sequential_block_5 (SequentialBloc  multiple                   318833080   Y          ||\n",
      "|| k)                                                                                    ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| parallel_block_1 (ParallelBlock)  multiple                   318791928   Y          |||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||| embeddings (ParallelBlock)  multiple                       318791928   N          ||||\n",
      "|||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||||\n",
      "||||| item_category (EmbeddingTable)  multiple                 205968      N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| item_shop (EmbeddingTable)  multiple                     33851944    N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| item_intention (EmbeddingTable)  multiple                3850360     N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| item_brand (EmbeddingTable)  multiple                    9992640     N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| item_id (EmbeddingTable)  multiple                       270891016   N          |||||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| sequential_block_4 (SequentialBloc  multiple                 41152       Y          |||\n",
      "||| k)                                                                                  |||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||| private__dense_5 (_Dense)  multiple                        32896       Y          ||||\n",
      "||||                                                                                   ||||\n",
      "|||| private__dense_6 (_Dense)  multiple                        8256        Y          ||||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| model_context (ModelContext)   multiple                        0           N          ||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " item_retrieval_task (ItemRetrieval  multiple                       0           Y          \n",
      " Task)                                                                                     \n",
      "                                                                                           \n",
      " model_context (ModelContext)       multiple                        0           N          \n",
      "                                                                                           \n",
      "===========================================================================================\n",
      "Total params: 340,774,201\n",
      "Trainable params: 80,256\n",
      "Non-trainable params: 340,693,945\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(day_1, batch_size=1024, epochs=1)\n",
    "model.summary(expand_nested=True, show_trainable=True, line_length=80)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2dcd41-31f7-4c09-b120-3b58900f76d4",
   "metadata": {},
   "source": [
    "When we call `freeze_blocks` on some layers, all these layers and their children layers become non-trainable. For example, if a `ParallelBlock` is frozen, the children blocks inside this `ParallelBlock` are also frozen. As shown in below summary result, we freeze the `user_embeddings`, and it is a `ParallelBlock`, all the children layers are frozen as well.\n",
    "\n",
    "```\n",
    "|||||| embeddings (ParallelBlock)  multiple                   21902016    N          ||||||\n",
    "|||||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||||||\n",
    "||||||| user_categories (EmbeddingTable)  multiple           146088      N          |||||||\n",
    "|||||||                                                                             |||||||\n",
    "||||||| user_shops (EmbeddingTable)  multiple                4669680     N          |||||||\n",
    "|||||||                                                                             |||||||\n",
    "||||||| user_brands (EmbeddingTable)  multiple               1856512     N          |||||||\n",
    "|||||||                                                                             |||||||\n",
    "||||||| user_intentions (EmbeddingTable)  multiple           1081184     N          |||||||\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea5782-c88f-4a34-990f-9074bb387d63",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d3d88-979e-4587-a74a-bcf61db36b84",
   "metadata": {},
   "source": [
    "In this example notebook we learned how to use different learning rates for different layers in our model architecture, and how to freeze embedding layers, so that we do not update their parameters during training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c78a7de67f1468ee33d22a76790123f2989400fa0e73ac6b45f15b09432f615d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
