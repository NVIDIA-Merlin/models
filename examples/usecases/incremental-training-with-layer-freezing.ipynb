{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e493825",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b423f1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://developer.download.nvidia.com//notebooks/dlsw-notebooks/merlin_models_incremental-training-with-layer-freezing/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Incremental Training with Different Learning Rates and Layer Freezing\n",
    "\n",
    "This notebook is created using the latest stable [merlin-tensorflow](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags) container. \n",
    "\n",
    "In this example, we fine-tune a model by setting different learning rates to different layers and freezing embedding tables. Incremental training of a model is a common practice allows models to continuously learn and extend the existing model's knowledge by adjusting model parameters that has been learned previously using new examples. Another scenario to do incremental training is to resume a training job that was stopped. Here, we first showcase how to incrementally train the same model architecture with different hyperparameter settings (adjusting the learning rates) and using different datasets. Then, in a new scenario, we showcase how one can freeze certain layers of the model such as pretrained embedding layers and perform training.\n",
    "\n",
    "**Learning objectives**\n",
    "- Training a model with multiple learning rates\n",
    "- Fine-tune a model by freezing embedding tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381c615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:19:26.844088: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:19:30.718269: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-11 15:19:32.610890: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-01-11 15:19:32.610991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16254 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from merlin.datasets.synthetic import generate_data\n",
    "import merlin.models.tf as mm\n",
    "from merlin.schema import Schema, Tags\n",
    "from merlin.io.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7339a9e-6efa-48f5-ab59-54f98d9394c8",
   "metadata": {},
   "source": [
    "## Building a Two-Tower Model with Merlin Models\n",
    "\n",
    "We choose Two-Tower model architecture for this example. To learn more about a Two-Tower model you can visit this [notebook](https://github.com/NVIDIA-Merlin/models/blob/main/examples/05-Retrieval-Model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a197d69",
   "metadata": {},
   "source": [
    "### Generate Synthetic Dataset\n",
    "\n",
    "Let's create three datasets. To generate the synthetic dataset for our example, we can use `generate_data()` function. We can assume that each dataset here was collected at a different day. Therefore, below we show how we can do incremental training with Merlin Models. We generate three datasets synthetically and we name them as `day_1, day_2, day_3` for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e08919-08d9-401c-ad9c-476890d616b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NUM_ROWS = int(os.environ.get(\"NUM_ROWS\", '10000'))\n",
    "day_1, day_2, day_3 = generate_data(\"e-commerce\", int(NUM_ROWS), set_sizes=(0.33, 0.33, 0.34))\n",
    "schema = day_1.schema.without(['click', 'conversion'])\n",
    "day_1.schema = schema\n",
    "day_2.schema = schema\n",
    "day_3.schema = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912649bd-1388-4fac-9830-941b624d8e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_categories</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>user_categories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_shops</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>user_shops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_brands</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>user_brands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_intentions</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>user_intentions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_profile</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>user_profile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user_group</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>user_group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_gender</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>user_gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>user_age</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>user_age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>user_consumption_1</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>user_consumption_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user_consumption_2</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>user_consumption_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>user_is_occupied</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>user_is_occupied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_geography</td>\n",
       "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>user_geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user_id</td>\n",
       "      <td>(Tags.USER_ID, Tags.USER, Tags.CATEGORICAL, Ta...</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>user_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>item_category</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>item_category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>item_shop</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>item_shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>item_intention</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>item_intention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>item_brand</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>item_brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>item_id</td>\n",
       "      <td>(Tags.ID, Tags.CATEGORICAL, Tags.ITEM, Tags.IT...</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>item_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>user_item_categories</td>\n",
       "      <td>(Tags.CATEGORICAL, user_item)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>user_item_categories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>user_item_shops</td>\n",
       "      <td>(Tags.CATEGORICAL, user_item)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>user_item_shops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>user_item_brands</td>\n",
       "      <td>(Tags.CATEGORICAL, user_item)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>user_item_brands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>user_item_intentions</td>\n",
       "      <td>(Tags.CATEGORICAL, user_item)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>user_item_intentions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>position</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.CONTEXT)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>position</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'user_categories', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 300, 'name': 'user_categories'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_shops', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 500, 'name': 'user_shops'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_brands', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 250, 'name': 'user_brands'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_intentions', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 50, 'name': 'user_intentions'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_profile', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 20, 'name': 'user_profile'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_group', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 14, 'name': 'user_group'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_gender', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 3, 'name': 'user_gender'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_age', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 8, 'name': 'user_age'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_consumption_1', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 4, 'name': 'user_consumption_1'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_consumption_2', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 4, 'name': 'user_consumption_2'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_is_occupied', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 3, 'name': 'user_is_occupied'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_geography', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'domain': {'min': 0, 'max': 5, 'name': 'user_geography'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_id', 'tags': {<Tags.USER_ID: 'user_id'>, <Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ID: 'id'>}, 'properties': {'domain': {'min': 0, 'max': 1000, 'name': 'user_id'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_category', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>}, 'properties': {'domain': {'min': 0, 'max': 100, 'name': 'item_category'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_shop', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>}, 'properties': {'domain': {'min': 0, 'max': 500, 'name': 'item_shop'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_intention', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>}, 'properties': {'domain': {'min': 0, 'max': 25, 'name': 'item_intention'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_brand', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>}, 'properties': {'domain': {'min': 0, 'max': 250, 'name': 'item_brand'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_id', 'tags': {<Tags.ID: 'id'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>}, 'properties': {'domain': {'min': 0, 'max': 1000, 'name': 'item_id'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_item_categories', 'tags': {<Tags.CATEGORICAL: 'categorical'>, 'user_item'}, 'properties': {'domain': {'min': 0, 'max': 300, 'name': 'user_item_categories'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_item_shops', 'tags': {<Tags.CATEGORICAL: 'categorical'>, 'user_item'}, 'properties': {'domain': {'min': 0, 'max': 500, 'name': 'user_item_shops'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_item_brands', 'tags': {<Tags.CATEGORICAL: 'categorical'>, 'user_item'}, 'properties': {'domain': {'min': 0, 'max': 250, 'name': 'user_item_brands'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'user_item_intentions', 'tags': {<Tags.CATEGORICAL: 'categorical'>, 'user_item'}, 'properties': {'domain': {'min': 0, 'max': 25, 'name': 'user_item_intentions'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'position', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.CONTEXT: 'context'>}, 'properties': {'domain': {'min': 0, 'max': 4, 'name': 'position'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_1.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d2952-5737-40a2-917e-1e7b865f2b83",
   "metadata": {},
   "source": [
    "### Iteration 1: Using Different Learning Rates\n",
    "At first, we train the model on the first day's data and evaluate it on the second day's data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147d9115-5e58-4527-ae14-c96ccdd5635d",
   "metadata": {},
   "source": [
    "Define the embeddings for features in the item and query towers using `Embedddings` class. By setting `infer_embedding_sizes` to True, we can automatically define the embedding dimension from the feature cardinality in the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a87040-d3fe-41cd-a111-803b2a532e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings = mm.Embeddings(schema.select_by_tag(Tags.ITEM), infer_embedding_sizes=True)\n",
    "query_embeddings = mm.Embeddings(schema.select_by_tag(Tags.USER), infer_embedding_sizes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c80e3-847d-4af9-b370-3f87213972c7",
   "metadata": {},
   "source": [
    "Build the Two-Tower model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43af3239-f332-4cd6-bd3d-fd0d2a1a2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mm.TwoTowerModel(schema, \n",
    "                         query_tower=mm.InputBlockV2(schema.select_by_tag(Tags.USER), categorical=query_embeddings).connect(mm.MLPBlock([128, 64])), \n",
    "                         item_tower=mm.InputBlockV2(schema.select_by_tag(Tags.ITEM), categorical=item_embeddings).connect(mm.MLPBlock([128, 64])),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82d988-82cd-48a8-8703-da99a0f257cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training the model with first day's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745ce099-8b12-4465-9569-d51c53f8d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = int(os.environ.get(\n",
    "    \"BATCH_SIZE\", \n",
    "    '1024'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791e06ec-c0cb-4c0f-9e41-7e5c8fa1dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f5e563bc400>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f5e563bc400>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 12s 46ms/step - loss: 6.8098 - recall_at_10: 0.0276 - mrr_at_10: 0.0180 - ndcg_at_10: 0.0202 - map_at_10: 0.0180 - precision_at_10: 0.0028 - regularization_loss: 0.0000e+00 - loss_batch: 6.3128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5d8304a430>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "model.fit(day_1, batch_size=BATCH_SIZE, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59174a-c32c-4808-aa75-14695d5d8c2b",
   "metadata": {},
   "source": [
    "**Evaluate the data using day_2 dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149c864-b745-4382-81f1-f1f80954873d",
   "metadata": {},
   "source": [
    "Training model on a certain period of time, and then evaluating on a dataset which is closer to the test set time period make sense and is a common practice. However, please note that in this example the data is randomly separated, thus we dont really expect a temporal sequence in day_1, day_2, and day_3. Therefore the evaluation metrics might not \"make sense\", since this is a hypotetical example to showcase the functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e88f906-3174-4be3-a77d-e84ac8ff089d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 15ms/step - loss: 6.8088 - recall_at_10: 0.0255 - mrr_at_10: 0.0246 - ndcg_at_10: 0.0248 - map_at_10: 0.0246 - precision_at_10: 0.0025 - regularization_loss: 0.0000e+00 - loss_batch: 6.3119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 6.808794975280762,\n",
       " 'recall_at_10': 0.03030303120613098,\n",
       " 'mrr_at_10': 0.028212962672114372,\n",
       " 'ndcg_at_10': 0.028665972873568535,\n",
       " 'map_at_10': 0.028212962672114372,\n",
       " 'precision_at_10': 0.0030303029343485832,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 5.410911560058594}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics = model.evaluate(day_2, batch_size=BATCH_SIZE, return_dict=True)\n",
    "eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c222dcb6-3e69-4283-ad80-5e7395b3fe78",
   "metadata": {},
   "source": [
    "#### Training the model with second day's data \n",
    "\n",
    "Now we continue to train the model on the second day's data but using different strategies. We can use different learning rate for different layers of the model, i.e. a smaller learning rate for embedding tables while a bigger learning rate for two towers. If we want small updates to the weights of embedding tables, we can set the small learning rate value. Here we choose `0.001` as the learning rate for embedding tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d50639a-515c-44f1-b9b6-13fdb68ef669",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = mm.MultiOptimizer(\n",
    "            default_optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.01),\n",
    "            optimizers_and_blocks=[mm.OptimizerBlocks(tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "                                                      [item_embeddings, query_embeddings])]\n",
    ")                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d738c20c-29a8-43fc-8af7-4616467026a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 50ms/step - loss: 6.8089 - recall_at_10: 0.0289 - mrr_at_10: 0.0278 - ndcg_at_10: 0.0281 - map_at_10: 0.0278 - precision_at_10: 0.0029 - regularization_loss: 0.0000e+00 - loss_batch: 6.3122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5d82080190>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer)\n",
    "model.fit(day_2, batch_size=BATCH_SIZE, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923636d-0189-460c-a55c-3c42b7aed8c5",
   "metadata": {},
   "source": [
    "**Evaluate on the third day's data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd42c5a1-8021-477f-ab82-1158e18f670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 13ms/step - loss: 6.8030 - recall_at_10: 0.0359 - mrr_at_10: 0.0324 - ndcg_at_10: 0.0332 - map_at_10: 0.0324 - precision_at_10: 0.0036 - regularization_loss: 0.0000e+00 - loss_batch: 6.4583\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = model.evaluate(day_3, batch_size=BATCH_SIZE,  return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a5c8634-8e51-44b7-8f5d-9d01fc08d72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 6.803046226501465,\n",
       " 'recall_at_10': 0.03735294193029404,\n",
       " 'mrr_at_10': 0.03274918347597122,\n",
       " 'ndcg_at_10': 0.03387266397476196,\n",
       " 'map_at_10': 0.03274918347597122,\n",
       " 'precision_at_10': 0.0037352940998971462,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 5.776802062988281}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c589a4e-7654-46a6-84cb-1e012cc7852c",
   "metadata": {},
   "source": [
    "### Iteration 2: Training with Freezing Layers\n",
    "\n",
    "Let's consider a new situation. Suppose we have trained the model on all previous data and achieved a good performance. Now there is incoming new data, but we do not want to change the pretrained embedding tables and only want to train the top MLP layers. We can use `model.freeze_blocks()`. When we call `freeze_blocks`, what do we actually do? Each layer maintains a variable called `trainable`. When a layer is created, this variable is set. The default value is `True`, which means all the weights in this layer can be updated. If you change `trainable` into `False`, the weights would not be changed anymore, unless its `trainable` variable becomes `True` again. So when `freeze_blocks` is called, the `trainable` of the layer is set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6994177d-60fb-4657-80f6-4f40b2d1dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_blocks([item_embeddings, query_embeddings])\n",
    "\n",
    "# recompile your model after making any changes\n",
    "# to the `trainable` attribute of any inner layer, so that your changes\n",
    "# are taken into account\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c8e62f5-842e-4caa-85ac-5fa4ec418c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 32ms/step - loss: 6.8077 - recall_at_10: 0.0294 - mrr_at_10: 0.0284 - ndcg_at_10: 0.0286 - map_at_10: 0.0284 - precision_at_10: 0.0029 - regularization_loss: 0.0000e+00 - loss_batch: 6.3090\n",
      "Model: \"retrieval_model\"\n",
      "___________________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                    Param #     Trainable  \n",
      "===========================================================================================\n",
      " two_tower_block (TwoTowerBlock)    multiple                        164728      Y          \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| tower_block (TowerBlock)         multiple                        122120      Y          |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| sequential_block_4 (SequentialBloc  multiple                   122120      Y          ||\n",
      "|| k)                                                                                    ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| parallel_block (ParallelBlock)  multiple                     97352       Y          |||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||| embeddings (ParallelBlock)  multiple                       97352       N          ||||\n",
      "|||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||||\n",
      "||||| user_categories (EmbeddingTable)  multiple               70352       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_shops (EmbeddingTable)  multiple                    73552       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_brands (EmbeddingTable)  multiple                   67544       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_intentions (EmbeddingTable)  multiple               65944       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_profile (EmbeddingTable)  multiple                  65704       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_group (EmbeddingTable)  multiple                    65656       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_gender (EmbeddingTable)  multiple                   65568       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_age (EmbeddingTable)  multiple                      65608       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_consumption_1 (EmbeddingTable  multiple             65576       N          |||||\n",
      "||||| )                                                                               |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_consumption_2 (EmbeddingTable  multiple             65576       N          |||||\n",
      "||||| )                                                                               |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_is_occupied (EmbeddingTable)  multiple              65568       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_geography (EmbeddingTable)  multiple                65584       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| user_id (EmbeddingTable)  multiple                       81552       N          |||||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| sequential_block_3 (SequentialBloc  multiple                 24768       Y          |||\n",
      "||| k)                                                                                  |||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||| private__dense_4 (_Dense)  multiple                        16512       Y          ||||\n",
      "||||                                                                                   ||||\n",
      "|||| private__dense_5 (_Dense)  multiple                        8256        Y          ||||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| model_context (ModelContext)   multiple                        65536       N          ||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| tower_block_1 (TowerBlock)       multiple                        108144      Y          |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| sequential_block_6 (SequentialBloc  multiple                   108144      Y          ||\n",
      "|| k)                                                                                    ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| parallel_block_1 (ParallelBlock)  multiple                   92592       Y          |||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||| embeddings (ParallelBlock)  multiple                       92592       N          ||||\n",
      "|||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||||\n",
      "||||| item_category (EmbeddingTable)  multiple                 66344       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| item_shop (EmbeddingTable)  multiple                     73552       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| item_intention (EmbeddingTable)  multiple                65744       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| item_brand (EmbeddingTable)  multiple                    67544       N          |||||\n",
      "|||||                                                                                 |||||\n",
      "||||| item_id (EmbeddingTable)  multiple                       81552       N          |||||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| sequential_block_5 (SequentialBloc  multiple                 15552       Y          |||\n",
      "||| k)                                                                                  |||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||| private__dense_6 (_Dense)  multiple                        7296        Y          ||||\n",
      "||||                                                                                   ||||\n",
      "|||| private__dense_7 (_Dense)  multiple                        8256        Y          ||||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| model_context (ModelContext)   multiple                        65536       N          ||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " item_retrieval_task (ItemRetrieval  multiple                       65536       Y          \n",
      " Task)                                                                                     \n",
      "                                                                                           \n",
      " model_context (ModelContext)       multiple                        65536       N          \n",
      "                                                                                           \n",
      " process_list (ProcessList)         multiple                        0           Y          \n",
      "                                                                                           \n",
      "===========================================================================================\n",
      "Total params: 164,729\n",
      "Trainable params: 40,320\n",
      "Non-trainable params: 124,409\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(day_1, batch_size=BATCH_SIZE, epochs=1)\n",
    "model.summary(expand_nested=True, show_trainable=True, line_length=80)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2dcd41-31f7-4c09-b120-3b58900f76d4",
   "metadata": {},
   "source": [
    "When we call `freeze_blocks` on some layers, all these layers and their children layers become non-trainable. For example, if a `ParallelBlock` is frozen, the children blocks inside this `ParallelBlock` are also frozen. As shown in below summary result, we freeze the `user_embeddings`, and it is a `ParallelBlock`, all the children layers are frozen as well.\n",
    "\n",
    "```\n",
    "|||||| embeddings (ParallelBlock)  multiple                   21902016    N          ||||||\n",
    "|||||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||||||\n",
    "||||||| user_categories (EmbeddingTable)  multiple           146088      N          |||||||\n",
    "|||||||                                                                             |||||||\n",
    "||||||| user_shops (EmbeddingTable)  multiple                4669680     N          |||||||\n",
    "|||||||                                                                             |||||||\n",
    "||||||| user_brands (EmbeddingTable)  multiple               1856512     N          |||||||\n",
    "|||||||                                                                             |||||||\n",
    "||||||| user_intentions (EmbeddingTable)  multiple           1081184     N          |||||||\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea5782-c88f-4a34-990f-9074bb387d63",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d3d88-979e-4587-a74a-bcf61db36b84",
   "metadata": {},
   "source": [
    "In this example notebook we learned how to use different learning rates for different layers in our model architecture, and how to freeze embedding layers, so that we do not update their parameters during training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c78a7de67f1468ee33d22a76790123f2989400fa0e73ac6b45f15b09432f615d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
