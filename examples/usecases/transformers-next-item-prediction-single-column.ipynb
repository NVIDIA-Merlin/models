{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64526ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was cb431a8a Fix the serialization of `SequenceSummary` block (#927)\n",
      "Switched to branch 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/Models\n",
      "   835ad186..a1d748d1  main                   -> origin/main\n",
      " * [new branch]        asvdb_metric_tracking  -> origin/asvdb_metric_tracking\n",
      " * [new branch]        ci/horovod             -> origin/ci/horovod\n",
      " * [new branch]        codespell_fix          -> origin/codespell_fix\n",
      "   16fb4149..fcaefc3e  fea-sok-integration-wj -> origin/fea-sok-integration-wj\n",
      " * [new branch]        fea-sok-load-dump      -> origin/fea-sok-load-dump\n",
      "   95462360..a638656c  gh-pages               -> origin/gh-pages\n",
      " * [new branch]        inference_benchmarking_transformers -> origin/inference_benchmarking_transformers\n",
      " * [new branch]        mtl_example            -> origin/mtl_example\n",
      "   cb431a8a..b90e9a1b  release-22.12          -> origin/release-22.12\n",
      " * [new branch]        release-23.02          -> origin/release-23.02\n",
      " * [new branch]        tf/column_sampling_serialization_fix -> origin/tf/column_sampling_serialization_fix\n",
      " * [new branch]        tf/continuous_seq_feats_fix -> origin/tf/continuous_seq_feats_fix\n",
      " * [new branch]        tf/dataloader_changes  -> origin/tf/dataloader_changes\n",
      " * [new branch]        tf/dlrm_dropout_fix    -> origin/tf/dlrm_dropout_fix\n",
      " * [new branch]        tf/fix_broadcast_to_sequence -> origin/tf/fix_broadcast_to_sequence\n",
      " * [new branch]        tf/fix_training_smaller_accuracy -> origin/tf/fix_training_smaller_accuracy\n",
      " * [new branch]        tf/mtl_example_updates_v2 -> origin/tf/mtl_example_updates_v2\n",
      " + 169f3df5...06eecddd tf/output-block        -> origin/tf/output-block  (forced update)\n",
      " * [new branch]        tf/process_list_to_prepare_features -> origin/tf/process_list_to_prepare_features\n",
      " * [new branch]        tf/quick_start_ranking -> origin/tf/quick_start_ranking\n",
      " * [new branch]        tf/transformer-api     -> origin/tf/transformer-api\n",
      " * [new branch]        torch/dev              -> origin/torch/dev\n",
      " * [new branch]        torch/remove-t4r-code  -> origin/torch/remove-t4r-code\n",
      " * [new branch]        tox_github_actions_fix -> origin/tox_github_actions_fix\n",
      " * [new branch]        transformer-api        -> origin/transformer-api\n",
      " + 0a65d603...9f53e8ff update_07              -> origin/update_07  (forced update)\n",
      " * [new tag]           v23.02.00              -> v23.02.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 835ad186..a1d748d1\n",
      "Fast-forward\n",
      " .github/workflows/cpu-horovod.yml                  |   49 +\n",
      " .github/workflows/cpu-nvtabular.yml                |    4 +-\n",
      " .github/workflows/cpu-systems.yml                  |    4 +-\n",
      " .github/workflows/datasets.yml                     |    4 +-\n",
      " .github/workflows/docs-sched-rebuild.yaml          |    7 +-\n",
      " .github/workflows/gpu-ci.yml                       |    4 +-\n",
      " .github/workflows/implicit.yml                     |    4 +-\n",
      " .github/workflows/lightfm.yml                      |    4 +-\n",
      " .github/workflows/multi-gpu-ci.yml                 |   30 +\n",
      " .github/workflows/pre-commit.yml                   |    4 +\n",
      " .github/workflows/pytorch.yml                      |    5 +-\n",
      " .github/workflows/tensorflow.yml                   |   20 +-\n",
      " .github/workflows/xgboost.yml                      |    4 +-\n",
      " .pre-commit-config.yaml                            |   10 +-\n",
      " README.md                                          |    2 +-\n",
      " ci/pr.gpu.Jenkinsfile                              |    2 +-\n",
      " docs/README.md                                     |   46 +-\n",
      " docs/source/api.rst                                |   99 +-\n",
      " examples/01-Getting-started.ipynb                  |  101 +-\n",
      " ...2-Merlin-Models-and-NVTabular-integration.ipynb |   13 +-\n",
      " examples/03-Exploring-different-models.ipynb       |   25 +-\n",
      " examples/04-Exporting-ranking-models.ipynb         |    9 +-\n",
      " examples/05-Retrieval-Model.ipynb                  |   30 +-\n",
      " ...-your-own-architecture-with-Merlin-Models.ipynb |  546 +++----\n",
      " ...nal-ML-models-using-the-Merlin-Models-API.ipynb |  701 +++++++-\n",
      " examples/images/mtl_architectures.png              |  Bin 0 -> 72404 bytes\n",
      " ...ing-of-large-embedding-tables-by-LazyAdam.ipynb |   12 +-\n",
      " ...on-based-next-item-prediction-for-fashion.ipynb |   11 +-\n",
      " .../entertainment-with-pretrained-embeddings.ipynb |    8 +-\n",
      " .../incremental-training-with-layer-freezing.ipynb |  275 ++--\n",
      " .../multi-gpu-data-parallel-training.ipynb         |    7 +-\n",
      " .../multi-gpu/install_sparse_operation_kit.sh      |   16 +\n",
      " .../usecases/ranking_with_multitask_learning.ipynb | 1718 ++++++++++++++++++++\n",
      " ...etrieval-with-hyperparameter-optimization.ipynb |    5 +-\n",
      " .../transformers-next-item-prediction.ipynb        |  418 ++---\n",
      " .../ecommerce/booking/transformed/schema.pbtxt     |   15 +-\n",
      " merlin/datasets/ecommerce/small/schema.json        |    7 +-\n",
      " .../entertainment/movielens/100k/schema.pbtxt      |    1 +\n",
      " .../entertainment/movielens/1m/schema.pbtxt        |    3 +-\n",
      " .../entertainment/movielens/25m/schema.pbtxt       |    1 +\n",
      " .../entertainment/music_streaming/schema.json      |   10 +-\n",
      " .../entertainment/tenrec_video/__init__.py         |   15 +\n",
      " .../entertainment/tenrec_video/schema.pbtxt        |  159 ++\n",
      " merlin/datasets/synthetic.py                       |  104 +-\n",
      " .../datasets/testing/sequence_testing/schema.json  |   24 +-\n",
      " merlin/models/implicit/__init__.py                 |  115 +-\n",
      " merlin/models/io.py                                |    2 -\n",
      " merlin/models/lightfm/__init__.py                  |  132 +-\n",
      " merlin/models/tf/__init__.py                       |   12 +-\n",
      " merlin/models/tf/blocks/dlrm.py                    |   21 +-\n",
      " merlin/models/tf/blocks/experts.py                 |   33 +-\n",
      " merlin/models/tf/blocks/optimizer.py               |   74 +-\n",
      " merlin/models/tf/blocks/retrieval/base.py          |    1 -\n",
      " merlin/models/tf/core/aggregation.py               |   87 +-\n",
      " merlin/models/tf/core/combinators.py               |    6 +-\n",
      " merlin/models/tf/core/encoder.py                   |   43 +-\n",
      " merlin/models/tf/core/tabular.py                   |    3 +-\n",
      " merlin/models/tf/distributed/backend.py            |   20 +\n",
      " merlin/models/tf/distributed/embedding.py          |  232 +++\n",
      " merlin/models/tf/experimental/sample_weight.py     |  177 ++\n",
      " merlin/models/tf/inputs/base.py                    |   26 +-\n",
      " merlin/models/tf/inputs/continuous.py              |   41 +-\n",
      " merlin/models/tf/inputs/embedding.py               |  138 +-\n",
      " merlin/models/tf/loader.py                         |   36 +-\n",
      " merlin/models/tf/metrics/__init__.py               |   31 +-\n",
      " merlin/models/tf/metrics/evaluation.py             |    4 +-\n",
      " merlin/models/tf/metrics/topk.py                   |   17 +-\n",
      " merlin/models/tf/models/base.py                    |  765 +++++++--\n",
      " merlin/models/tf/models/benchmark.py               |   20 +-\n",
      " merlin/models/tf/models/ranking.py                 |   93 +-\n",
      " merlin/models/tf/models/retrieval.py               |    4 +\n",
      " merlin/models/tf/models/utils.py                   |   38 +\n",
      " merlin/models/tf/outputs/base.py                   |   23 +-\n",
      " merlin/models/tf/outputs/block.py                  |  300 ++++\n",
      " merlin/models/tf/outputs/classification.py         |   12 +-\n",
      " merlin/models/tf/outputs/contrastive.py            |    4 +-\n",
      " merlin/models/tf/outputs/regression.py             |    8 +-\n",
      " merlin/models/tf/outputs/sampling/base.py          |   17 +-\n",
      " merlin/models/tf/outputs/sampling/popularity.py    |    4 +-\n",
      " merlin/models/tf/outputs/topk.py                   |    2 -\n",
      " merlin/models/tf/prediction_tasks/base.py          |   15 +\n",
      " .../models/tf/prediction_tasks/classification.py   |   11 +-\n",
      " merlin/models/tf/prediction_tasks/regression.py    |    3 +-\n",
      " merlin/models/tf/transformers/block.py             |   61 +-\n",
      " merlin/models/tf/transformers/transforms.py        |   52 +-\n",
      " merlin/models/tf/transforms/bias.py                |   15 +-\n",
      " merlin/models/tf/transforms/features.py            |  577 +++++--\n",
      " merlin/models/tf/transforms/negative_sampling.py   |   25 +-\n",
      " merlin/models/tf/transforms/sequence.py            |  523 ++++--\n",
      " merlin/models/tf/transforms/tensor.py              |  249 +--\n",
      " merlin/models/tf/utils/testing_utils.py            |   74 +-\n",
      " merlin/models/tf/utils/tf_utils.py                 |   76 +-\n",
      " merlin/models/torch/utils/data_utils.py            |    1 -\n",
      " merlin/models/utils/dataset.py                     |   59 +-\n",
      " merlin/models/utils/misc_utils.py                  |    7 +-\n",
      " merlin/models/utils/schema_utils.py                |   24 +-\n",
      " merlin/models/xgb/__init__.py                      |    1 -\n",
      " pytest.ini                                         |   15 +\n",
      " requirements/docs.txt                              |    3 +-\n",
      " requirements/horovod-cpu-environment.yml           |   18 +\n",
      " requirements/horovod.txt                           |    1 +\n",
      " requirements/test.txt                              |    2 +-\n",
      " requirements/transformers.txt                      |    2 +-\n",
      " tests/common/tf/retrieval/retrieval_utils.py       |    4 +-\n",
      " tests/integration/tf/test_ci_01_getting_started.py |   20 +-\n",
      " .../tf/test_ci_03_exploring_different_models.py    |    8 +-\n",
      " .../tf/test_ci_06_advanced_own_architecture.py     |    8 +-\n",
      " tests/unit/datasets/test_ecommerce.py              |   25 +-\n",
      " tests/unit/datasets/test_synthetic.py              |   12 +-\n",
      " tests/unit/implicit/test_implicit.py               |   60 +-\n",
      " tests/unit/lightfm/test_lightfm.py                 |   68 +\n",
      " tests/unit/tf/blocks/retrieval/test_two_tower.py   |    2 +-\n",
      " tests/unit/tf/blocks/test_cross.py                 |    2 -\n",
      " tests/unit/tf/blocks/test_interactions.py          |    6 +-\n",
      " tests/unit/tf/blocks/test_mlp.py                   |   39 +\n",
      " tests/unit/tf/blocks/test_optimizer.py             |   64 +-\n",
      " tests/unit/tf/core/test_base.py                    |    5 +-\n",
      " tests/unit/tf/core/test_combinators.py             |    1 +\n",
      " tests/unit/tf/core/test_encoder.py                 |    6 +-\n",
      " tests/unit/tf/examples/test_01_getting_started.py  |    8 +-\n",
      " .../examples/test_03_exploring_different_models.py |    8 +-\n",
      " ...test_usecase_accelerate_training_by_lazyadam.py |    1 +\n",
      " ..._usecase_incremental_training_layer_freezing.py |    8 +-\n",
      " ...test_usecase_ranking_with_multitask_learning.py |   46 +\n",
      " ...st_usecase_transformers_next_item_prediction.py |    1 -\n",
      " tests/unit/tf/experimental/__init__.py             |   15 +\n",
      " tests/unit/tf/experimental/test_sample_weight.py   |  110 ++\n",
      " tests/unit/tf/horovod/__init__.py                  |    2 +-\n",
      " tests/unit/tf/horovod/test_embedding.py            |   46 +\n",
      " tests/unit/tf/horovod/test_horovod.py              |   10 +-\n",
      " tests/unit/tf/inputs/test_base.py                  |    2 +-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tests/unit/tf/inputs/test_block.py                 |  202 +++\n",
      " tests/unit/tf/inputs/test_continuous.py            |    4 +-\n",
      " tests/unit/tf/inputs/test_embedding.py             |   33 +-\n",
      " tests/unit/tf/inputs/test_tabular.py               |   10 +-\n",
      " tests/unit/tf/metrics/test_metrics_topk.py         |    2 -\n",
      " tests/unit/tf/models/test_base.py                  |  135 +-\n",
      " tests/unit/tf/models/test_benchmark.py             |   13 +-\n",
      " tests/unit/tf/models/test_ranking.py               |  103 +-\n",
      " tests/unit/tf/models/test_retrieval.py             |   27 +-\n",
      " tests/unit/tf/outputs/test_base.py                 |   78 +-\n",
      " tests/unit/tf/outputs/test_block.py                |  936 +++++++++++\n",
      " tests/unit/tf/outputs/test_classification.py       |   69 +-\n",
      " tests/unit/tf/outputs/test_contrastive.py          |   23 +-\n",
      " tests/unit/tf/outputs/test_sampling.py             |   17 +-\n",
      " tests/unit/tf/prediction_tasks/test_multi_task.py  |  281 +++-\n",
      " tests/unit/tf/test_loader.py                       |   28 +-\n",
      " tests/unit/tf/transformers/test_block.py           |  183 ++-\n",
      " tests/unit/tf/transforms/test_features.py          |  123 +-\n",
      " tests/unit/tf/transforms/test_negative_sampling.py |   63 +-\n",
      " tests/unit/tf/transforms/test_noise.py             |    1 -\n",
      " tests/unit/tf/transforms/test_sequence.py          |   55 +-\n",
      " tests/unit/tf/transforms/test_tensor.py            |   20 +-\n",
      " tests/unit/torch/tabular/test_transformations.py   |    1 -\n",
      " tox.ini                                            |   62 +-\n",
      " 155 files changed, 9535 insertions(+), 2412 deletions(-)\n",
      " create mode 100644 .github/workflows/cpu-horovod.yml\n",
      " create mode 100644 .github/workflows/multi-gpu-ci.yml\n",
      " create mode 100644 examples/images/mtl_architectures.png\n",
      " create mode 100644 examples/usecases/multi-gpu/install_sparse_operation_kit.sh\n",
      " create mode 100644 examples/usecases/ranking_with_multitask_learning.ipynb\n",
      " create mode 100644 merlin/datasets/entertainment/tenrec_video/__init__.py\n",
      " create mode 100644 merlin/datasets/entertainment/tenrec_video/schema.pbtxt\n",
      " create mode 100644 merlin/models/tf/distributed/embedding.py\n",
      " create mode 100644 merlin/models/tf/experimental/sample_weight.py\n",
      " create mode 100644 merlin/models/tf/outputs/block.py\n",
      " create mode 100644 pytest.ini\n",
      " create mode 100644 requirements/horovod-cpu-environment.yml\n",
      " create mode 100644 tests/unit/tf/examples/test_usecase_ranking_with_multitask_learning.py\n",
      " create mode 100644 tests/unit/tf/experimental/__init__.py\n",
      " create mode 100644 tests/unit/tf/experimental/test_sample_weight.py\n",
      " create mode 100644 tests/unit/tf/horovod/test_embedding.py\n",
      " create mode 100644 tests/unit/tf/inputs/test_block.py\n",
      " create mode 100644 tests/unit/tf/outputs/test_block.py\n",
      "Processing /models\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: merlin-dataloader>=0.0.2 in /usr/local/lib/python3.8/dist-packages (from merlin-models==0.9.0+134.ga1d748d1) (0.0.4)\n",
      "Requirement already satisfied: merlin-core>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-models==0.9.0+134.ga1d748d1) (0.10.0)\n",
      "Requirement already satisfied: distributed>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (2022.7.1)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (0.56.4)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.2.5)\n",
      "Requirement already satisfied: dask>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (2022.7.1)\n",
      "Requirement already satisfied: pandas<1.4.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.3.5)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (4.64.1)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (3.19.6)\n",
      "Requirement already satisfied: fsspec==2022.5.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (2022.5.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (22.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (8.0.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.26.13)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (2.2.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (2.4.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (0.12.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.0.4)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (5.9.4)\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (2.2.0)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.0.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.7.0)\n",
      "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (8.1.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (3.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (6.0)\n",
      "Requirement already satisfied: tornado<6.2,>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (6.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.22.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (5.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (45.2.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (0.39.1)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (0.4.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.2.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (2.8.2)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.57.0)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (3.11.0)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (4.1.0)\n",
      "Requirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (6.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (1.14.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+134.ga1d748d1) (4.0.0)\n",
      "Building wheels for collected packages: merlin-models\n",
      "  Building wheel for merlin-models (PEP 517): started\n",
      "  Building wheel for merlin-models (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-models: filename=merlin_models-0.9.0+134.ga1d748d1-py3-none-any.whl size=381738 sha256=aa3aed677e9e6c87b1ac8a65a2f3130d0e803219bd504b9d6c05df84e7979596\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-29ple7ef/wheels/4d/e8/98/0493db55fff90dc9af123f55a9455b96f7f8166c912a02c8a6\n",
      "Successfully built merlin-models\n",
      "Installing collected packages: merlin-models\n",
      "  Attempting uninstall: merlin-models\n",
      "    Found existing installation: merlin-models 0.11.0\n",
      "    Uninstalling merlin-models-0.11.0:\n",
      "      Successfully uninstalled merlin-models-0.11.0\n",
      "Successfully installed merlin-models-0.9.0+134.ga1d748d1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was 020b24b7 Fix output error occurring due to  check if it is a dict or not (#1742)\n",
      "Switched to branch 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/NVTabular\n",
      "   c5bc4098..cdc5ff12  main                    -> origin/main\n",
      " * [new branch]        bench-pynvml-fix        -> origin/bench-pynvml-fix\n",
      " * [new branch]        dataloader-remove-sparse -> origin/dataloader-remove-sparse\n",
      " * [new branch]        disable-package-build-on-pull-requests -> origin/disable-package-build-on-pull-requests\n",
      " * [new branch]        fix-docs-tox-env        -> origin/fix-docs-tox-env\n",
      " * [new branch]        fix-wf-file             -> origin/fix-wf-file\n",
      " * [new branch]        fix/inference-deprecation -> origin/fix/inference-deprecation\n",
      "   842fb654..9fec8adc  gh-pages                -> origin/gh-pages\n",
      " * [new branch]        laiacano/check-list-from-schema -> origin/laiacano/check-list-from-schema\n",
      " * [new branch]        packages-workflow-split -> origin/packages-workflow-split\n",
      "   020b24b7..211f9fbb  release-22.12           -> origin/release-22.12\n",
      " * [new branch]        release-23.02           -> origin/release-23.02\n",
      " * [new branch]        test-column-similarity-dataset-cpu-default-none -> origin/test-column-similarity-dataset-cpu-default-none\n",
      " * [new branch]        test-torch-dataloader-dataset-cpu-default-none -> origin/test-torch-dataloader-dataset-cpu-default-none\n",
      " * [new branch]        workflow-transform-dataframe -> origin/workflow-transform-dataframe\n",
      " * [new tag]           v1.8.1                  -> v1.8.1\n",
      " * [new tag]           v23.02.00               -> v23.02.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating c5bc4098..cdc5ff12\n",
      "Fast-forward\n",
      " .github/ISSUE_TEMPLATE/bug_report.md               |  11 +-\n",
      " .github/ISSUE_TEMPLATE/documentation-request.md    |   3 +-\n",
      " .github/ISSUE_TEMPLATE/feature_request.md          |   3 +-\n",
      " .github/ISSUE_TEMPLATE/operator_request.md         |  14 +-\n",
      " .github/ISSUE_TEMPLATE/research_question.md        |   3 +-\n",
      " .github/ISSUE_TEMPLATE/submit-question.md          |   3 +-\n",
      " .github/ISSUE_TEMPLATE/task.md                     |   4 +-\n",
      " .github/release-drafter.yml                        |  44 ++--\n",
      " .github/workflows/blossom-ci.yml                   | 230 ++++++++++-----------\n",
      " .github/workflows/conda-env-create.yml             |  30 +--\n",
      " .github/workflows/cpu-ci.yml                       | 138 -------------\n",
      " .github/workflows/cpu-packages.yml                 | 166 +++++++++++++++\n",
      " .github/workflows/cpu-tests.yml                    |  71 +++++++\n",
      " .github/workflows/docs-preview-pr.yaml             |   4 +-\n",
      " .github/workflows/docs-sched-rebuild.yaml          |   7 +-\n",
      " .github/workflows/gpu-ci.yml                       |  30 ---\n",
      " .github/workflows/gpu-tests.yml                    |  30 +++\n",
      " .gitlab-ci.yml                                     |  23 +--\n",
      " .pre-commit-config.yaml                            |  47 +++--\n",
      " .prettierignore                                    |   2 +\n",
      " CHANGELOG.md                                       | 187 ++++++++---------\n",
      " CONTRIBUTING.md                                    |  30 +--\n",
      " README.md                                          |  48 ++---\n",
      " bench/datasets/tools/nvt_etl.py                    |   4 +-\n",
      " bench/datasets/tools/train_tensorflow.py           |   1 -\n",
      " bench/examples/MultiGPUBench.md                    |  67 +++---\n",
      " bench/examples/dask-nvtabular-criteo-benchmark.py  |   4 +-\n",
      " ci/pr.gpu.Jenkinsfile                              |   2 +-\n",
      " conda/environments/nvtabular_aws_sagemaker.yml     |   2 +-\n",
      " docs/README.md                                     |  29 ++-\n",
      " docs/source/core_features.md                       |  48 ++---\n",
      " docs/source/resources/architecture.md              |  17 +-\n",
      " docs/source/resources/cloud_integration.md         |  24 ++-\n",
      " docs/source/resources/links.md                     |  40 ++--\n",
      " docs/source/toc.yaml                               |  12 +-\n",
      " examples/01-Getting-started.ipynb                  |   5 +-\n",
      " examples/02-Advanced-NVTabular-workflow.ipynb      |   5 +-\n",
      " .../03-Running-on-multiple-GPUs-or-on-CPU.ipynb    |   5 +-\n",
      " examples/README.md                                 |   1 +\n",
      " nvtabular/inference/__init__.py                    |   4 +-\n",
      " nvtabular/inference/triton/ensemble.py             |  86 ++------\n",
      " nvtabular/inference/triton/model/model_pt.py       |   1 -\n",
      " nvtabular/inference/workflow/hugectr.py            |   2 +-\n",
      " nvtabular/loader/backend.py                        |  31 +--\n",
      " nvtabular/loader/tensorflow.py                     |   1 +\n",
      " nvtabular/ops/categorify.py                        |   2 -\n",
      " nvtabular/ops/groupby.py                           |  35 ++--\n",
      " nvtabular/ops/join_external.py                     |   1 -\n",
      " nvtabular/ops/join_groupby.py                      |  18 +-\n",
      " nvtabular/ops/list_slice.py                        |  22 +-\n",
      " nvtabular/ops/moments.py                           |   2 -\n",
      " nvtabular/ops/reduce_dtype_size.py                 |   9 +-\n",
      " nvtabular/ops/value_counts.py                      |  14 +-\n",
      " nvtabular/tools/data_gen.py                        |   4 +-\n",
      " nvtabular/workflow/workflow.py                     | 163 +++++++++++++--\n",
      " requirements-test.txt                              |   2 -\n",
      " requirements/test.txt                              |   3 +-\n",
      " setup.py                                           |   5 +\n",
      " tests/conftest.py                                  |  24 ++-\n",
      " .../test_02-Advanced-NVTabular-workflow.py         |  12 +-\n",
      " .../test_03-Running-on-multiple-GPUs-or-on-CPU.py  |   5 +\n",
      " tests/unit/loader/test_tf_dataloader.py            | 206 +++---------------\n",
      " tests/unit/loader/test_torch_dataloader.py         |  59 ++----\n",
      " tests/unit/ops/test_column_similarity.py           |   3 +-\n",
      " tests/unit/ops/test_groupyby.py                    |   2 +-\n",
      " tests/unit/ops/test_lambda.py                      |  28 ++-\n",
      " tests/unit/ops/test_ops_schema.py                  |  25 ++-\n",
      " tests/unit/ops/test_value_count.py                 |   2 +\n",
      " tests/unit/workflow/test_workflow.py               |  84 +++++++-\n",
      " tox.ini                                            |  10 +-\n",
      " 70 files changed, 1231 insertions(+), 1028 deletions(-)\n",
      " delete mode 100644 .github/workflows/cpu-ci.yml\n",
      " create mode 100644 .github/workflows/cpu-packages.yml\n",
      " create mode 100644 .github/workflows/cpu-tests.yml\n",
      " delete mode 100644 .github/workflows/gpu-ci.yml\n",
      " create mode 100644 .github/workflows/gpu-tests.yml\n",
      " create mode 100644 .prettierignore\n",
      " delete mode 100644 requirements-test.txt\n",
      "Processing /nvtabular\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: merlin-dataloader>=0.0.2 in /usr/local/lib/python3.8/dist-packages (from nvtabular==1.6.0+55.gcdc5ff12) (0.0.4)\n",
      "Requirement already satisfied: merlin-core>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from nvtabular==1.6.0+55.gcdc5ff12) (0.10.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nvtabular==1.6.0+55.gcdc5ff12) (1.9.3)\n",
      "Requirement already satisfied: distributed>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (2022.7.1)\n",
      "Requirement already satisfied: fsspec==2022.5.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (2022.5.0)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.12.0)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (4.64.1)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.2.5)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (8.0.0)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (3.19.6)\n",
      "Requirement already satisfied: pandas<1.4.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.3.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (22.0)\n",
      "Requirement already satisfied: dask>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (2022.7.1)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (0.56.4)\n",
      "Requirement already satisfied: numpy<1.26.0,>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from scipy->nvtabular==1.6.0+55.gcdc5ff12) (1.22.4)\n",
      "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (8.1.3)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.26.13)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.0.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (0.12.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (2.2.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (2.4.0)\n",
      "Requirement already satisfied: tornado<6.2,>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (6.1)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.0.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (3.1.2)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (5.9.4)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (2.2.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.57.0)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.3.0)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (0.4.3)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (2022.7)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.3.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (45.2.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (5.2.0)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (2.1.1)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (4.1.0)\n",
      "Requirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (6.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (1.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.54->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (3.11.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (4.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->nvtabular==1.6.0+55.gcdc5ff12) (6.0.1)\n",
      "Building wheels for collected packages: nvtabular\n",
      "  Building wheel for nvtabular (PEP 517): started\n",
      "  Building wheel for nvtabular (PEP 517): finished with status 'done'\n",
      "  Created wheel for nvtabular: filename=nvtabular-1.6.0+55.gcdc5ff12-cp38-cp38-linux_x86_64.whl size=258811 sha256=e8969a713256ebfbe7b83eea55fb6c7db6fa1a4bdb283bafff7a7ec1edc5a196\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-lu1dqucq/wheels/df/bf/c2/9cc2a62fe6da42038c26a9c0c4e25f9767093528b102fa30a2\n",
      "Successfully built nvtabular\n",
      "Installing collected packages: nvtabular\n",
      "  Attempting uninstall: nvtabular\n",
      "    Found existing installation: nvtabular 1.8.0\n",
      "    Uninstalling nvtabular-1.8.0:\n",
      "      Successfully uninstalled nvtabular-1.8.0\n",
      "Successfully installed nvtabular-1.6.0+55.gcdc5ff12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was 2fc6889 add schema parameter to the `repartition` method (#192)\n",
      "Switched to branch 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/core\n",
      "   cd96ca5f..0bade49f main              -> origin/main\n",
      "   4f82053e..80005f18 gh-pages          -> origin/gh-pages\n",
      " * [new branch]      release-23.02     -> origin/release-23.02\n",
      "   b48439af..1e9b4051 tags-intersection -> origin/tags-intersection\n",
      " * [new tag]         v23.02.01         -> v23.02.01\n",
      " * [new tag]           v23.02.00         -> v23.02.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cd96ca5f..0bade49f\n",
      "Fast-forward\n",
      " .github/release-drafter.yml                        |  44 +--\n",
      " .github/workflows/ISSUE_TEMPLATE/bug-report.md     |  17 +-\n",
      " .../ISSUE_TEMPLATE/documentation-request.md        |  12 +-\n",
      " .../workflows/ISSUE_TEMPLATE/feature-request.md    |   5 +-\n",
      " .../workflows/ISSUE_TEMPLATE/submit-question.md    |   3 +-\n",
      " .github/workflows/ISSUE_TEMPLATE/task.md           |   5 +-\n",
      " .github/workflows/cpu-ci.yml                       | 136 +--------\n",
      " .github/workflows/cpu-models.yml                   |  44 ---\n",
      " .github/workflows/cpu-nvtabular.yml                |  44 ---\n",
      " .github/workflows/cpu-packages.yml                 | 126 ++++++++\n",
      " .github/workflows/cpu-systems.yml                  |  44 ---\n",
      " .github/workflows/docs-preview-pr.yaml             |   2 +-\n",
      " .github/workflows/docs-sched-rebuild.yaml          |   7 +-\n",
      " .github/workflows/gpu-ci.yml                       |  48 ++-\n",
      " .github/workflows/merlin.yml                       |  35 +++\n",
      " .github/workflows/release-drafter.yaml             |   2 +-\n",
      " .github/workflows/tox.yml                          |  38 +++\n",
      " .pre-commit-config.yaml                            |  55 ++--\n",
      " .prettierignore                                    |   2 +\n",
      " CLA.md                                             |   9 +-\n",
      " CONTRIBUTING.md                                    |  28 +-\n",
      " README.md                                          |  68 ++---\n",
      " ci/pr.gpu.Jenkinsfile                              |   2 +-\n",
      " docs/README.md                                     |  49 +--\n",
      " merlin/core/compat.py                              | 188 +++++++++++-\n",
      " merlin/core/dispatch.py                            | 235 ++++++++++-----\n",
      " merlin/core/has_gpu.py                             |  46 +++\n",
      " merlin/core/utils.py                               |  89 +-----\n",
      " merlin/dag/__init__.py                             |   1 +\n",
      " merlin/dag/base_operator.py                        |  30 +-\n",
      " merlin/dag/dictarray.py                            |   3 +-\n",
      " merlin/dag/executors.py                            | 107 ++++---\n",
      " merlin/dag/graph.py                                |  20 ++\n",
      " merlin/dag/node.py                                 |   2 +-\n",
      " merlin/dag/selector.py                             |   3 +\n",
      " merlin/dag/utils.py                                |  69 +++++\n",
      " merlin/dispatch/lazy.py                            | 156 ++++++++++\n",
      " merlin/dtypes/__init__.py                          |  61 ++++\n",
      " merlin/dtypes/aliases.py                           |  52 ++++\n",
      " merlin/dtypes/base.py                              | 178 +++++++++++\n",
      " merlin/dtypes/mapping.py                           | 173 +++++++++++\n",
      " merlin/dtypes/mappings/__init__.py                 |  18 ++\n",
      " merlin/dtypes/mappings/cudf.py                     |  57 ++++\n",
      " merlin/dtypes/mappings/numpy.py                    |  52 ++++\n",
      " merlin/dtypes/mappings/pandas.py                   |  38 +++\n",
      " merlin/dtypes/mappings/python.py                   |  31 ++\n",
      " merlin/dtypes/mappings/tf.py                       |  52 ++++\n",
      " merlin/dtypes/mappings/torch.py                    |  43 +++\n",
      " merlin/dtypes/mappings/triton.py                   |  53 ++++\n",
      " merlin/dtypes/registry.py                          | 142 +++++++++\n",
      " merlin/dtypes/shape.py                             | 189 ++++++++++++\n",
      " merlin/io/__init__.py                              |   2 +-\n",
      " merlin/io/avro.py                                  |   4 -\n",
      " merlin/io/csv.py                                   |   1 -\n",
      " merlin/io/dask.py                                  |  74 ++++-\n",
      " merlin/io/dataset.py                               | 107 +++++--\n",
      " merlin/io/fsspec_utils.py                          |   8 +-\n",
      " merlin/io/parquet.py                               |  17 +-\n",
      " merlin/io/writer.py                                |   1 -\n",
      " merlin/io/writer_factory.py                        |  10 +-\n",
      " merlin/schema/io/tensorflow_metadata.py            | 115 +++++---\n",
      " merlin/schema/schema.py                            | 327 +++++++++++++--------\n",
      " merlin/schema/tags.py                              |   1 +\n",
      " merlin/table/__init__.py                           |  24 ++\n",
      " merlin/table/conversions.py                        | 155 ++++++++++\n",
      " merlin/table/cupy_column.py                        | 106 +++++++\n",
      " merlin/table/numpy_column.py                       | 114 +++++++\n",
      " merlin/table/tensor_column.py                      | 261 ++++++++++++++++\n",
      " merlin/table/tensor_table.py                       | 226 ++++++++++++++\n",
      " merlin/table/tensorflow_column.py                  | 173 +++++++++++\n",
      " merlin/table/torch_column.py                       | 133 +++++++++\n",
      " requirements.txt                                   |  12 +-\n",
      " tests/conftest.py                                  |  26 +-\n",
      " tests/unit/core/test_dispatch.py                   |  17 +-\n",
      " tests/unit/core/test_protocols.py                  |  10 +-\n",
      " tests/unit/core/test_version.py                    |   2 +\n",
      " tests/unit/dag/test_dag_utils.py                   |  31 ++\n",
      " tests/unit/dispatch/test_lazy_dispatch.py          |  61 ++++\n",
      " tests/unit/dtypes/test_module.py                   |  48 +++\n",
      " tests/unit/dtypes/test_shape.py                    | 222 ++++++++++++++\n",
      " tests/unit/io/test_dataset.py                      |  51 ++++\n",
      " tests/unit/io/test_io.py                           |  92 ++++--\n",
      " tests/unit/schema/test_column_schemas.py           | 142 ++++++---\n",
      " tests/unit/schema/test_schema.py                   |  60 +++-\n",
      " tests/unit/schema/test_schema_io.py                |  27 +-\n",
      " tests/unit/table/test_convert_column.py            | 164 +++++++++++\n",
      " tests/unit/table/test_tensor_column.py             | 262 +++++++++++++++++\n",
      " tests/unit/table/test_tensor_table.py              | 313 ++++++++++++++++++++\n",
      " tests/unit/utils/test_utils.py                     |  16 +-\n",
      " tox.ini                                            |  45 ++-\n",
      " 90 files changed, 5427 insertions(+), 946 deletions(-)\n",
      " delete mode 100644 .github/workflows/cpu-models.yml\n",
      " delete mode 100644 .github/workflows/cpu-nvtabular.yml\n",
      " create mode 100644 .github/workflows/cpu-packages.yml\n",
      " delete mode 100644 .github/workflows/cpu-systems.yml\n",
      " create mode 100644 .github/workflows/merlin.yml\n",
      " create mode 100644 .github/workflows/tox.yml\n",
      " create mode 100644 .prettierignore\n",
      " create mode 100644 merlin/core/has_gpu.py\n",
      " create mode 100644 merlin/dag/utils.py\n",
      " create mode 100644 merlin/dispatch/lazy.py\n",
      " create mode 100644 merlin/dtypes/__init__.py\n",
      " create mode 100644 merlin/dtypes/aliases.py\n",
      " create mode 100644 merlin/dtypes/base.py\n",
      " create mode 100644 merlin/dtypes/mapping.py\n",
      " create mode 100644 merlin/dtypes/mappings/__init__.py\n",
      " create mode 100644 merlin/dtypes/mappings/cudf.py\n",
      " create mode 100644 merlin/dtypes/mappings/numpy.py\n",
      " create mode 100644 merlin/dtypes/mappings/pandas.py\n",
      " create mode 100644 merlin/dtypes/mappings/python.py\n",
      " create mode 100644 merlin/dtypes/mappings/tf.py\n",
      " create mode 100644 merlin/dtypes/mappings/torch.py\n",
      " create mode 100644 merlin/dtypes/mappings/triton.py\n",
      " create mode 100644 merlin/dtypes/registry.py\n",
      " create mode 100644 merlin/dtypes/shape.py\n",
      " create mode 100644 merlin/table/__init__.py\n",
      " create mode 100644 merlin/table/conversions.py\n",
      " create mode 100644 merlin/table/cupy_column.py\n",
      " create mode 100644 merlin/table/numpy_column.py\n",
      " create mode 100644 merlin/table/tensor_column.py\n",
      " create mode 100644 merlin/table/tensor_table.py\n",
      " create mode 100644 merlin/table/tensorflow_column.py\n",
      " create mode 100644 merlin/table/torch_column.py\n",
      " create mode 100644 tests/unit/dag/test_dag_utils.py\n",
      " create mode 100644 tests/unit/dispatch/test_lazy_dispatch.py\n",
      " create mode 100644 tests/unit/dtypes/test_module.py\n",
      " create mode 100644 tests/unit/dtypes/test_shape.py\n",
      " create mode 100644 tests/unit/io/test_dataset.py\n",
      " create mode 100644 tests/unit/table/test_convert_column.py\n",
      " create mode 100644 tests/unit/table/test_tensor_column.py\n",
      " create mode 100644 tests/unit/table/test_tensor_table.py\n",
      "Processing /core\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting distributed>=2022.11.1\n",
      "  Downloading distributed-2023.3.2-py3-none-any.whl (956 kB)\n",
      "Collecting fsspec>=2022.7.1\n",
      "  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from merlin-core==0.9.0+86.g0bade49f) (22.0)\n",
      "Requirement already satisfied: pynvml<11.5,>=11.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core==0.9.0+86.g0bade49f) (11.4.1)\n",
      "Collecting dask-cuda>=22.12.0\n",
      "  Downloading dask_cuda-23.2.1-py3-none-any.whl (240 kB)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core==0.9.0+86.g0bade49f) (1.2.5)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core==0.9.0+86.g0bade49f) (3.19.6)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core==0.9.0+86.g0bade49f) (8.0.0)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core==0.9.0+86.g0bade49f) (1.12.0)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core==0.9.0+86.g0bade49f) (4.64.1)\n",
      "Collecting dask>=2022.11.1\n",
      "  Downloading dask-2023.3.2-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core==0.9.0+86.g0bade49f) (0.56.4)\n",
      "Requirement already satisfied: pandas<1.6.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core==0.9.0+86.g0bade49f) (1.3.5)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (2.4.0)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (8.1.3)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (1.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (6.0)\n",
      "Requirement already satisfied: zict>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (2.2.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (0.12.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (6.1)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (3.1.2)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (1.0.0)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (1.26.13)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (2.2.0)\n",
      "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (5.9.4)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from dask-cuda>=22.12.0->merlin-core==0.9.0+86.g0bade49f) (1.22.4)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core==0.9.0+86.g0bade49f) (1.2.0)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core==0.9.0+86.g0bade49f) (0.4.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core==0.9.0+86.g0bade49f) (1.57.0)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core==0.9.0+86.g0bade49f) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (5.2.0)\n",
      "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba>=0.54->merlin-core==0.9.0+86.g0bade49f) (45.2.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core==0.9.0+86.g0bade49f) (0.39.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core==0.9.0+86.g0bade49f) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core==0.9.0+86.g0bade49f) (2.8.2)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=2.1.0->distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10.3->distributed>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (2.1.1)\n",
      "Requirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core==0.9.0+86.g0bade49f) (6.0.4)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core==0.9.0+86.g0bade49f) (4.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.13.0->dask>=2022.11.1->merlin-core==0.9.0+86.g0bade49f) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas<1.6.0dev0,>=1.2.0->merlin-core==0.9.0+86.g0bade49f) (1.14.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core==0.9.0+86.g0bade49f) (4.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core==0.9.0+86.g0bade49f) (6.0.1)\n",
      "Building wheels for collected packages: merlin-core\n",
      "  Building wheel for merlin-core (PEP 517): started\n",
      "  Building wheel for merlin-core (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-core: filename=merlin_core-0.9.0+86.g0bade49f-py3-none-any.whl size=157279 sha256=e16e8d28c5c9e98ab51a6b471aad6a026af2620b4bcdf645915604a7ce52d59c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6r168yrr/wheels/8f/da/8c/c779661788874afaa32fd10abeac6016635956e3bad9940584\n",
      "Successfully built merlin-core\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: dask-cudf 22.8.0a0+304.g6ca81bbc78.dirty requires cupy-cuda118<12,>=9.5.0, which is not installed.\n",
      "ERROR: cudf 22.8.0a0+304.g6ca81bbc78.dirty requires cupy-cuda118<12,>=9.5.0, which is not installed.\n",
      "ERROR: dask-cudf 22.8.0a0+304.g6ca81bbc78.dirty has requirement dask==2022.7.1, but you'll have dask 2023.3.2 which is incompatible.\n",
      "ERROR: dask-cudf 22.8.0a0+304.g6ca81bbc78.dirty has requirement distributed==2022.7.1, but you'll have distributed 2023.3.2 which is incompatible.\n",
      "ERROR: dask-cuda 23.2.1 has requirement dask==2023.1.1, but you'll have dask 2023.3.2 which is incompatible.\n",
      "ERROR: dask-cuda 23.2.1 has requirement distributed==2023.1.1, but you'll have distributed 2023.3.2 which is incompatible.\n",
      "ERROR: cudf 22.8.0a0+304.g6ca81bbc78.dirty has requirement cuda-python<11.7.1,>=11.5, but you'll have cuda-python 11.8.1 which is incompatible.\n",
      "ERROR: cudf 22.8.0a0+304.g6ca81bbc78.dirty has requirement protobuf<3.21.0a0,>=3.20.1, but you'll have protobuf 3.19.6 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: fsspec, dask, distributed, dask-cuda, merlin-core\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.5.0\n",
      "    Uninstalling fsspec-2022.5.0:\n",
      "      Successfully uninstalled fsspec-2022.5.0\n",
      "  Attempting uninstall: dask\n",
      "    Found existing installation: dask 2022.7.1\n",
      "    Uninstalling dask-2022.7.1:\n",
      "      Successfully uninstalled dask-2022.7.1\n",
      "  Attempting uninstall: distributed\n",
      "    Found existing installation: distributed 2022.7.1\n",
      "    Uninstalling distributed-2022.7.1:\n",
      "      Successfully uninstalled distributed-2022.7.1\n",
      "  Attempting uninstall: dask-cuda\n",
      "    Found existing installation: dask-cuda 22.8.0a0+36.g9860cad\n",
      "    Uninstalling dask-cuda-22.8.0a0+36.g9860cad:\n",
      "      Successfully uninstalled dask-cuda-22.8.0a0+36.g9860cad\n",
      "  Attempting uninstall: merlin-core\n",
      "    Found existing installation: merlin-core 0.10.0\n",
      "    Uninstalling merlin-core-0.10.0:\n",
      "      Successfully uninstalled merlin-core-0.10.0\n",
      "Successfully installed dask-2023.3.2 dask-cuda-23.2.1 distributed-2023.3.2 fsspec-2023.3.0 merlin-core-0.9.0+86.g0bade49f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was feaf748 adding async tf strategy for gpu memory (#264)\n",
      "Switched to branch 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/systems\n",
      "   20bb231..dc4bf32  main          -> origin/main\n",
      " * [new branch]      dataset-cpu-default-None -> origin/dataset-cpu-default-None\n",
      "   8650b6c..398ab3d  gh-pages      -> origin/gh-pages\n",
      " * [new branch]      release-23.02 -> origin/release-23.02\n",
      " * [new tag]         v23.02.00     -> v23.02.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 20bb231..dc4bf32\n",
      "Fast-forward\n",
      " .github/ISSUE_TEMPLATE/bug-report.md               |  17 +-\n",
      " .github/ISSUE_TEMPLATE/documentation-request.md    |  12 +-\n",
      " .github/ISSUE_TEMPLATE/feature-request.md          |   5 +-\n",
      " .github/ISSUE_TEMPLATE/submit-question.md          |   3 +-\n",
      " .github/ISSUE_TEMPLATE/task.md                     |   5 +-\n",
      " .github/release-drafter.yml                        |  44 +-\n",
      " .github/workflows/cpu-ci.yml                       | 133 ++--\n",
      " .github/workflows/docs-preview-pr.yaml             |   2 +-\n",
      " .github/workflows/docs-sched-rebuild.yaml          |   7 +-\n",
      " .github/workflows/gpu-ci.yml                       |  36 +-\n",
      " .github/workflows/lint.yaml                        |  12 +-\n",
      " .github/workflows/postmerge-cpu.yml                |  96 +++\n",
      " .github/workflows/postmerge-gpu.yml                |  27 +\n",
      " .github/workflows/release-drafter.yml              |   2 +-\n",
      " .pre-commit-config.yaml                            |  71 +-\n",
      " .prettierignore                                    |   2 +\n",
      " CLA.md                                             |   9 +-\n",
      " CONTRIBUTING.md                                    |   2 +-\n",
      " README.md                                          |   2 +-\n",
      " ci/pr.gpu.Jenkinsfile                              |   2 +-\n",
      " docs/README.md                                     |  53 +-\n",
      " ...ing-An-Implicit-Model-With-Merlin-Systems.ipynb |   5 +-\n",
      " ...ving-An-XGboost-Model-With-Merlin-Systems.ipynb |   5 +-\n",
      " ...erving-Ranking-Models-With-Merlin-Systems.ipynb |   5 +-\n",
      " merlin/systems/dag/__init__.py                     |   2 -\n",
      " merlin/systems/dag/dictarray.py                    | 345 ----------\n",
      " merlin/systems/dag/ensemble.py                     |   2 +-\n",
      " merlin/systems/dag/node.py                         |  29 +-\n",
      " merlin/systems/dag/op_runner.py                    |  68 --\n",
      " merlin/systems/dag/ops/__init__.py                 |  22 +-\n",
      " merlin/systems/dag/ops/faiss.py                    | 109 +--\n",
      " merlin/systems/dag/ops/feast.py                    | 110 +---\n",
      " merlin/systems/dag/ops/fil.py                      |  74 +--\n",
      " merlin/systems/dag/ops/implicit.py                 |  84 +--\n",
      " merlin/systems/dag/ops/operator.py                 | 216 +-----\n",
      " merlin/systems/dag/ops/pytorch.py                  |  24 +-\n",
      " merlin/systems/dag/ops/session_filter.py           |  72 +-\n",
      " merlin/systems/dag/ops/softmax_sampling.py         |  61 +-\n",
      " merlin/systems/dag/ops/tensorflow.py               | 140 ++--\n",
      " merlin/systems/dag/ops/unroll_features.py          |  36 +-\n",
      " merlin/systems/dag/ops/workflow.py                 |  24 +-\n",
      " merlin/systems/dag/runtimes/triton/ops/fil.py      |  43 +-\n",
      " merlin/systems/dag/runtimes/triton/ops/operator.py |  84 ++-\n",
      " merlin/systems/dag/runtimes/triton/ops/pytorch.py  |  11 +-\n",
      " .../systems/dag/runtimes/triton/ops/tensorflow.py  |  25 +-\n",
      " merlin/systems/dag/runtimes/triton/ops/workflow.py | 154 ++++-\n",
      " merlin/systems/dag/runtimes/triton/runtime.py      |  29 +-\n",
      " merlin/systems/triton/__init__.py                  | 118 ++--\n",
      " merlin/systems/triton/conversions.py               |  58 +-\n",
      " merlin/systems/triton/export.py                    | 729 +--------------------\n",
      " merlin/systems/triton/models/executor_model.py     |  38 +-\n",
      " merlin/systems/triton/models/oprunner_model.py     | 129 ----\n",
      " merlin/systems/triton/models/pytorch_model.py      | 139 ++--\n",
      " merlin/systems/triton/models/workflow_model.py     |  52 +-\n",
      " merlin/systems/triton/utils.py                     |  50 +-\n",
      " merlin/systems/workflow/base.py                    |   5 -\n",
      " merlin/systems/workflow/tensorflow.py              |   8 +-\n",
      " pytest.ini                                         |   7 +-\n",
      " tests/conftest.py                                  |  28 +-\n",
      " ...erving_an_implicit_model_with_merlin_systems.py |   4 +-\n",
      " ...serving_an_xgboost_model_with_merlin_systems.py |   4 +-\n",
      " tests/integration/tf/test_transformer_model.py     | 105 +++\n",
      " .../systems/dag/test_column.py => test_passing.py} |  15 +-\n",
      " tests/unit/systems/dag/ops/test_ops.py             | 101 ++-\n",
      " .../dag/runtimes/local/ops/fil/test_lightgbm.py    |  15 +-\n",
      " .../dag/runtimes/local/ops/fil/test_sklearn.py     |  15 +-\n",
      " .../dag/runtimes/local/ops/fil/test_xgboost.py     |  15 +-\n",
      " .../runtimes/local/ops/nvtabular/test_ensemble.py  |  10 +-\n",
      " .../runtimes/local/ops/tensorflow/test_ensemble.py |  35 +-\n",
      " .../dag/runtimes/local/ops/torch/test_op.py        |   6 +-\n",
      " .../triton/ops/fil/test_lightgbm_triton.py         |  11 +-\n",
      " .../runtimes/triton/ops/fil/test_sklearn_triton.py |   4 +-\n",
      " .../runtimes/triton/ops/fil/test_xgboost_triton.py |   4 +-\n",
      " .../dag/runtimes/triton/ops/torch/test_op.py       |   4 +-\n",
      " .../runtimes/triton/ops/workflow/test_ensemble.py  |  69 +-\n",
      " .../systems/dag/runtimes/triton/test_triton.py     |  21 +-\n",
      " tests/unit/systems/dag/test_dict_array.py          |  76 ---\n",
      " tests/unit/systems/dag/test_ensemble.py            |   4 +-\n",
      " tests/unit/systems/dag/test_executors.py           |  12 +-\n",
      " tests/unit/systems/dag/test_op_runner.py           | 210 ------\n",
      " tests/unit/systems/ops/faiss/test_executor.py      |  25 +-\n",
      " tests/unit/systems/ops/feast/test_op.py            |  76 +--\n",
      " tests/unit/systems/ops/fil/test_ensemble.py        |   4 +-\n",
      " tests/unit/systems/ops/fil/test_forest.py          |  43 --\n",
      " tests/unit/systems/ops/implicit/test_executor.py   |   4 +-\n",
      " tests/unit/systems/ops/implicit/test_op.py         |  51 +-\n",
      " tests/unit/systems/ops/tf/test_ensemble.py         |  15 +-\n",
      " tests/unit/systems/ops/tf/test_op.py               |   6 +-\n",
      " tests/unit/systems/utils/ops.py                    |  13 +-\n",
      " tests/unit/systems/utils/tf.py                     |  65 +-\n",
      " tests/unit/test_export.py                          |  77 ---\n",
      " tox.ini                                            |  42 +-\n",
      " 92 files changed, 1603 insertions(+), 3240 deletions(-)\n",
      " create mode 100644 .github/workflows/postmerge-cpu.yml\n",
      " create mode 100644 .github/workflows/postmerge-gpu.yml\n",
      " create mode 100644 .prettierignore\n",
      " delete mode 100644 merlin/systems/dag/dictarray.py\n",
      " delete mode 100644 merlin/systems/dag/op_runner.py\n",
      " delete mode 100644 merlin/systems/triton/models/oprunner_model.py\n",
      " create mode 100644 tests/integration/tf/test_transformer_model.py\n",
      " rename tests/{unit/systems/dag/test_column.py => test_passing.py} (66%)\n",
      " delete mode 100644 tests/unit/systems/dag/test_dict_array.py\n",
      " delete mode 100644 tests/unit/systems/dag/test_op_runner.py\n",
      " delete mode 100644 tests/unit/test_export.py\n",
      "Processing /systems\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: merlin-core>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-systems==23.2.0+14.gdc4bf32) (0.9.0+86.g0bade49f)\n",
      "Requirement already satisfied: treelite==2.4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-systems==23.2.0+14.gdc4bf32) (2.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.10 in /usr/local/lib/python3.8/dist-packages (from merlin-systems==23.2.0+14.gdc4bf32) (2.28.1)\n",
      "Requirement already satisfied: nvtabular>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-systems==23.2.0+14.gdc4bf32) (1.6.0+55.gcdc5ff12)\n",
      "Requirement already satisfied: treelite-runtime==2.4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-systems==23.2.0+14.gdc4bf32) (2.4.0)\n",
      "Requirement already satisfied: distributed>=2022.11.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (2023.3.2)\n",
      "Requirement already satisfied: fsspec>=2022.7.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (2023.3.0)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (4.64.1)\n",
      "Requirement already satisfied: dask>=2022.11.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (2023.3.2)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.2.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.12.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (8.0.0)\n",
      "Requirement already satisfied: dask-cuda>=22.12.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (23.2.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (22.0)\n",
      "Requirement already satisfied: pandas<1.6.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.3.5)\n",
      "Requirement already satisfied: pynvml<11.5,>=11.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (11.4.1)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (0.56.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from treelite==2.4.0->merlin-systems==23.2.0+14.gdc4bf32) (1.9.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from treelite==2.4.0->merlin-systems==23.2.0+14.gdc4bf32) (1.22.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.10->merlin-systems==23.2.0+14.gdc4bf32) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.10->merlin-systems==23.2.0+14.gdc4bf32) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.10->merlin-systems==23.2.0+14.gdc4bf32) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.10->merlin-systems==23.2.0+14.gdc4bf32) (1.26.13)\n",
      "Requirement already satisfied: merlin-dataloader>=0.0.2 in /usr/local/lib/python3.8/dist-packages (from nvtabular>=1.0.0->merlin-systems==23.2.0+14.gdc4bf32) (0.0.4)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (8.1.3)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (6.0)\n",
      "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (5.9.4)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.0.0)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (3.1.2)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (2.2.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.7.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (0.12.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (6.1)\n",
      "Requirement already satisfied: zict>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (2.2.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.0.4)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (2.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (5.2.0)\n",
      "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.3.0)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.2.0)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (0.4.3)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.57.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (2.8.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (45.2.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (0.39.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10.3->distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (2.1.1)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=2.1.0->distributed>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.13.0->dask>=2022.11.1->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (3.11.0)\n",
      "Requirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (6.0.4)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (4.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas<1.6.0dev0,>=1.2.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (1.14.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-systems==23.2.0+14.gdc4bf32) (4.0.0)\n",
      "Building wheels for collected packages: merlin-systems\n",
      "  Building wheel for merlin-systems (PEP 517): started\n",
      "  Building wheel for merlin-systems (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-systems: filename=merlin_systems-23.2.0+14.gdc4bf32-py3-none-any.whl size=87231 sha256=d672c238b8424e2b6d985835c54f6ed4610bebd04c5bd2344897141a1d10bc5f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yhu7li4o/wheels/1f/e9/71/1b0c6295aa7f4b37cb70292d96d87d9f38204674e6531bdda6\n",
      "Successfully built merlin-systems\n",
      "Installing collected packages: merlin-systems\n",
      "  Attempting uninstall: merlin-systems\n",
      "    Found existing installation: merlin-systems 0.9.0\n",
      "    Uninstalling merlin-systems-0.9.0:\n",
      "      Successfully uninstalled merlin-systems-0.9.0\n",
      "Successfully installed merlin-systems-23.2.0+14.gdc4bf32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was fd5d3fc Use tf.function for list column operations (#89)\n",
      "Switched to branch 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/dataloader\n",
      "   5b3fe46..020e538  main                   -> origin/main\n",
      " * [new branch]      chore/comprehensive-shapes -> origin/chore/comprehensive-shapes\n",
      " * [new branch]      chore/packages-action  -> origin/chore/packages-action\n",
      " * [new branch]      collabify_examples     -> origin/collabify_examples\n",
      " * [new branch]      feature/embedding-tags -> origin/feature/embedding-tags\n",
      "   9cfee7f..2ddeeec  gh-pages               -> origin/gh-pages\n",
      " * [new branch]      release-23.02          -> origin/release-23.02\n",
      " * [new tag]         v23.02.01              -> v23.02.01\n",
      " * [new tag]         v23.02.00              -> v23.02.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 5b3fe46..020e538\n",
      "Fast-forward\n",
      " .github/workflows/cpu-ci.yml                       |  81 -----\n",
      " .github/workflows/cpu-packages.yml                 | 125 +++++++\n",
      " .github/workflows/docs-sched-rebuild.yaml          |   7 +-\n",
      " .pre-commit-config.yaml                            |  14 +-\n",
      " ci/pr.gpu.Jenkinsfile                              |  44 +++\n",
      " docs/README.md                                     |  28 +-\n",
      " examples/01a-Getting-started-Tensorflow.ipynb      |   5 +-\n",
      " examples/01b-Getting-started-Pytorch.ipynb         |   5 +-\n",
      " .../02-Multi-GPU-Tensorflow-with-Horovod.ipynb     | 371 +++++++++++++++++++++\n",
      " merlin/dataloader/jax.py                           |  33 +-\n",
      " merlin/dataloader/loader_base.py                   | 312 +++++++----------\n",
      " merlin/dataloader/ops/embeddings/embedding_op.py   |   4 +-\n",
      " merlin/dataloader/tensorflow.py                    |  79 +----\n",
      " merlin/dataloader/torch.py                         |  71 ++--\n",
      " merlin/dataloader/utils/tf/tf_trainer.py           |   2 +-\n",
      " tests/conftest.py                                  |   2 +-\n",
      " .../test_multi_GPU_with_horovod_and_tensorflow.py  |  28 ++\n",
      " tests/unit/dataloader/test_jax_dataloader.py       |  29 +-\n",
      " tests/unit/dataloader/test_tf_dataloader.py        | 205 +++++-------\n",
      " tests/unit/dataloader/test_tf_embeddings.py        |  24 +-\n",
      " tests/unit/dataloader/test_torch_dataloader.py     | 195 ++++++++---\n",
      " tests/unit/dataloader/test_torch_embeddings.py     |  12 +-\n",
      " tox.ini                                            |   1 +\n",
      " 23 files changed, 1050 insertions(+), 627 deletions(-)\n",
      " create mode 100644 .github/workflows/cpu-packages.yml\n",
      " create mode 100644 ci/pr.gpu.Jenkinsfile\n",
      " create mode 100644 examples/02-Multi-GPU-Tensorflow-with-Horovod.ipynb\n",
      " create mode 100644 tests/examples/test_multi_GPU_with_horovod_and_tensorflow.py\n",
      "Processing /dataloader\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: merlin-core>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from merlin-dataloader==23.2.0+12.g020e538) (0.9.0+86.g0bade49f)\n",
      "Requirement already satisfied: distributed>=2022.11.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (2023.3.2)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (4.64.1)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (0.56.4)\n",
      "Requirement already satisfied: pynvml<11.5,>=11.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (11.4.1)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (8.0.0)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.2.5)\n",
      "Requirement already satisfied: pandas<1.6.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.3.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (22.0)\n",
      "Requirement already satisfied: dask>=2022.11.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (2023.3.2)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.12.0)\n",
      "Requirement already satisfied: fsspec>=2022.7.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (2023.3.0)\n",
      "Requirement already satisfied: dask-cuda>=22.12.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (23.2.1)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (3.19.6)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (3.1.2)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.0.0)\n",
      "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (5.9.4)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (2.4.0)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.26.13)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.0.4)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (6.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (0.12.0)\n",
      "Requirement already satisfied: zict>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (2.2.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (6.1)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (2.2.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.7.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba>=0.54->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (45.2.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.22.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (5.2.0)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (0.4.3)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (2.8.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.57.0)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10.3->distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (2.1.1)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=2.1.0->distributed>=2022.11.1->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.54->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (3.11.0)\n",
      "Requirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (6.0.4)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (4.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas<1.6.0dev0,>=1.2.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (1.14.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.8.0->merlin-dataloader==23.2.0+12.g020e538) (4.0.0)\n",
      "Building wheels for collected packages: merlin-dataloader\n",
      "  Building wheel for merlin-dataloader (PEP 517): started\n",
      "  Building wheel for merlin-dataloader (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-dataloader: filename=merlin_dataloader-23.2.0+12.g020e538-py3-none-any.whl size=39504 sha256=dd55e78e35ccb7f7045fd5ad52cd027447005749dbfadccf961fb0a707b1cf92\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z7pw5lr4/wheels/8c/19/5b/15dc04f5a977f6a7f73ed66c91996a687b1d9e3154a4765536\n",
      "Successfully built merlin-dataloader\n",
      "Installing collected packages: merlin-dataloader\n",
      "  Attempting uninstall: merlin-dataloader\n",
      "    Found existing installation: merlin-dataloader 0.0.4\n",
      "    Uninstalling merlin-dataloader-0.0.4:\n",
      "      Successfully uninstalled merlin-dataloader-0.0.4\n",
      "Successfully installed merlin-dataloader-23.2.0+12.g020e538\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /models && git checkout main && git pull && pip install .\n",
    "cd /nvtabular && git checkout main && git pull && pip install .\n",
    "cd /core && git checkout main && git pull && pip install .\n",
    "cd /systems && git checkout main && git pull && pip install .\n",
    "cd /dataloader && git checkout main && git pull && pip install .\n",
    "cd /workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a556f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions anda\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697d1452",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_models-transformers-net-item-prediction/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Transformer-based architecture for next-item prediction task\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this use case we will train a Transformer-based architecture for next-item prediction task.\n",
    "\n",
    "**Note, the data for this notebook will be automatically downloaded to the folder specified in the cells below.**\n",
    "\n",
    "We will use the [booking.com dataset](https://github.com/bookingcom/ml-dataset-mdt) to train a session-based model. The dataset contains 1,166,835 of anonymized hotel reservations in the train set and 378,667 in the test set. Each reservation is a part of a customer's trip (identified by `utrip_id`) which includes consecutive reservations.\n",
    "\n",
    "We will reshape the data to organize it into 'sessions'. Each session will be a full customer itinerary in chronological order. The goal will be to predict the city_id of the final reservation of each trip.\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Training a Transformer-based architecture for next-item prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cccd005",
   "metadata": {},
   "source": [
    "## Downloading and preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0b619b",
   "metadata": {},
   "source": [
    "We will download the dataset using a functionality provided by merlin models. The dataset can be found on GitHub [here](https://github.com/bookingcom/ml-dataset-mdt).\n",
    "\n",
    "**Read more about libraries used in the import statements below**\n",
    "\n",
    "- [get_lib](https://github.com/NVIDIA-Merlin/core/blob/main/merlin/core/dispatch.py)\n",
    "- [get_booking](https://github.com/NVIDIA-Merlin/models/tree/main/merlin/datasets/ecommerce)\n",
    "- [nvtabular](https://github.com/NVIDIA-Merlin/NVTabular/tree/main/nvtabular)\n",
    "- [nvtabular ops](https://github.com/NVIDIA-Merlin/NVTabular/tree/main/nvtabular/ops)\n",
    "- [schema tags](https://github.com/NVIDIA-Merlin/core/blob/main/merlin/schema/tags.py)\n",
    "- [merlin models tensorflow](https://github.com/NVIDIA-Merlin/models/tree/main/merlin/models/tf)\n",
    "- [get_booking](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/datasets/ecommerce/booking/dataset.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d9dccc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 03:52:21.580404: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 03:52:22.797459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:52:22.797892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:52:22.798053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: sparse_operation_kit is imported\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.1.4-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Initialize finished, communication tool: horovod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 03:52:23.163225: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 03:52:23.164156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:52:23.164392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:52:23.164554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:52:23.926192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:52:23.926407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:52:23.926571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:52:23.926682: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-03-31 03:52:23.926694: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-03-31 03:52:23.926753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24576 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data import complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.SESSION_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.SESSION: 'session'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Resetting the TF memory allocation to not be 50% by default. \n",
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "from merlin.core.dispatch import get_lib\n",
    "from merlin.datasets.ecommerce import get_booking\n",
    "\n",
    "import numpy as np\n",
    "import cudf\n",
    "\n",
    "from nvtabular import *\n",
    "from nvtabular import ops\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "import merlin.models.tf as mm\n",
    "\n",
    "get_booking('/workspace/data')\n",
    "train = get_lib().read_csv('/workspace/data/train_set.csv', parse_dates=['checkin', 'checkout'])\n",
    "\n",
    "print('Training data import complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b7224",
   "metadata": {},
   "source": [
    "Each reservation has a unique `utrip_id`. During each trip a customer vists several destinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "192a5727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id    checkin   checkout  city_id device_class  affiliate_id  \\\n",
      "0  1000027 2016-08-13 2016-08-14     8183      desktop          7168   \n",
      "1  1000027 2016-08-14 2016-08-16    15626      desktop          7168   \n",
      "2  1000027 2016-08-16 2016-08-18    60902      desktop          7168   \n",
      "3  1000027 2016-08-18 2016-08-21    30628      desktop           253   \n",
      "4  1000033 2016-04-09 2016-04-11    38677       mobile           359   \n",
      "\n",
      "  booker_country hotel_country   utrip_id  \n",
      "0        Elbonia        Gondal  1000027_1  \n",
      "1        Elbonia        Gondal  1000027_1  \n",
      "2        Elbonia        Gondal  1000027_1  \n",
      "3        Elbonia        Gondal  1000027_1  \n",
      "4         Gondal  Cobra Island  1000033_1  \n"
     ]
    }
   ],
   "source": [
    "# When displaying cudf dataframes use print() or display(), otherwise Jupyter creates hidden copies.\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecc2d94",
   "metadata": {},
   "source": [
    "We will train on sequences of `city_id` and `booker_country` and based on this information, our model will attempt to predict the next `city_id` (the next hop in the journey).\n",
    "\n",
    "We will train a transformer model that can work with sequences of variable length within a batch. This functionality is provided to us out of the box and doesn't require any changes to the architecture. Thanks to it we do not have to pad or trim our sequences to any particular length -- our model can make effective use of all of the data!\n",
    "\n",
    "*With one exception.* For a masked language model that we will be training, we need to discard sequences that are shorter than two hops. This makes sense as there is nothing our model could learn if it was only presented with an itinerary with a single destination on it!\n",
    "\n",
    "Let us begin by splitting the data into a train and validation set based on trip ID.\n",
    "\n",
    "Let's see how many unique trips there are in the dataset. Also, let us shuffle the trips along the way so that our validation set consists of a random sample of our train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23bef6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique trips is : 217686\n"
     ]
    }
   ],
   "source": [
    "# Unique trip ids.\n",
    "utrip_ids = train.sample(frac=1).utrip_id.unique()\n",
    "print('Number of unique trips is :', len(utrip_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eca1f6",
   "metadata": {},
   "source": [
    "Now let's assign data to our train and validation sets. Furthermore, we sort the data by `utrip_id` and `checkin`. This way we ensure our sequences of visited `city_ids` will be in proper order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4be8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cudf.from_pandas(\n",
    "    train.to_pandas().join(train.to_pandas().groupby('utrip_id').size().rename('num_examples'), on='utrip_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62e95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.num_examples > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da67df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.checkin = train.checkin.astype('int')\n",
    "train.checkout = train.checkout.astype('int')\n",
    "\n",
    "train_set_utrip_ids = utrip_ids[:int(0.8 * utrip_ids.shape[0])]\n",
    "validation_set_utrip_ids = utrip_ids[int(0.8 * utrip_ids.shape[0]):]\n",
    "\n",
    "train_set = train[train.utrip_id.isin(train_set_utrip_ids)].sort_values(['utrip_id', 'checkin'])\n",
    "validation_set = train[train.utrip_id.isin(validation_set_utrip_ids)].sort_values(['utrip_id', 'checkin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc3992",
   "metadata": {},
   "source": [
    "##  Preprocessing with NVTabular\n",
    "\n",
    "We can now begin with data preprocessing.\n",
    "\n",
    "We will combine trips into \"sessions\", discard trips that are too short and calculate total trip length.\n",
    "\n",
    "We will use NVTabular for this work. It offers optimized tabular data preprocessing operators that run on the GPU. If you would like to learn more about the NVTabular library, please take a look [here](https://github.com/NVIDIA-Merlin/NVTabular).\n",
    "\n",
    "Read more about the [Merlin's Dataset API](https://github.com/NVIDIA-Merlin/core/blob/main/merlin/io/dataset.py)  \n",
    "Read more about how [parquet files are read in and processed by Merlin](https://github.com/NVIDIA-Merlin/core/blob/main/merlin/io/parquet.py)  \n",
    "Read more about [Tags](https://github.com/NVIDIA-Merlin/core/blob/main/merlin/schema/tags.py)  \n",
    "- [schema_select_by_tag](https://github.com/NVIDIA-Merlin/core/blob/main/merlin/schema/schema.py)  \n",
    "\n",
    "Read more about [NVTabular Workflows](https://github.com/NVIDIA-Merlin/NVTabular/blob/main/nvtabular/workflow/workflow.py)  \n",
    "- [fit_transform](https://github.com/NVIDIA-Merlin/NVTabular/blob/main/nvtabular/workflow/workflow.py)\n",
    "- [transform](https://github.com/NVIDIA-Merlin/NVTabular/blob/main/nvtabular/workflow/workflow.py)  \n",
    "\n",
    "Read more about the [NVTabular Operators]()  \n",
    "- [Categorify](https://github.com/NVIDIA-Merlin/NVTabular/blob/main/nvtabular/ops/categorify.py)\n",
    "- [AddTags](https://github.com/NVIDIA-Merlin/NVTabular/blob/main/nvtabular/ops/add_metadata.py)\n",
    "- [LambdaOp](https://github.com/NVIDIA-Merlin/NVTabular/blob/main/nvtabular/ops/lambdaop.py)\n",
    "- [Rename](https://github.com/NVIDIA-Merlin/NVTabular/blob/main/nvtabular/ops/rename.py)\n",
    "- [Filter](https://github.com/NVIDIA-Merlin/NVTabular/blob/main/nvtabular/ops/filter.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3435af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_dataset = Dataset(train_set)\n",
    "validation_set_dataset = Dataset(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60bd5e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = (['city_id']) >> ops.Categorify(start_index=1)  \n",
    "\n",
    "groupby_features = categorical_features + ['utrip_id', 'checkin'] >> ops.Groupby(\n",
    "    groupby_cols=['utrip_id'],\n",
    "    aggs={\n",
    "        'city_id': ['list'],\n",
    "    },\n",
    "    sort_cols=\"checkin\"\n",
    ")\n",
    "\n",
    "list_features = (\n",
    "            groupby_features['city_id_list'] >> ops.AddTags([Tags.SEQUENCE])\n",
    ")\n",
    "\n",
    "# Filter out sessions with less than 2 interactions \n",
    "MINIMUM_SESSION_LENGTH = 2\n",
    "features = list_features >>  ops.AddTags([Tags.CATEGORICAL])\n",
    "filtered_sessions = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6105767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(filtered_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edcbcdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_processed = wf.fit_transform(train_set_dataset)\n",
    "validation_set_processed = wf.transform(validation_set_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a6675",
   "metadata": {},
   "source": [
    "Our data consists of a sequence of visited `city_ids`, a sequence of `booker_countries` (represented as integer categories) and a `city_id_count` column (which contains the count of visited cities in a trip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dee6b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8239, 157, 2279, 2098]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[64, 1161, 88, 619, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[8, 7, 25, 1051, 66, 53, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1033, 758, 141, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3604, 263, 663, 251, 360]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  city_id_list\n",
       "0      [8239, 157, 2279, 2098]\n",
       "1      [64, 1161, 88, 619, 64]\n",
       "2  [8, 7, 25, 1051, 66, 53, 4]\n",
       "3          [1033, 758, 141, 4]\n",
       "4   [3604, 263, 663, 251, 360]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_processed.compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89cc3a0",
   "metadata": {},
   "source": [
    "We are now ready to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95c794",
   "metadata": {},
   "source": [
    "Here is the schema of the data that our model will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4813456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_id_list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>.//categories/unique.city_id.parquet</td>\n",
       "      <td>0</td>\n",
       "      <td>37203</td>\n",
       "      <td>city_id</td>\n",
       "      <td>37204</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'city_id_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 1, 'cat_path': './/categories/unique.city_id.parquet', 'domain': {'min': 0, 'max': 37203, 'name': 'city_id'}, 'embedding_sizes': {'cardinality': 37204, 'dimension': 512}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_schema = train_set_processed.schema.select_by_tag(Tags.SEQUENCE)\n",
    "seq_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a87439c",
   "metadata": {},
   "source": [
    "Align the schema of train and validation datasets with the model's schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b90424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_processed.schema = seq_schema\n",
    "validation_set_processed.schema = seq_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d422833",
   "metadata": {},
   "source": [
    "Let's also identify the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e34a3a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'city_id_list'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train_set_processed.schema.select_by_tag(Tags.SEQUENCE).column_names[0]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8adad",
   "metadata": {},
   "source": [
    "## Constructing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb17fe",
   "metadata": {},
   "source": [
    "Let's construct our model.\n",
    "\n",
    "We can specify various hyperparameters, such as the number of heads and number of layers to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a460e4c",
   "metadata": {},
   "source": [
    "For the transformer portion of our model, we will use the `XLNet` architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf02dc",
   "metadata": {},
   "source": [
    "Later, when we run the `fit` method on our model, we will specify the `masking_probability` of `0.3` and link it to the transformer block defined in out model. Through the combination of these parameters, our model will train on sequences where any given timestep will be masked with a probability of 0.3 and it will be our model's training task to infer the target value for that step!\n",
    "\n",
    "To summarize, Masked Language Modeling is implemented by:\n",
    "\n",
    "* `SequenceMaskRandom()` - Used as a pre for model.fit(), it randomly selects items from the sequence to be masked for prediction as targets, by using Keras masking. This block also adds the necessary configuration to the specified `transformer` block so as it\n",
    "is pre-configured with the necessary layers needed to prepare the inputs to the HuggingFace transformer layer and to post-process its outputs. For example, one pre-processing operation is to replace the input embeddings at masked positions for prediction by a dummy trainable embedding, to avoid leakage of the targets.\n",
    "\n",
    "\n",
    "**Read more about the apis used to construct models** \n",
    "- [blocks](https://github.com/NVIDIA-Merlin/models/tree/main/merlin/models/tf/blocks)\n",
    "- [MLPBlock](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/blocks/mlp.py)\n",
    "- [InputBlockV2](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/inputs/base.py)\n",
    "- [Embeddings](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/inputs/embedding.py)\n",
    "- [XLNetBlock](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transformers/block.py)\n",
    "- [CategoricalOutput](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/outputs/classification.py)\n",
    "- [.schema.select_by_name](https://github.com/NVIDIA-Merlin/core/blob/main/merlin/schema/schema.py)\n",
    "- [.schema.select_by_tag](https://github.com/NVIDIA-Merlin/core/blob/main/merlin/schema/schema.py)\n",
    "- [model.compile()](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/models/base.py)\n",
    "- [model.fit()](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/models/base.py)\n",
    "- [model.evaluate()](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/models/base.py)\n",
    "- [mm.SequenceMaskRandom](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transforms/sequence.py)\n",
    "- [mm.SequenceMaskLast](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transforms/sequence.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cddfd424",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel=48\n",
    "mlp_block = mm.MLPBlock(\n",
    "                [128,dmodel],\n",
    "                activation='relu',\n",
    "                no_activation_last_layer=True,\n",
    "            )\n",
    "transformer_block = mm.XLNetBlock(d_model=dmodel, n_head=4, n_layer=2)\n",
    "model = mm.Model(\n",
    "    mm.InputBlockV2(\n",
    "        seq_schema,\n",
    "        embeddings=mm.Embeddings(\n",
    "            train_set_processed.schema.select_by_tag(Tags.CATEGORICAL), sequence_combiner=None\n",
    "        ),\n",
    "    ),\n",
    "    mlp_block,\n",
    "    transformer_block,\n",
    "    mm.CategoricalOutput(\n",
    "        train_set_processed.schema.select_by_name(target),\n",
    "        default_loss=\"categorical_crossentropy\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac975cd",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65d28c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "2023-03-31 03:52:31.404040: I tensorflow/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['model/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/xl_net_block/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/xl_net_block/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask/GatherV2:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/xl_net_block/prepare_transformer_inputs_4/RaggedToTensor_1/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/xl_net_block/sequential_block_5/replace_masked_embeddings/RaggedWhere/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model/xl_net_block/sequential_block_5/replace_masked_embeddings/RaggedWhere/Reshape_2:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/xl_net_block/sequential_block_5/replace_masked_embeddings/RaggedWhere/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/xl_net_block/sequential_block_5/replace_masked_embeddings/RaggedWhere/RaggedTile_2/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/xl_net_block/sequential_block_5/replace_masked_embeddings/RaggedWhere/RaggedTile_2/Reshape_2:0\", shape=(None, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/xl_net_block/sequential_block_5/replace_masked_embeddings/RaggedWhere/RaggedTile_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['model/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 03:52:40.595669: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model/xl_net_block/sequential_block_5/replace_masked_embeddings/RaggedWhere/Assert/AssertGuard/branch_executed/_31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720/2720 [==============================] - 67s 21ms/step - loss: 7.5283 - recall_at_10: 0.1682 - mrr_at_10: 0.0703 - ndcg_at_10: 0.0932 - map_at_10: 0.0703 - precision_at_10: 0.0168 - regularization_loss: 0.0000e+00 - loss_batch: 7.5266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc8e9716e50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(run_eagerly=False, optimizer='adam', loss=\"categorical_crossentropy\")\n",
    "model.fit(train_set_processed, batch_size=64, epochs=1, pre=mm.SequenceMaskRandom(schema=seq_schema, target=target, masking_prob=0.3, transformer=transformer_block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb7d207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(\n",
      "  (_feature_shapes): Dict(\n",
      "    (city_id_list): TensorShape([64, None, 1])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (city_id_list): tf.int64\n",
      "  )\n",
      "), because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (city_id_list): TensorShape([64, None, 1])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (city_id_list): tf.int64\n",
      "  )\n",
      "), because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (city_id_list): TensorShape([64, None, 1])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (city_id_list): tf.int64\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, sequence_mask_random_layer_call_fn, sequence_mask_random_layer_call_and_return_conditional_losses, prepare_list_features_layer_call_fn while saving (showing 5 of 86). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp__h2ob6y/model.savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp__h2ob6y/model.savedmodel/assets\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/models/tf/utils/tf_utils.py:100: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config[key] = tf.keras.utils.serialize_keras_object(maybe_value)\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py:288: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config[i] = tf.keras.utils.serialize_keras_object(layer)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/saving/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(\n",
      "  (_feature_shapes): Dict(\n",
      "    (city_id_list): TensorShape([64, None, 1])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (city_id_list): tf.int64\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(\n",
      "  (_feature_shapes): Dict(\n",
      "    (city_id_list): TensorShape([64, None, 1])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (city_id_list): tf.int64\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (city_id_list): TensorShape([64, None, 1])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (city_id_list): tf.int64\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (city_id_list): TensorShape([64, None, 1])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (city_id_list): tf.int64\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (city_id_list): TensorShape([64, None, 1])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (city_id_list): tf.int64\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (city_id_list): TensorShape([64, None, 1])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (city_id_list): tf.int64\n",
      "  )\n",
      "), because it is not built.\n",
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, sequence_mask_random_layer_call_fn, sequence_mask_random_layer_call_and_return_conditional_losses, prepare_list_features_layer_call_fn while saving (showing 5 of 86). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel/assets\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/models/tf/utils/tf_utils.py:100: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config[key] = tf.keras.utils.serialize_keras_object(maybe_value)\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py:288: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config[i] = tf.keras.utils.serialize_keras_object(layer)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/saving/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from merlin.systems.dag.ops.tensorflow import PredictTensorflow\n",
    "from merlin.systems.dag.ensemble import Ensemble\n",
    "from merlin.systems.dag.ops.workflow import TransformWorkflow\n",
    "\n",
    "inf_ops = wf.input_schema.column_names >> TransformWorkflow(wf) >> PredictTensorflow(model)\n",
    "\n",
    "ensemble = Ensemble(inf_ops, wf.input_schema)\n",
    "ensemble.export('/workspace/models_for_benchmarking');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fab503b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x7fc8ead8b2b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0331 03:54:54.819512 643 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fee32000000' with size 268435456\n",
      "I0331 03:54:54.819824 643 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "I0331 03:54:54.821984 643 model_lifecycle.cc:459] loading: executor_model:1\n",
      "I0331 03:54:54.822004 643 model_lifecycle.cc:459] loading: 0_transformworkflowtriton:1\n",
      "I0331 03:54:54.822018 643 model_lifecycle.cc:459] loading: 1_predicttensorflowtriton:1\n",
      "I0331 03:54:55.013608 643 tensorflow.cc:2536] TRITONBACKEND_Initialize: tensorflow\n",
      "I0331 03:54:55.013626 643 tensorflow.cc:2546] Triton TRITONBACKEND API version: 1.10\n",
      "I0331 03:54:55.013630 643 tensorflow.cc:2552] 'tensorflow' TRITONBACKEND API version: 1.10\n",
      "I0331 03:54:55.013632 643 tensorflow.cc:2576] backend configuration:\n",
      "{\"cmdline\":{\"auto-complete-config\":\"true\",\"min-compute-capability\":\"6.000000\",\"backend-directory\":\"/opt/tritonserver/backends\",\"default-max-batch-size\":\"4\"}}\n",
      "2023-03-31 03:54:56.249380: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 03:54:57.552946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:54:57.553338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:54:57.553495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2023-03-31 03:55:01.085937: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 03:55:02.387651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:02.388067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:02.388262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "I0331 03:55:04.662113 643 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: executor_model (GPU device 0)\n",
      "2023-03-31 03:55:06.169153: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 03:55:07.500688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:07.501062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:07.501235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I0331 03:55:08.025258 643 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: 0_transformworkflowtriton (GPU device 0)\n",
      "I0331 03:55:08.025417 643 model_lifecycle.cc:694] successfully loaded 'executor_model' version 1\n",
      "2023-03-31 03:55:09.267413: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 03:55:10.559264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:10.559674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:10.559838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I0331 03:55:11.110868 643 tensorflow.cc:2642] TRITONBACKEND_ModelInitialize: 1_predicttensorflowtriton (version 1)\n",
      "I0331 03:55:11.111042 643 model_lifecycle.cc:694] successfully loaded '0_transformworkflowtriton' version 1\n",
      "2023-03-31 03:55:11.111317: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 03:55:11.138196: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-31 03:55:11.138240: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 03:55:11.138371: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 03:55:11.139562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.163075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.163361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.163749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.163992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.164217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.164390: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-03-31 03:55:11.164496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44866 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "2023-03-31 03:55:11.250949: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-03-31 03:55:11.269934: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 03:55:11.463914: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 03:55:11.580106: I tensorflow/cc/saved_model/loader.cc:325] SavedModel load for tags { serve }; Status: success: OK. Took 468797 microseconds.\n",
      "I0331 03:55:11.639350 643 tensorflow.cc:2691] TRITONBACKEND_ModelInstanceInitialize: 1_predicttensorflowtriton (GPU device 0)\n",
      "2023-03-31 03:55:11.639580: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 03:55:11.658022: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-31 03:55:11.658065: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 03:55:11.658258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.658475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.658634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.658832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.658994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 03:55:11.659116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44866 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "2023-03-31 03:55:11.715545: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-03-31 03:55:11.901119: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 03:55:12.009243: I tensorflow/cc/saved_model/loader.cc:325] SavedModel load for tags { serve }; Status: success: OK. Took 369668 microseconds.\n",
      "I0331 03:55:12.009506 643 model_lifecycle.cc:694] successfully loaded '1_predicttensorflowtriton' version 1\n",
      "I0331 03:55:12.009596 643 server.cc:563] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0331 03:55:12.009673 643 server.cc:590] \n",
      "+------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Backend    | Path                                                            | Config                                                                                                                                                        |\n",
      "+------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| python     | /opt/tritonserver/backends/python/libtriton_python.so           | {\"cmdline\":{\"auto-complete-config\":\"true\",\"min-compute-capability\":\"6.000000\",\"backend-directory\":\"/opt/tritonserver/backends\",\"default-max-batch-size\":\"4\"}} |\n",
      "| tensorflow | /opt/tritonserver/backends/tensorflow2/libtriton_tensorflow2.so | {\"cmdline\":{\"auto-complete-config\":\"true\",\"min-compute-capability\":\"6.000000\",\"backend-directory\":\"/opt/tritonserver/backends\",\"default-max-batch-size\":\"4\"}} |\n",
      "+------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0331 03:55:12.009724 643 server.cc:633] \n",
      "+---------------------------+---------+--------+\n",
      "| Model                     | Version | Status |\n",
      "+---------------------------+---------+--------+\n",
      "| 0_transformworkflowtriton | 1       | READY  |\n",
      "| 1_predicttensorflowtriton | 1       | READY  |\n",
      "| executor_model            | 1       | READY  |\n",
      "+---------------------------+---------+--------+\n",
      "\n",
      "I0331 03:55:12.050534 643 metrics.cc:864] Collecting metrics for GPU 0: Quadro RTX 8000\n",
      "I0331 03:55:12.050893 643 metrics.cc:757] Collecting CPU metrics\n",
      "I0331 03:55:12.051100 643 tritonserver.cc:2264] \n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Option                           | Value                                                                                                                                                                                                |\n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| server_id                        | triton                                                                                                                                                                                               |\n",
      "| server_version                   | 2.28.0                                                                                                                                                                                               |\n",
      "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |\n",
      "| model_repository_path[0]         | /workspace/models_for_benchmarking/                                                                                                                                                                  |\n",
      "| model_control_mode               | MODE_NONE                                                                                                                                                                                            |\n",
      "| strict_model_config              | 0                                                                                                                                                                                                    |\n",
      "| rate_limit                       | OFF                                                                                                                                                                                                  |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |\n",
      "| response_cache_byte_size         | 0                                                                                                                                                                                                    |\n",
      "| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |\n",
      "| strict_readiness                 | 1                                                                                                                                                                                                    |\n",
      "| exit_timeout                     | 30                                                                                                                                                                                                   |\n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0331 03:55:12.052246 643 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I0331 03:55:12.052542 643 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000\n",
      "I0331 03:55:12.093419 643 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002\n"
     ]
    }
   ],
   "source": [
    "import nvtabular.inference.triton as nvt_triton\n",
    "import tritonclient.grpc as grpcclient\n",
    "import subprocess\n",
    "\n",
    "subprocess.Popen(['tritonserver', '--model-repository=/workspace/models_for_benchmarking/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "511a7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client created.\n",
      "GET /v2/health/live, headers None\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tritonhttpclient/__init__.py:31: DeprecationWarning: The package `tritonhttpclient` is deprecated and will be removed in a future version. Please use instead `tritonclient.http`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tritonhttpclient\n",
    "try:\n",
    "    triton_client = tritonhttpclient.InferenceServerClient(url=\"localhost:8000\", verbose=True)\n",
    "    print(\"client created.\")\n",
    "except Exception as e:\n",
    "    print(\"channel creation failed: \" + str(e))\n",
    "triton_client.is_server_live()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df40196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = validation_set_dataset.compute()\n",
    "validation_data = validation_data[['city_id', 'checkin', 'utrip_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "001b9b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city_id', 'checkin', 'utrip_id'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba49c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = nvt_triton.convert_df_to_triton_input(wf.input_schema.column_names, validation_data.iloc[:10], grpcclient.InferInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4289996a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InferenceServerException",
     "evalue": "[StatusCode.INVALID_ARGUMENT] [request id: <id_unknown>] unexpected shape for input 'utrip_id' for model 'executor_model'. Expected [-1], got [10,1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInferenceServerException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m grpcclient\u001b[38;5;241m.\u001b[39mInferenceServerClient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost:8001\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[0;32m----> 2\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexecutor_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tritonclient/grpc/__init__.py:1431\u001b[0m, in \u001b[0;36mInferenceServerClient.infer\u001b[0;34m(self, model_name, inputs, model_version, outputs, request_id, sequence_id, sequence_start, sequence_end, priority, timeout, client_timeout, headers, compression_algorithm)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[43mraise_error_grpc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrpc_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tritonclient/grpc/__init__.py:62\u001b[0m, in \u001b[0;36mraise_error_grpc\u001b[0;34m(rpc_error)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_error_grpc\u001b[39m(rpc_error):\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_error_grpc(rpc_error) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInferenceServerException\u001b[0m: [StatusCode.INVALID_ARGUMENT] [request id: <id_unknown>] unexpected shape for input 'utrip_id' for model 'executor_model'. Expected [-1], got [10,1]"
     ]
    }
   ],
   "source": [
    "with grpcclient.InferenceServerClient(\"localhost:8001\") as client:\n",
    "    response = client.infer('executor_model', inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66e590af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal (15) received.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0331 04:09:46.862105 643 server.cc:264] Waiting for in-flight requests to complete.\n",
      "I0331 04:09:46.862120 643 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences\n",
      "I0331 04:09:46.862226 643 server.cc:295] All models are stopped, unloading models\n",
      "I0331 04:09:46.862232 643 server.cc:302] Timeout 30: Found 3 live models and 0 in-flight non-inference requests\n",
      "I0331 04:09:46.862354 643 tensorflow.cc:2729] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "I0331 04:09:46.862435 643 tensorflow.cc:2668] TRITONBACKEND_ModelFinalize: delete model state\n",
      "I0331 04:09:46.930082 643 model_lifecycle.cc:579] successfully unloaded '1_predicttensorflowtriton' version 1\n",
      "I0331 04:09:47.862379 643 server.cc:302] Timeout 29: Found 2 live models and 0 in-flight non-inference requests\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "I0331 04:09:48.633011 643 model_lifecycle.cc:579] successfully unloaded 'executor_model' version 1\n",
      "I0331 04:09:48.747692 643 model_lifecycle.cc:579] successfully unloaded '0_transformworkflowtriton' version 1\n",
      "I0331 04:09:48.862472 643 server.cc:302] Timeout 28: Found 0 live models and 0 in-flight non-inference requests\n"
     ]
    }
   ],
   "source": [
    "!pkill triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b67f5751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"executor_model\"\r\n",
      "platform: \"merlin_executor\"\r\n",
      "input {\r\n",
      "  name: \"city_id\"\r\n",
      "  data_type: TYPE_INT64\r\n",
      "  dims: -1\r\n",
      "}\r\n",
      "input {\r\n",
      "  name: \"checkin\"\r\n",
      "  data_type: TYPE_INT64\r\n",
      "  dims: -1\r\n",
      "}\r\n",
      "input {\r\n",
      "  name: \"utrip_id\"\r\n",
      "  data_type: TYPE_STRING\r\n",
      "  dims: -1\r\n",
      "}\r\n",
      "output {\r\n",
      "  name: \"city_id_list/categorical_output\"\r\n",
      "  data_type: TYPE_FP32\r\n",
      "  dims: -1\r\n",
      "  dims: 37204\r\n",
      "}\r\n",
      "backend: \"python\"\r\n"
     ]
    }
   ],
   "source": [
    "cat /workspace/models_for_benchmarking/executor_model/config.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a037f2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /workspace/models_for_benchmarking/executor_model/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile /workspace/models_for_benchmarking/executor_model/config.pbtxt\n",
    "\n",
    "name: \"executor_model\"\n",
    "platform: \"merlin_executor\"\n",
    "input {\n",
    "  name: \"city_id\"\n",
    "  data_type: TYPE_INT64\n",
    "  dims: -1\n",
    "  dims: 1\n",
    "}\n",
    "input {\n",
    "  name: \"checkin\"\n",
    "  data_type: TYPE_INT64\n",
    "  dims: -1\n",
    "  dims: 1\n",
    "}\n",
    "input {\n",
    "  name: \"utrip_id\"\n",
    "  data_type: TYPE_STRING\n",
    "  dims: -1\n",
    "  dims: 1\n",
    "}\n",
    "output {\n",
    "  name: \"city_id_list/categorical_output\"\n",
    "  data_type: TYPE_FP32\n",
    "  dims: -1\n",
    "  dims: 37204\n",
    "}\n",
    "backend: \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8361eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x7fc669ea8b80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0331 04:10:21.241112 1140 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f0136000000' with size 268435456\n",
      "I0331 04:10:21.241478 1140 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "I0331 04:10:21.243629 1140 model_lifecycle.cc:459] loading: 0_transformworkflowtriton:1\n",
      "I0331 04:10:21.243663 1140 model_lifecycle.cc:459] loading: 1_predicttensorflowtriton:1\n",
      "I0331 04:10:21.243687 1140 model_lifecycle.cc:459] loading: executor_model:1\n",
      "I0331 04:10:21.426653 1140 tensorflow.cc:2536] TRITONBACKEND_Initialize: tensorflow\n",
      "I0331 04:10:21.426673 1140 tensorflow.cc:2546] Triton TRITONBACKEND API version: 1.10\n",
      "I0331 04:10:21.426678 1140 tensorflow.cc:2552] 'tensorflow' TRITONBACKEND API version: 1.10\n",
      "I0331 04:10:21.426680 1140 tensorflow.cc:2576] backend configuration:\n",
      "{\"cmdline\":{\"auto-complete-config\":\"true\",\"min-compute-capability\":\"6.000000\",\"backend-directory\":\"/opt/tritonserver/backends\",\"default-max-batch-size\":\"4\"}}\n",
      "2023-03-31 04:10:22.654432: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 04:10:23.956997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:23.957415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:23.957588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "I0331 04:10:26.273402 1140 tensorflow.cc:2642] TRITONBACKEND_ModelInitialize: 1_predicttensorflowtriton (version 1)\n",
      "2023-03-31 04:10:26.273904: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 04:10:26.302373: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-31 04:10:26.302417: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 04:10:26.302546: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 04:10:26.303573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:26.320112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:26.320349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:26.548110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:26.548333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:26.548502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:26.548632: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-03-31 04:10:26.548714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45186 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "2023-03-31 04:10:26.627843: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-03-31 04:10:26.647556: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-03-31 04:10:26.845664: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 04:10:26.964696: I tensorflow/cc/saved_model/loader.cc:325] SavedModel load for tags { serve }; Status: success: OK. Took 690803 microseconds.\n",
      "2023-03-31 04:10:28.277030: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 04:10:29.579382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:29.579724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:29.579883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "I0331 04:10:31.885484 1140 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: 0_transformworkflowtriton (GPU device 0)\n",
      "2023-03-31 04:10:33.139873: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 04:10:34.455441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:34.455850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:34.456046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I0331 04:10:35.011120 1140 tensorflow.cc:2691] TRITONBACKEND_ModelInstanceInitialize: 1_predicttensorflowtriton (GPU device 0)\n",
      "I0331 04:10:35.011305 1140 model_lifecycle.cc:694] successfully loaded '0_transformworkflowtriton' version 1\n",
      "2023-03-31 04:10:35.011540: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 04:10:35.050358: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-31 04:10:35.050407: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 04:10:35.050652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:35.050950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:35.051189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:35.051479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:35.051719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:35.051888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45186 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "2023-03-31 04:10:35.133980: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 04:10:35.325589: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /workspace/models_for_benchmarking/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-03-31 04:10:35.439054: I tensorflow/cc/saved_model/loader.cc:325] SavedModel load for tags { serve }; Status: success: OK. Took 427522 microseconds.\n",
      "I0331 04:10:35.439161 1140 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: executor_model (GPU device 0)\n",
      "I0331 04:10:35.439379 1140 model_lifecycle.cc:694] successfully loaded '1_predicttensorflowtriton' version 1\n",
      "2023-03-31 04:10:36.712996: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 04:10:38.035153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:38.035554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 04:10:38.035735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I0331 04:10:38.556066 1140 model_lifecycle.cc:694] successfully loaded 'executor_model' version 1\n",
      "I0331 04:10:38.556154 1140 server.cc:563] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0331 04:10:38.556196 1140 server.cc:590] \n",
      "+------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Backend    | Path                                                            | Config                                                                                                                                                        |\n",
      "+------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| python     | /opt/tritonserver/backends/python/libtriton_python.so           | {\"cmdline\":{\"auto-complete-config\":\"true\",\"min-compute-capability\":\"6.000000\",\"backend-directory\":\"/opt/tritonserver/backends\",\"default-max-batch-size\":\"4\"}} |\n",
      "| tensorflow | /opt/tritonserver/backends/tensorflow2/libtriton_tensorflow2.so | {\"cmdline\":{\"auto-complete-config\":\"true\",\"min-compute-capability\":\"6.000000\",\"backend-directory\":\"/opt/tritonserver/backends\",\"default-max-batch-size\":\"4\"}} |\n",
      "+------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0331 04:10:38.556221 1140 server.cc:633] \n",
      "+---------------------------+---------+--------+\n",
      "| Model                     | Version | Status |\n",
      "+---------------------------+---------+--------+\n",
      "| 0_transformworkflowtriton | 1       | READY  |\n",
      "| 1_predicttensorflowtriton | 1       | READY  |\n",
      "| executor_model            | 1       | READY  |\n",
      "+---------------------------+---------+--------+\n",
      "\n",
      "I0331 04:10:38.580980 1140 metrics.cc:864] Collecting metrics for GPU 0: Quadro RTX 8000\n",
      "I0331 04:10:38.581225 1140 metrics.cc:757] Collecting CPU metrics\n",
      "I0331 04:10:38.581357 1140 tritonserver.cc:2264] \n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Option                           | Value                                                                                                                                                                                                |\n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| server_id                        | triton                                                                                                                                                                                               |\n",
      "| server_version                   | 2.28.0                                                                                                                                                                                               |\n",
      "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |\n",
      "| model_repository_path[0]         | /workspace/models_for_benchmarking/                                                                                                                                                                  |\n",
      "| model_control_mode               | MODE_NONE                                                                                                                                                                                            |\n",
      "| strict_model_config              | 0                                                                                                                                                                                                    |\n",
      "| rate_limit                       | OFF                                                                                                                                                                                                  |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |\n",
      "| response_cache_byte_size         | 0                                                                                                                                                                                                    |\n",
      "| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |\n",
      "| strict_readiness                 | 1                                                                                                                                                                                                    |\n",
      "| exit_timeout                     | 30                                                                                                                                                                                                   |\n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0331 04:10:38.582209 1140 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I0331 04:10:38.582367 1140 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000\n",
      "I0331 04:10:38.623073 1140 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002\n"
     ]
    }
   ],
   "source": [
    "subprocess.Popen(['tritonserver', '--model-repository=/workspace/models_for_benchmarking/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58d05be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "Failed to transform operator <merlin.systems.dag.runtimes.triton.ops.workflow.TransformWorkflowTriton object at 0x7f074ca31280>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/merlin/dag/executors.py\", line 183, in _transform_data\n",
      "    output_data = node.op.transform(selection, input_data)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/runtimes/triton/ops/workflow.py\", line 97, in transform\n",
      "    raise tritonclient.utils.InferenceServerException(\n",
      "tritonclient.utils.InferenceServerException: unexpected inference output 'city_id_list' for model '0_transformworkflowtriton'\n"
     ]
    },
    {
     "ename": "InferenceServerException",
     "evalue": "[StatusCode.INTERNAL] unexpected inference output 'city_id_list' for model '0_transformworkflowtriton'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInferenceServerException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m grpcclient\u001b[38;5;241m.\u001b[39mInferenceServerClient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost:8001\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[0;32m----> 2\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexecutor_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tritonclient/grpc/__init__.py:1431\u001b[0m, in \u001b[0;36mInferenceServerClient.infer\u001b[0;34m(self, model_name, inputs, model_version, outputs, request_id, sequence_id, sequence_start, sequence_end, priority, timeout, client_timeout, headers, compression_algorithm)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[43mraise_error_grpc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrpc_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tritonclient/grpc/__init__.py:62\u001b[0m, in \u001b[0;36mraise_error_grpc\u001b[0;34m(rpc_error)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_error_grpc\u001b[39m(rpc_error):\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_error_grpc(rpc_error) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInferenceServerException\u001b[0m: [StatusCode.INTERNAL] unexpected inference output 'city_id_list' for model '0_transformworkflowtriton'"
     ]
    }
   ],
   "source": [
    "with grpcclient.InferenceServerClient(\"localhost:8001\") as client:\n",
    "    response = client.infer('executor_model', inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef369ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"0_transformworkflowtriton\"\r\n",
      "input {\r\n",
      "  name: \"city_id\"\r\n",
      "  data_type: TYPE_INT64\r\n",
      "  dims: -1\r\n",
      "}\r\n",
      "input {\r\n",
      "  name: \"checkin\"\r\n",
      "  data_type: TYPE_INT64\r\n",
      "  dims: -1\r\n",
      "}\r\n",
      "input {\r\n",
      "  name: \"utrip_id\"\r\n",
      "  data_type: TYPE_STRING\r\n",
      "  dims: -1\r\n",
      "}\r\n",
      "output {\r\n",
      "  name: \"city_id_list__values\"\r\n",
      "  data_type: TYPE_INT64\r\n",
      "  dims: -1\r\n",
      "  dims: -1\r\n",
      "}\r\n",
      "output {\r\n",
      "  name: \"city_id_list__offsets\"\r\n",
      "  data_type: TYPE_INT32\r\n",
      "  dims: -1\r\n",
      "  dims: -1\r\n",
      "}\r\n",
      "parameters {\r\n",
      "  key: \"cats\"\r\n",
      "  value {\r\n",
      "  }\r\n",
      "}\r\n",
      "parameters {\r\n",
      "  key: \"conts\"\r\n",
      "  value {\r\n",
      "  }\r\n",
      "}\r\n",
      "parameters {\r\n",
      "  key: \"output_model\"\r\n",
      "  value {\r\n",
      "  }\r\n",
      "}\r\n",
      "parameters {\r\n",
      "  key: \"python_module\"\r\n",
      "  value {\r\n",
      "    string_value: \"merlin.systems.triton.models.workflow_model\"\r\n",
      "  }\r\n",
      "}\r\n",
      "backend: \"python\"\r\n"
     ]
    }
   ],
   "source": [
    "cat /workspace/models_for_benchmarking/0_transformworkflowtriton/config.pbtxt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
