{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe68e3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/core\n",
      "   9d9b5c6a..c5c9bc25 release-23.04       -> origin/release-23.04\n",
      " * [new branch]      feature/merlin-array-dispatch -> origin/feature/merlin-array-dispatch\n",
      " * [new branch]      fix-repartition     -> origin/fix-repartition\n",
      " * [new branch]      fix-with-properties -> origin/fix-with-properties\n",
      " * [new branch]      gh-pages            -> origin/gh-pages\n",
      " * [new branch]      laiacano/docs-on-pr -> origin/laiacano/docs-on-pr\n",
      " * [new branch]      main                -> origin/main\n",
      " * [new branch]      release-22.10       -> origin/release-22.10\n",
      " * [new branch]      release-22.11       -> origin/release-22.11\n",
      " * [new branch]      release-22.12       -> origin/release-22.12\n",
      " * [new branch]      release-23.02       -> origin/release-23.02\n",
      " * [new branch]      revert-163-refactor/dictarray-columns -> origin/revert-163-refactor/dictarray-columns\n",
      " * [new branch]      stable              -> origin/stable\n",
      " * [new branch]      tags-intersection   -> origin/tags-intersection\n",
      " * [new branch]      v0.2.0-docs         -> origin/v0.2.0-docs\n",
      " * [new tag]         v0.10.0             -> v0.10.0\n",
      " * [new tag]         v0.8.0              -> v0.8.0\n",
      " * [new tag]         v0.9.0              -> v0.9.0\n",
      " * [new tag]         v23.02.01           -> v23.02.01\n",
      " * [new tag]           v0.1.0              -> v0.1.0\n",
      " * [new tag]           v0.1.1              -> v0.1.1\n",
      " * [new tag]           v0.2.0              -> v0.2.0\n",
      " * [new tag]           v0.3.0              -> v0.3.0\n",
      " * [new tag]           v0.4.0              -> v0.4.0\n",
      " * [new tag]           v0.5.0              -> v0.5.0\n",
      " * [new tag]           v0.6.0              -> v0.6.0\n",
      " * [new tag]           v0.7.0              -> v0.7.0\n",
      " * [new tag]           v23.02.00           -> v23.02.00\n",
      " * [new tag]           v23.05.dev0         -> v23.05.dev0\n",
      "Switched to a new branch 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'main' set up to track remote branch 'main' from 'origin'.\n",
      "Processing /core\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: merlin-core\n",
      "  Building wheel for merlin-core (PEP 517): started\n",
      "  Building wheel for merlin-core (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-core: filename=merlin_core-23.5.dev0+28.ge1eaf269-py3-none-any.whl size=164561 sha256=700362e2fca0348cfdc2bd7dfb188985b727984a4844f5e604b89d110c8f35dc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xnol33be/wheels/8f/da/8c/c779661788874afaa32fd10abeac6016635956e3bad9940584\n",
      "Successfully built merlin-core\n",
      "Installing collected packages: merlin-core\n",
      "  Attempting uninstall: merlin-core\n",
      "    Found existing installation: merlin-core 23.4.0\n",
      "    Uninstalling merlin-core-23.4.0:\n",
      "      Successfully uninstalled merlin-core-23.4.0\n",
      "Successfully installed merlin-core-23.5.dev0+28.ge1eaf269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/NVTabular\n",
      "   f8f484e5..90489194 release-23.04           -> origin/release-23.04\n",
      " * [new branch]      1077-implement          -> origin/1077-implement\n",
      " * [new branch]      21.09/column-tagging    -> origin/21.09/column-tagging\n",
      " * [new branch]      21.09/dataset-collection -> origin/21.09/dataset-collection\n",
      " * [new branch]      21.09/operator-block    -> origin/21.09/operator-block\n",
      " * [new branch]      21.09/schema            -> origin/21.09/schema\n",
      " * [new branch]      add_sum_to_supported_aggregations -> origin/add_sum_to_supported_aggregations\n",
      " * [new branch]      aiobotocore_v2          -> origin/aiobotocore_v2\n",
      " * [new branch]      alexanderronquillo-patch-1 -> origin/alexanderronquillo-patch-1\n",
      " * [new branch]      atomize_adding_of_tags  -> origin/atomize_adding_of_tags\n",
      " * [new branch]      automate_pypi           -> origin/automate_pypi\n",
      " * [new branch]      bench-pynvml-fix        -> origin/bench-pynvml-fix\n",
      " * [new branch]      branch-0.6              -> origin/branch-0.6\n",
      " * [new branch]      bschifferer-remove_examples_1 -> origin/bschifferer-remove_examples_1\n",
      " * [new branch]      categorify-inference-int16 -> origin/categorify-inference-int16\n",
      " * [new branch]      columns_with_aggs_in_names -> origin/columns_with_aggs_in_names\n",
      " * [new branch]      conda-package-python-versions -> origin/conda-package-python-versions\n",
      " * [new branch]      conda_gh_action         -> origin/conda_gh_action\n",
      " * [new branch]      dataloader-remove-sparse -> origin/dataloader-remove-sparse\n",
      " * [new branch]      dataloader_doc_fix      -> origin/dataloader_doc_fix\n",
      " * [new branch]      disable-package-build-on-pull-requests -> origin/disable-package-build-on-pull-requests\n",
      " * [new branch]      dont_install_tests      -> origin/dont_install_tests\n",
      " * [new branch]      drop_low_cardinality    -> origin/drop_low_cardinality\n",
      " * [new branch]      fix-docs-tox-env        -> origin/fix-docs-tox-env\n",
      " * [new branch]      fix-wf-file             -> origin/fix-wf-file\n",
      " * [new branch]      fix/inference-deprecation -> origin/fix/inference-deprecation\n",
      " * [new branch]      fix_data_path           -> origin/fix_data_path\n",
      " * [new branch]      fix_hugectr_nb          -> origin/fix_hugectr_nb\n",
      " * [new branch]      fix_nbs                 -> origin/fix_nbs\n",
      " * [new branch]      gh-pages                -> origin/gh-pages\n",
      " * [new branch]      groupby_without_groupby_col_in_col_selector -> origin/groupby_without_groupby_col_in_col_selector\n",
      " * [new branch]      hugectr-newapi          -> origin/hugectr-newapi\n",
      " * [new branch]      laiacano/check-list-from-schema -> origin/laiacano/check-list-from-schema\n",
      " * [new branch]      laiacano/workflow-subgraph -> origin/laiacano/workflow-subgraph\n",
      " * [new branch]      main                    -> origin/main\n",
      " * [new branch]      na_sentinel             -> origin/na_sentinel\n",
      " * [new branch]      notebooks-21.10         -> origin/notebooks-21.10\n",
      " * [new branch]      nvt-1195                -> origin/nvt-1195\n",
      " * [new branch]      nvtabular_examples      -> origin/nvtabular_examples\n",
      " * [new branch]      packages-workflow-split -> origin/packages-workflow-split\n",
      " * [new branch]      readme_updates          -> origin/readme_updates\n",
      " * [new branch]      refactor/fit-schema     -> origin/refactor/fit-schema\n",
      " * [new branch]      refactor/input-column-selection -> origin/refactor/input-column-selection\n",
      " * [new branch]      refactor/postpone-schema-binding -> origin/refactor/postpone-schema-binding\n",
      " * [new branch]      release-22.10           -> origin/release-22.10\n",
      " * [new branch]      release-22.11           -> origin/release-22.11\n",
      " * [new branch]      release-22.12           -> origin/release-22.12\n",
      " * [new branch]      release-23.02           -> origin/release-23.02\n",
      " * [new branch]      remove_poetry           -> origin/remove_poetry\n",
      " * [new branch]      remove_release_notes    -> origin/remove_release_notes\n",
      " * [new branch]      repeat-ops              -> origin/repeat-ops\n",
      " * [new branch]      revert_atomize_tags     -> origin/revert_atomize_tags\n",
      " * [new branch]      rjzamora-simplify-criteo -> origin/rjzamora-simplify-criteo\n",
      " * [new branch]      rnyak-patch-1           -> origin/rnyak-patch-1\n",
      " * [new branch]      romeyn/input-api        -> origin/romeyn/input-api\n",
      " * [new branch]      stable                  -> origin/stable\n",
      " * [new branch]      test-column-similarity-dataset-cpu-default-none -> origin/test-column-similarity-dataset-cpu-default-none\n",
      " * [new branch]      test-torch-dataloader-dataset-cpu-default-none -> origin/test-torch-dataloader-dataset-cpu-default-none\n",
      " * [new branch]      torch_catch             -> origin/torch_catch\n",
      " * [new branch]      update-dask-reqs        -> origin/update-dask-reqs\n",
      " * [new branch]      update_merlin_core      -> origin/update_merlin_core\n",
      " * [new branch]      update_requirements     -> origin/update_requirements\n",
      " * [new branch]      v0.10.0-docs            -> origin/v0.10.0-docs\n",
      " * [new branch]      v0.11.0-docs            -> origin/v0.11.0-docs\n",
      " * [new branch]      v0.7.1-docs             -> origin/v0.7.1-docs\n",
      " * [new branch]      v0.8.0-docs             -> origin/v0.8.0-docs\n",
      " * [new branch]      v0.9.0-docs             -> origin/v0.9.0-docs\n",
      " * [new branch]      v1.0.0-docs             -> origin/v1.0.0-docs\n",
      " * [new tag]         v0.6.1                  -> v0.6.1\n",
      " * [new tag]         v1.6.0                  -> v1.6.0\n",
      " * [new tag]         v1.7.0                  -> v1.7.0\n",
      " * [new tag]         v1.8.1                  -> v1.8.1\n",
      " * [new tag]         v23.02.00               -> v23.02.00\n",
      " * [new tag]           v0.1.0                  -> v0.1.0\n",
      " * [new tag]           v0.1.1                  -> v0.1.1\n",
      " * [new tag]           v0.10.0                 -> v0.10.0\n",
      " * [new tag]           v0.11.0                 -> v0.11.0\n",
      " * [new tag]           v0.2.0                  -> v0.2.0\n",
      " * [new tag]           v0.3.0                  -> v0.3.0\n",
      " * [new tag]           v0.4.0                  -> v0.4.0\n",
      " * [new tag]           v0.5.0                  -> v0.5.0\n",
      " * [new tag]           v0.5.1                  -> v0.5.1\n",
      " * [new tag]           v0.5.2                  -> v0.5.2\n",
      " * [new tag]           v0.5.3                  -> v0.5.3\n",
      " * [new tag]           v0.6.0                  -> v0.6.0\n",
      " * [new tag]           v0.7.0                  -> v0.7.0\n",
      " * [new tag]           v0.7.1                  -> v0.7.1\n",
      " * [new tag]           v0.8.0                  -> v0.8.0\n",
      " * [new tag]           v0.9.0                  -> v0.9.0\n",
      " * [new tag]           v1.0.0                  -> v1.0.0\n",
      " * [new tag]           v1.1.0                  -> v1.1.0\n",
      " * [new tag]           v1.1.1                  -> v1.1.1\n",
      " * [new tag]           v1.2.0                  -> v1.2.0\n",
      " * [new tag]           v1.2.1                  -> v1.2.1\n",
      " * [new tag]           v1.2.2                  -> v1.2.2\n",
      " * [new tag]           v1.3.0                  -> v1.3.0\n",
      " * [new tag]           v1.3.1                  -> v1.3.1\n",
      " * [new tag]           v1.3.2                  -> v1.3.2\n",
      " * [new tag]           v1.3.3                  -> v1.3.3\n",
      " * [new tag]           v1.4.0                  -> v1.4.0\n",
      " * [new tag]           v1.5.0                  -> v1.5.0\n",
      " * [new tag]           v1.8.0                  -> v1.8.0\n",
      " * [new tag]           v23.05.dev0             -> v23.05.dev0\n",
      "Switched to a new branch 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'main' set up to track remote branch 'main' from 'origin'.\n",
      "Processing /nvtabular\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: nvtabular\n",
      "  Building wheel for nvtabular (PEP 517): started\n",
      "  Building wheel for nvtabular (PEP 517): finished with status 'done'\n",
      "  Created wheel for nvtabular: filename=nvtabular-23.5.dev0+11.g7557ff03-cp38-cp38-linux_x86_64.whl size=261194 sha256=474771e2b56bf4622084d4117f357d1f51cb382cf8dcedbef5f155c9eabb408a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-h7yuc48r/wheels/df/bf/c2/9cc2a62fe6da42038c26a9c0c4e25f9767093528b102fa30a2\n",
      "Successfully built nvtabular\n",
      "Installing collected packages: nvtabular\n",
      "  Attempting uninstall: nvtabular\n",
      "    Found existing installation: nvtabular 23.4.0\n",
      "    Uninstalling nvtabular-23.4.0:\n",
      "      Successfully uninstalled nvtabular-23.4.0\n",
      "Successfully installed nvtabular-23.5.dev0+11.g7557ff03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/Models\n",
      "   a44eced6..56c7d6a4 release-23.04           -> origin/release-23.04\n",
      " * [new branch]      Mai                     -> origin/Mai\n",
      " * [new branch]      add_category_encoding_test -> origin/add_category_encoding_test\n",
      " * [new branch]      add_lightfm_and_explicit_training_example -> origin/add_lightfm_and_explicit_training_example\n",
      " * [new branch]      add_logo_tracking_to_07 -> origin/add_logo_tracking_to_07\n",
      " * [new branch]      add_notebooks_test      -> origin/add_notebooks_test\n",
      " * [new branch]      add_sigir_dataset       -> origin/add_sigir_dataset\n",
      " * [new branch]      add_tf_docstrings_rny   -> origin/add_tf_docstrings_rny\n",
      " * [new branch]      advanced_example        -> origin/advanced_example\n",
      " * [new branch]      asvdb_metric_tracking   -> origin/asvdb_metric_tracking\n",
      " * [new branch]      batched-dataset/schema  -> origin/batched-dataset/schema\n",
      " * [new branch]      benchmark-session-based -> origin/benchmark-session-based\n",
      " * [new branch]      block-context           -> origin/block-context\n",
      " * [new branch]      blossom_report_skipped  -> origin/blossom_report_skipped\n",
      " * [new branch]      break_ties              -> origin/break_ties\n",
      " * [new branch]      bs_unittest_examples_v2 -> origin/bs_unittest_examples_v2\n",
      " * [new branch]      bschifferer-patch-1     -> origin/bschifferer-patch-1\n",
      " * [new branch]      change_two_tower_api_test -> origin/change_two_tower_api_test\n",
      " * [new branch]      ci/backend-tests        -> origin/ci/backend-tests\n",
      " * [new branch]      ci/example-linting      -> origin/ci/example-linting\n",
      " * [new branch]      ci/horovod              -> origin/ci/horovod\n",
      " * [new branch]      cicd                    -> origin/cicd\n",
      " * [new branch]      codespell_fix           -> origin/codespell_fix\n",
      " * [new branch]      compare_ranking_models  -> origin/compare_ranking_models\n",
      " * [new branch]      conda_recipe            -> origin/conda_recipe\n",
      " * [new branch]      consolidate-abstractions -> origin/consolidate-abstractions\n",
      " * [new branch]      dataloader_tag_fix      -> origin/dataloader_tag_fix\n",
      " * [new branch]      dcn_tests               -> origin/dcn_tests\n",
      " * [new branch]      deps/merlin-core-commit -> origin/deps/merlin-core-commit\n",
      " * [new branch]      docs-strings            -> origin/docs-strings\n",
      " * [new branch]      docs/interrogate-cfg    -> origin/docs/interrogate-cfg\n",
      " * [new branch]      docs/interrogate-config -> origin/docs/interrogate-config\n",
      " * [new branch]      emb_export_fix          -> origin/emb_export_fix\n",
      " * [new branch]      evaluate_fixes          -> origin/evaluate_fixes\n",
      " * [new branch]      examples/unit-tests     -> origin/examples/unit-tests\n",
      " * [new branch]      examples/update_link    -> origin/examples/update_link\n",
      " * [new branch]      examples_fixes          -> origin/examples_fixes\n",
      " * [new branch]      fea-sok-integration-wj  -> origin/fea-sok-integration-wj\n",
      " * [new branch]      fea-sok-load-dump       -> origin/fea-sok-load-dump\n",
      " * [new branch]      feature/multi-hot-columns -> origin/feature/multi-hot-columns\n",
      " * [new branch]      feature/retrieval-dnn   -> origin/feature/retrieval-dnn\n",
      " * [new branch]      fix-contrastive-predictions -> origin/fix-contrastive-predictions\n",
      " * [new branch]      fix/aliccp_workflow     -> origin/fix/aliccp_workflow\n",
      " * [new branch]      fix/batch_predict       -> origin/fix/batch_predict\n",
      " * [new branch]      fix/example-tests       -> origin/fix/example-tests\n",
      " * [new branch]      fix/python-version      -> origin/fix/python-version\n",
      " * [new branch]      fix/shared_embeddings   -> origin/fix/shared_embeddings\n",
      " * [new branch]      fix_aliccp_schema       -> origin/fix_aliccp_schema\n",
      " * [new branch]      fix_cated_ohe           -> origin/fix_cated_ohe\n",
      " * [new branch]      fix_datetime_issue_add_inference_on_TIS -> origin/fix_datetime_issue_add_inference_on_TIS\n",
      " * [new branch]      fix_lightfm_evaluate    -> origin/fix_lightfm_evaluate\n",
      " * [new branch]      fix_masking             -> origin/fix_masking\n",
      " * [new branch]      fix_mtl_metrics         -> origin/fix_mtl_metrics\n",
      " * [new branch]      fix_notebooks           -> origin/fix_notebooks\n",
      " * [new branch]      fix_regression          -> origin/fix_regression\n",
      " * [new branch]      fix_retrieval           -> origin/fix_retrieval\n",
      " * [new branch]      fix_retrieval_eval_loss -> origin/fix_retrieval_eval_loss\n",
      " * [new branch]      fix_sampled_softmax_evaluation -> origin/fix_sampled_softmax_evaluation\n",
      " * [new branch]      fix_test_07             -> origin/fix_test_07\n",
      " * [new branch]      getting_started_exp     -> origin/getting_started_exp\n",
      " * [new branch]      gh-pages                -> origin/gh-pages\n",
      " * [new branch]      hashed_cross_test       -> origin/hashed_cross_test\n",
      " * [new branch]      implement_review_comments -> origin/implement_review_comments\n",
      " * [new branch]      in-bath-sampling-bug    -> origin/in-bath-sampling-bug\n",
      " * [new branch]      infer_embeddings        -> origin/infer_embeddings\n",
      " * [new branch]      inference_benchmarking_transformers -> origin/inference_benchmarking_transformers\n",
      " * [new branch]      laiacano/concurrency    -> origin/laiacano/concurrency\n",
      " * [new branch]      laiacano/tox            -> origin/laiacano/tox\n",
      " * [new branch]      layer_freezing_test     -> origin/layer_freezing_test\n",
      " * [new branch]      load_retrieval_model    -> origin/load_retrieval_model\n",
      " * [new branch]      logit_correction_nol2_temp -> origin/logit_correction_nol2_temp\n",
      " * [new branch]      losses                  -> origin/losses\n",
      " * [new branch]      main                    -> origin/main\n",
      " * [new branch]      masking_transforms      -> origin/masking_transforms\n",
      " * [new branch]      merlin-standard-lib     -> origin/merlin-standard-lib\n",
      " * [new branch]      metrics_opt             -> origin/metrics_opt\n",
      " * [new branch]      metrics_opt2            -> origin/metrics_opt2\n",
      " * [new branch]      mikemckiernan-patch-1   -> origin/mikemckiernan-patch-1\n",
      " * [new branch]      mlm                     -> origin/mlm\n",
      " * [new branch]      mlm_alt                 -> origin/mlm_alt\n",
      " * [new branch]      mlp_selu                -> origin/mlp_selu\n",
      " * [new branch]      mrr_fix                 -> origin/mrr_fix\n",
      " * [new branch]      mtl_example             -> origin/mtl_example\n",
      " * [new branch]      mtl_loss                -> origin/mtl_loss\n",
      " * [new branch]      mtl_models              -> origin/mtl_models\n",
      " * [new branch]      mtl_regularization      -> origin/mtl_regularization\n",
      " * [new branch]      multi_optimizer_example -> origin/multi_optimizer_example\n",
      " * [new branch]      neg_sampling            -> origin/neg_sampling\n",
      " * [new branch]      poc                     -> origin/poc\n",
      " * [new branch]      pretrained_init         -> origin/pretrained_init\n",
      " * [new branch]      radekosmulski-patch-2   -> origin/radekosmulski-patch-2\n",
      " * [new branch]      ragged_embeddings       -> origin/ragged_embeddings\n",
      " * [new branch]      ranking_models_inputs   -> origin/ranking_models_inputs\n",
      " * [new branch]      ranking_tests           -> origin/ranking_tests\n",
      " * [new branch]      ranking_tests3          -> origin/ranking_tests3\n",
      " * [new branch]      readme_bash             -> origin/readme_bash\n",
      " * [new branch]      refactor-docs-reqs      -> origin/refactor-docs-reqs\n",
      " * [new branch]      refactor/docs-reqs      -> origin/refactor/docs-reqs\n",
      " * [new branch]      refactor/embedding-layers -> origin/refactor/embedding-layers\n",
      " * [new branch]      refactor/youtube-retrieval -> origin/refactor/youtube-retrieval\n",
      " * [new branch]      release-22.10           -> origin/release-22.10\n",
      " * [new branch]      release-22.11           -> origin/release-22.11\n",
      " * [new branch]      release-22.12           -> origin/release-22.12\n",
      " * [new branch]      release-23.02           -> origin/release-23.02\n",
      " * [new branch]      remove/masking          -> origin/remove/masking\n",
      " * [new branch]      reset-metrics           -> origin/reset-metrics\n",
      " * [new branch]      retrieval-sample-weights -> origin/retrieval-sample-weights\n",
      " * [new branch]      retrieval_debug         -> origin/retrieval_debug\n",
      " * [new branch]      retrieval_debug_no_l2norm -> origin/retrieval_debug_no_l2norm\n",
      " * [new branch]      retrieval_debug_scores_temp -> origin/retrieval_debug_scores_temp\n",
      " * [new branch]      retrieval_eval_fix      -> origin/retrieval_eval_fix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * [new branch]      retrieval_fixes         -> origin/retrieval_fixes\n",
      " * [new branch]      retrieval_fixes_2       -> origin/retrieval_fixes_2\n",
      " * [new branch]      retrieval_integration_tests -> origin/retrieval_integration_tests\n",
      " * [new branch]      revert-813-laiacano/tox-and-tmpdir -> origin/revert-813-laiacano/tox-and-tmpdir\n",
      " * [new branch]      romeyn/block-api        -> origin/romeyn/block-api\n",
      " * [new branch]      romeyn/block-cleanup    -> origin/romeyn/block-cleanup\n",
      " * [new branch]      romeyn/inputs           -> origin/romeyn/inputs\n",
      " * [new branch]      sampling                -> origin/sampling\n",
      " * [new branch]      select-by-tag           -> origin/select-by-tag\n",
      " * [new branch]      session-based/contrastive -> origin/session-based/contrastive\n",
      " * [new branch]      stable                  -> origin/stable\n",
      " * [new branch]      t4rec_use_case          -> origin/t4rec_use_case\n",
      " * [new branch]      tf/add-bokeh-to-dev     -> origin/tf/add-bokeh-to-dev\n",
      " * [new branch]      tf/base-model-test-graph-mode -> origin/tf/base-model-test-graph-mode\n",
      " * [new branch]      tf/batch_predict_fix    -> origin/tf/batch_predict_fix\n",
      " * [new branch]      tf/categorical-prediction -> origin/tf/categorical-prediction\n",
      " * [new branch]      tf/categorical-prediction-2 -> origin/tf/categorical-prediction-2\n",
      " * [new branch]      tf/column_sampling_serialization_fix -> origin/tf/column_sampling_serialization_fix\n",
      " * [new branch]      tf/combinators-base     -> origin/tf/combinators-base\n",
      " * [new branch]      tf/cond                 -> origin/tf/cond\n",
      " * [new branch]      tf/context-tensor       -> origin/tf/context-tensor\n",
      " * [new branch]      tf/continuous_seq_feats_fix -> origin/tf/continuous_seq_feats_fix\n",
      " * [new branch]      tf/contrastive-prediction -> origin/tf/contrastive-prediction\n",
      " * [new branch]      tf/core                 -> origin/tf/core\n",
      " * [new branch]      tf/dataloader_changes   -> origin/tf/dataloader_changes\n",
      " * [new branch]      tf/dep-prediction-tasks -> origin/tf/dep-prediction-tasks\n",
      " * [new branch]      tf/dlrm_dropout_fix     -> origin/tf/dlrm_dropout_fix\n",
      " * [new branch]      tf/doc_strings_update   -> origin/tf/doc_strings_update\n",
      " * [new branch]      tf/dynamic-memory-growth -> origin/tf/dynamic-memory-growth\n",
      " * [new branch]      tf/embedding-tables     -> origin/tf/embedding-tables\n",
      " * [new branch]      tf/embeddings_regularization -> origin/tf/embeddings_regularization\n",
      " * [new branch]      tf/evaluate_retrieval   -> origin/tf/evaluate_retrieval\n",
      " * [new branch]      tf/fix_broadcast_to_sequence -> origin/tf/fix_broadcast_to_sequence\n",
      " * [new branch]      tf/fix_logq_correction  -> origin/tf/fix_logq_correction\n",
      " * [new branch]      tf/fix_mlm_test         -> origin/tf/fix_mlm_test\n",
      " * [new branch]      tf/fix_tag_item_id      -> origin/tf/fix_tag_item_id\n",
      " * [new branch]      tf/fix_tests_shared_state -> origin/tf/fix_tests_shared_state\n",
      " * [new branch]      tf/fix_training_smaller_accuracy -> origin/tf/fix_training_smaller_accuracy\n",
      " * [new branch]      tf/input-block          -> origin/tf/input-block\n",
      " * [new branch]      tf/input-block-filter   -> origin/tf/input-block-filter\n",
      " * [new branch]      tf/inputs-concat        -> origin/tf/inputs-concat\n",
      " * [new branch]      tf/keras-embedding      -> origin/tf/keras-embedding\n",
      " * [new branch]      tf/logit_correction     -> origin/tf/logit_correction\n",
      " * [new branch]      tf/logq_correction      -> origin/tf/logq_correction\n",
      " * [new branch]      tf/loss_batch_metric    -> origin/tf/loss_batch_metric\n",
      " * [new branch]      tf/map-values           -> origin/tf/map-values\n",
      " * [new branch]      tf/masking_block        -> origin/tf/masking_block\n",
      " * [new branch]      tf/mf-retrieval-model   -> origin/tf/mf-retrieval-model\n",
      " * [new branch]      tf/mlm-schema           -> origin/tf/mlm-schema\n",
      " * [new branch]      tf/model-tests          -> origin/tf/model-tests\n",
      " * [new branch]      tf/model/sequential     -> origin/tf/model/sequential\n",
      " * [new branch]      tf/move-core            -> origin/tf/move-core\n",
      " * [new branch]      tf/mtl_example_updates_v2 -> origin/tf/mtl_example_updates_v2\n",
      " * [new branch]      tf/multi_task_improv    -> origin/tf/multi_task_improv\n",
      " * [new branch]      tf/ncf_model            -> origin/tf/ncf_model\n",
      " * [new branch]      tf/output-block         -> origin/tf/output-block\n",
      " * [new branch]      tf/pop_metrics          -> origin/tf/pop_metrics\n",
      " * [new branch]      tf/prediction           -> origin/tf/prediction\n",
      " * [new branch]      tf/prediction-block     -> origin/tf/prediction-block\n",
      " * [new branch]      tf/pretrained_emb       -> origin/tf/pretrained_emb\n",
      " * [new branch]      tf/process_list_to_prepare_features -> origin/tf/process_list_to_prepare_features\n",
      " * [new branch]      tf/pruning-parallel-block -> origin/tf/pruning-parallel-block\n",
      " * [new branch]      tf/quick_start_ranking  -> origin/tf/quick_start_ranking\n",
      " * [new branch]      tf/ragged-tensors       -> origin/tf/ragged-tensors\n",
      " * [new branch]      tf/ranking_metrics_sort -> origin/tf/ranking_metrics_sort\n",
      " * [new branch]      tf/refactor             -> origin/tf/refactor\n",
      " * [new branch]      tf/retireval_eval       -> origin/tf/retireval_eval\n",
      " * [new branch]      tf/retrieval-eval       -> origin/tf/retrieval-eval\n",
      " * [new branch]      tf/retrieval-model-v2   -> origin/tf/retrieval-model-v2\n",
      " * [new branch]      tf/retrieval-models     -> origin/tf/retrieval-models\n",
      " * [new branch]      tf/sampling/items       -> origin/tf/sampling/items\n",
      " * [new branch]      tf/save-regularizer     -> origin/tf/save-regularizer\n",
      " * [new branch]      tf/target-propagation   -> origin/tf/target-propagation\n",
      " * [new branch]      tf/targets              -> origin/tf/targets\n",
      " * [new branch]      tf/tf-cont-list         -> origin/tf/tf-cont-list\n",
      " * [new branch]      tf/topk_recommender     -> origin/tf/topk_recommender\n",
      " * [new branch]      tf/tower-save           -> origin/tf/tower-save\n",
      " * [new branch]      tf/train_metrics_steps_fix -> origin/tf/train_metrics_steps_fix\n",
      " * [new branch]      tf/transformer-api      -> origin/tf/transformer-api\n",
      " * [new branch]      tf/transformer-block    -> origin/tf/transformer-block\n",
      " * [new branch]      tf/transformer_block    -> origin/tf/transformer_block\n",
      " * [new branch]      tf/wide_and_deep        -> origin/tf/wide_and_deep\n",
      " * [new branch]      tf/wrap-as-model        -> origin/tf/wrap-as-model\n",
      " * [new branch]      tf/xlnet-bug            -> origin/tf/xlnet-bug\n",
      " * [new branch]      torch/agg               -> origin/torch/agg\n",
      " * [new branch]      torch/block             -> origin/torch/block\n",
      " * [new branch]      torch/clean-up          -> origin/torch/clean-up\n",
      " * [new branch]      torch/dev               -> origin/torch/dev\n",
      " * [new branch]      torch/link              -> origin/torch/link\n",
      " * [new branch]      torch/masking           -> origin/torch/masking\n",
      " * [new branch]      torch/mlp               -> origin/torch/mlp\n",
      " * [new branch]      torch/parallel-block    -> origin/torch/parallel-block\n",
      " * [new branch]      torch/prototype         -> origin/torch/prototype\n",
      " * [new branch]      torch/registry          -> origin/torch/registry\n",
      " * [new branch]      torch/remove-t4r-code   -> origin/torch/remove-t4r-code\n",
      " * [new branch]      torch/router            -> origin/torch/router\n",
      " * [new branch]      torch/router-block      -> origin/torch/router-block\n",
      " * [new branch]      torch/sample-batch      -> origin/torch/sample-batch\n",
      " * [new branch]      tox_github_actions_fix  -> origin/tox_github_actions_fix\n",
      " * [new branch]      transformer-api         -> origin/transformer-api\n",
      " * [new branch]      two_tower_fixes         -> origin/two_tower_fixes\n",
      " * [new branch]      update_07               -> origin/update_07\n",
      " * [new branch]      update_advanced_notebook -> origin/update_advanced_notebook\n",
      " * [new branch]      update_example_01       -> origin/update_example_01\n",
      " * [new branch]      update_example_pretrained_embs -> origin/update_example_pretrained_embs\n",
      " * [new branch]      update_examples_with_tracking_logo -> origin/update_examples_with_tracking_logo\n",
      " * [new branch]      update_pretrained_embs_example -> origin/update_pretrained_embs_example\n",
      " * [new branch]      v0.2.0-docs             -> origin/v0.2.0-docs\n",
      " * [new branch]      v0.3.0-docs             -> origin/v0.3.0-docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * [new branch]      validation_data_fix     -> origin/validation_data_fix\n",
      " * [new branch]      validation_data_fix2    -> origin/validation_data_fix2\n",
      " * [new branch]      wide_deep_example_test  -> origin/wide_deep_example_test\n",
      " * [new branch]      wideanddeep_example     -> origin/wideanddeep_example\n",
      " * [new branch]      xgboost/predict-without-target -> origin/xgboost/predict-without-target\n",
      " * [new branch]      youtube_dnn_retrieval   -> origin/youtube_dnn_retrieval\n",
      " * [new branch]      youtubednn_improv       -> origin/youtubednn_improv\n",
      " * [new branch]      youtubednn_logq         -> origin/youtubednn_logq\n",
      " * [new tag]         v0.10.0                 -> v0.10.0\n",
      " * [new tag]         v0.11.0                 -> v0.11.0\n",
      " * [new tag]         v0.9.0                  -> v0.9.0\n",
      " * [new tag]         v23.02.00               -> v23.02.00\n",
      " * [new tag]           v0.1.0                  -> v0.1.0\n",
      " * [new tag]           v0.2.0                  -> v0.2.0\n",
      " * [new tag]           v0.3.0                  -> v0.3.0\n",
      " * [new tag]           v0.4.0                  -> v0.4.0\n",
      " * [new tag]           v0.5.0                  -> v0.5.0\n",
      " * [new tag]           v0.6.0                  -> v0.6.0\n",
      " * [new tag]           v0.7.0                  -> v0.7.0\n",
      " * [new tag]           v0.8.0                  -> v0.8.0\n",
      " * [new tag]           v23.05.dev0             -> v23.05.dev0\n",
      "Switched to a new branch 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'main' set up to track remote branch 'main' from 'origin'.\n",
      "Processing /models\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: merlin-models\n",
      "  Building wheel for merlin-models (PEP 517): started\n",
      "  Building wheel for merlin-models (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-models: filename=merlin_models-23.5.dev0+17.g8efbd361-py3-none-any.whl size=357398 sha256=e4aa301d799d1832fc052f1fd69fe50634d244ec320cd9de0256679d2eed1a12\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-fbcn70jg/wheels/4d/e8/98/0493db55fff90dc9af123f55a9455b96f7f8166c912a02c8a6\n",
      "Successfully built merlin-models\n",
      "Installing collected packages: merlin-models\n",
      "  Attempting uninstall: merlin-models\n",
      "    Found existing installation: merlin-models 23.4.0\n",
      "    Uninstalling merlin-models-23.4.0:\n",
      "      Successfully uninstalled merlin-models-23.4.0\n",
      "Successfully installed merlin-models-23.5.dev0+17.g8efbd361\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /core\n",
    "git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "pip install . --no-deps\n",
    "\n",
    "cd /nvtabular\n",
    "git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "pip install . --no-deps\n",
    "\n",
    "cd /models\n",
    "git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "pip install . --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f6f096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 00:50:15.754273: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 00:50:18.196650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 00:50:18.197037: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 00:50:18.197163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: sparse_operation_kit is imported\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.1.4-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.1.4-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Initialize finished, communication tool: horovod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 00:50:20.188904: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 00:50:20.189860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 00:50:20.190036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 00:50:20.190160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 00:50:20.320157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 00:50:20.320346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 00:50:20.320476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 00:50:20.320578: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-05-22 00:50:20.320599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24576 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import merlin.models.tf as mm\n",
    "from merlin.schema.tags import Tags\n",
    "import tensorflow as tf\n",
    "from merlin.models.tf.blocks import *\n",
    "from merlin.datasets.synthetic import generate_data\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee19ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28d27af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "browsing_train.csv      search_train.csv\r\n",
      "browsing_train.parquet  sku_to_content.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls /workspace/sigir_dataset/train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3efcf7",
   "metadata": {},
   "source": [
    "If we attempt reading in the data, we unfortunately get a `cudf` error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ae1d99",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDF failure at: /opt/rapids/src/cudf/cpp/include/cudf/strings/detail/strings_column_factories.cuh:88: total size of strings is too large for cudf column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/workspace/sigir_dataset/train/browsing_train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/nvtx/nvtx.py:101\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    100\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 101\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/cudf/io/csv.py:88\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, prefix, mangle_dupe_cols, dtype, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, dayfirst, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, comment, delim_whitespace, byte_range, use_python_file_object, storage_options, bytes_per_thread)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_scalar(na_values):\n\u001b[1;32m     86\u001b[0m     na_values \u001b[38;5;241m=\u001b[39m [na_values]\n\u001b[0;32m---> 88\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mlibcudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmangle_dupe_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmangle_dupe_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelim_whitespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelim_whitespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipinitialspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipinitialspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbyte_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_blank_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_blank_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, abc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# There exists some dtypes in the result columns that is inferred.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Find them and map them to the default dtypes.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n",
      "File \u001b[0;32mcsv.pyx:423\u001b[0m, in \u001b[0;36mcudf._lib.csv.read_csv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDF failure at: /opt/rapids/src/cudf/cpp/include/cudf/strings/detail/strings_column_factories.cuh:88: total size of strings is too large for cudf column"
     ]
    }
   ],
   "source": [
    "cudf.read_csv('/workspace/sigir_dataset/train/browsing_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03e17b",
   "metadata": {},
   "source": [
    "`cudf` can only read in datasets that have fewer than 2**32 characters. Here there is so much data and the strings are so long we cross this limit.\n",
    "\n",
    "We could work with only partial data. But we would still have the problem of our id column consisting of strings. This is something that `datasets` is unable to work with for synthetic data generation.\n",
    "\n",
    "Let's instead \"categorify\" the string columns of interest. We will have to do this nonetheless if we will want to work with the full dataset in `cudf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c761fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/workspace/sigir_dataset/train/browsing_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be674da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>server_timestamp_epoch_ms</th>\n",
       "      <th>hashed_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20c458b802f6ea9374783bfc528b19421be977a6769785...</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>d5157f8bc52965390fa21ad5842a8502bc3eb8b0930f3f...</td>\n",
       "      <td>1550885210881</td>\n",
       "      <td>7e4527ac6a32deed4f4f06bb7c49b907b7ca371e59d57d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20c458b802f6ea9374783bfc528b19421be977a6769785...</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>61ef3869355b78e11011f39fc7ac8f8dfb209b3442a9d5...</td>\n",
       "      <td>1550885213307</td>\n",
       "      <td>4ed279f4f0deab6dfc80f4f7bf49d527fd894fa478a9ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20c458b802f6ea9374783bfc528b19421be977a6769785...</td>\n",
       "      <td>pageview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1550885213307</td>\n",
       "      <td>4ed279f4f0deab6dfc80f4f7bf49d527fd894fa478a9ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20c458b802f6ea9374783bfc528b19421be977a6769785...</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>d5157f8bc52965390fa21ad5842a8502bc3eb8b0930f3f...</td>\n",
       "      <td>1550885215484</td>\n",
       "      <td>7e4527ac6a32deed4f4f06bb7c49b907b7ca371e59d57d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20c458b802f6ea9374783bfc528b19421be977a6769785...</td>\n",
       "      <td>pageview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1550885215484</td>\n",
       "      <td>7e4527ac6a32deed4f4f06bb7c49b907b7ca371e59d57d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     session_id_hash     event_type  \\\n",
       "0  20c458b802f6ea9374783bfc528b19421be977a6769785...  event_product   \n",
       "1  20c458b802f6ea9374783bfc528b19421be977a6769785...  event_product   \n",
       "2  20c458b802f6ea9374783bfc528b19421be977a6769785...       pageview   \n",
       "3  20c458b802f6ea9374783bfc528b19421be977a6769785...  event_product   \n",
       "4  20c458b802f6ea9374783bfc528b19421be977a6769785...       pageview   \n",
       "\n",
       "  product_action                                   product_sku_hash  \\\n",
       "0         detail  d5157f8bc52965390fa21ad5842a8502bc3eb8b0930f3f...   \n",
       "1         detail  61ef3869355b78e11011f39fc7ac8f8dfb209b3442a9d5...   \n",
       "2            NaN                                                NaN   \n",
       "3         detail  d5157f8bc52965390fa21ad5842a8502bc3eb8b0930f3f...   \n",
       "4            NaN                                                NaN   \n",
       "\n",
       "   server_timestamp_epoch_ms  \\\n",
       "0              1550885210881   \n",
       "1              1550885213307   \n",
       "2              1550885213307   \n",
       "3              1550885215484   \n",
       "4              1550885215484   \n",
       "\n",
       "                                          hashed_url  \n",
       "0  7e4527ac6a32deed4f4f06bb7c49b907b7ca371e59d57d...  \n",
       "1  4ed279f4f0deab6dfc80f4f7bf49d527fd894fa478a9ce...  \n",
       "2  4ed279f4f0deab6dfc80f4f7bf49d527fd894fa478a9ce...  \n",
       "3  7e4527ac6a32deed4f4f06bb7c49b907b7ca371e59d57d...  \n",
       "4  7e4527ac6a32deed4f4f06bb7c49b907b7ca371e59d57d...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbaaa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.079307"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0] / 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a286a7af",
   "metadata": {},
   "source": [
    "36+ million records!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a55cd5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.iloc[0]['session_id_hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1eda8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.860037500165954"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**32 / (train.shape[0] * 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d2b36",
   "metadata": {},
   "source": [
    "We cannot accommodate even two hash columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44f6edd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>server_timestamp_epoch_ms</th>\n",
       "      <th>hashed_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>631811</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>47936</td>\n",
       "      <td>1550885210881</td>\n",
       "      <td>241663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631811</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>22091</td>\n",
       "      <td>1550885213307</td>\n",
       "      <td>151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>631811</td>\n",
       "      <td>pageview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1550885213307</td>\n",
       "      <td>151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>631811</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>47936</td>\n",
       "      <td>1550885215484</td>\n",
       "      <td>241663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>631811</td>\n",
       "      <td>pageview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1550885215484</td>\n",
       "      <td>241663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id_hash     event_type product_action  product_sku_hash  \\\n",
       "0           631811  event_product         detail             47936   \n",
       "1           631811  event_product         detail             22091   \n",
       "2           631811       pageview            NaN                -1   \n",
       "3           631811  event_product         detail             47936   \n",
       "4           631811       pageview            NaN                -1   \n",
       "\n",
       "   server_timestamp_epoch_ms  hashed_url  \n",
       "0              1550885210881      241663  \n",
       "1              1550885213307      151100  \n",
       "2              1550885213307      151100  \n",
       "3              1550885215484      241663  \n",
       "4              1550885215484      241663  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['session_id_hash'] = train['session_id_hash'].astype('category')\n",
    "categories_index = train['session_id_hash'].cat.categories\n",
    "train['session_id_hash'] = train['session_id_hash'].cat.codes\n",
    "\n",
    "train['product_sku_hash'] = train['product_sku_hash'].astype('category')\n",
    "categories_index = train['product_sku_hash'].cat.categories\n",
    "hash_to_cat_idx = {h: i for i, h in enumerate(categories_index)}\n",
    "train['product_sku_hash'] = train['product_sku_hash'].cat.codes\n",
    "\n",
    "train['hashed_url'] = train['hashed_url'].astype('category')\n",
    "categories_index = train['hashed_url'].cat.categories\n",
    "train['hashed_url'] = train['hashed_url'].cat.codes\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d3ecb",
   "metadata": {},
   "source": [
    "This is looking good and we are able to output and read in the file using `cudf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da20f283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>server_timestamp_epoch_ms</th>\n",
       "      <th>hashed_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>631811</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>47936</td>\n",
       "      <td>1550885210881</td>\n",
       "      <td>241663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631811</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>22091</td>\n",
       "      <td>1550885213307</td>\n",
       "      <td>151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>631811</td>\n",
       "      <td>pageview</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-1</td>\n",
       "      <td>1550885213307</td>\n",
       "      <td>151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>631811</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>47936</td>\n",
       "      <td>1550885215484</td>\n",
       "      <td>241663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>631811</td>\n",
       "      <td>pageview</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-1</td>\n",
       "      <td>1550885215484</td>\n",
       "      <td>241663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id_hash     event_type product_action  product_sku_hash  \\\n",
       "0           631811  event_product         detail             47936   \n",
       "1           631811  event_product         detail             22091   \n",
       "2           631811       pageview           <NA>                -1   \n",
       "3           631811  event_product         detail             47936   \n",
       "4           631811       pageview           <NA>                -1   \n",
       "\n",
       "   server_timestamp_epoch_ms  hashed_url  \n",
       "0              1550885210881      241663  \n",
       "1              1550885213307      151100  \n",
       "2              1550885213307      151100  \n",
       "3              1550885215484      241663  \n",
       "4              1550885215484      241663  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.to_parquet('/workspace/sigir_dataset/train/browsing_train.parquet')\n",
    "cudf.read_parquet('/workspace/sigir_dataset/train/browsing_train.parquet').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7ea66",
   "metadata": {},
   "source": [
    "For training on the full dataset, we would need to apply similar processing to the sku information (using the hash to index mapping we collected above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0163d658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "browsing_train.csv      search_train.csv\r\n",
      "browsing_train.parquet  sku_to_content.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls /workspace/sigir_dataset/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e20bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus = pd.read_csv('/workspace/sigir_dataset/train/sku_to_content.csv')\n",
    "\n",
    "skus['product_sku_hash'] = skus['product_sku_hash'].map(hash_to_cat_idx).fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500017c",
   "metadata": {},
   "source": [
    "This will allow us to link sessions data to pretrained embeddings.\n",
    "\n",
    "Let's now generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb1c45c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>server_timestamp_epoch_ms</th>\n",
       "      <th>hashed_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>1257</td>\n",
       "      <td>1550885210881</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>593</td>\n",
       "      <td>1550885213307</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194</td>\n",
       "      <td>pageview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1550885213307</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>1257</td>\n",
       "      <td>1550885215484</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194</td>\n",
       "      <td>pageview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1550885215484</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id_hash     event_type product_action  product_sku_hash  \\\n",
       "0              194  event_product         detail              1257   \n",
       "1              194  event_product         detail               593   \n",
       "2              194       pageview            NaN                -1   \n",
       "3              194  event_product         detail              1257   \n",
       "4              194       pageview            NaN                -1   \n",
       "\n",
       "   server_timestamp_epoch_ms  hashed_url  \n",
       "0              1550885210881        1320  \n",
       "1              1550885213307         832  \n",
       "2              1550885213307         832  \n",
       "3              1550885215484        1320  \n",
       "4              1550885215484        1320  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/workspace/sigir_dataset/train/browsing_train.csv').head(10_000)\n",
    "\n",
    "train['session_id_hash'] = train['session_id_hash'].astype('category')\n",
    "categories_index = train['session_id_hash'].cat.categories\n",
    "train['session_id_hash'] = train['session_id_hash'].cat.codes\n",
    "\n",
    "train['product_sku_hash'] = train['product_sku_hash'].astype('category')\n",
    "categories_index = train['product_sku_hash'].cat.categories\n",
    "hash_to_cat_idx = {h: i for i, h in enumerate(categories_index)}\n",
    "train['product_sku_hash'] = train['product_sku_hash'].cat.codes\n",
    "\n",
    "train['hashed_url'] = train['hashed_url'].astype('category')\n",
    "categories_index = train['hashed_url'].cat.categories\n",
    "train['hashed_url'] = train['hashed_url'].cat.codes\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63249b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1363"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.session_id_hash.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "066b0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvtabular import *\n",
    "import nvtabular as nvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f7efc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ['session_id_hash'] >> nvt.ops.Categorify(max_size=1000) >> nvt.ops.TagAsItemID()\n",
    "out += ['event_type', 'product_action', 'product_sku_hash', 'hashed_url'] >> nvt.ops.Categorify(max_size=1000)\n",
    "out += ['server_timestamp_epoch_ms'] >> nvt.ops.NormalizeMinMax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "813a55d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f83fa4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(train)\n",
    "ds_out = wf.fit_transform(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "64d75cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out.to_parquet('ds_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cb9719e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"feature\": [\r\n",
      "        {\r\n",
      "            \"name\": \"session_id_hash\",\r\n",
      "            \"type\": \"INT\",\r\n",
      "            \"intDomain\": {\r\n",
      "                \"name\": \"session_id_hash\",\r\n",
      "                \"max\": \"999\",\r\n",
      "                \"isCategorical\": true\r\n",
      "            },\r\n",
      "            \"annotation\": {\r\n",
      "                \"tag\": [\r\n",
      "                    \"id\",\r\n",
      "                    \"categorical\",\r\n",
      "                    \"item\"\r\n",
      "                ],\r\n",
      "                \"extraMetadata\": [\r\n",
      "                    {\r\n",
      "                        \"num_buckets\": null,\r\n",
      "                        \"freq_threshold\": 0.0,\r\n",
      "                        \"max_size\": 1000.0,\r\n",
      "                        \"start_index\": 0.0,\r\n",
      "                        \"cat_path\": \".//categories/unique.session_id_hash.parquet\",\r\n",
      "                        \"embedding_sizes\": {\r\n",
      "                            \"cardinality\": 1000.0,\r\n",
      "                            \"dimension\": 77.0\r\n",
      "                        },\r\n",
      "                        \"_dims\": [\r\n",
      "                            [\r\n",
      "                                0.0,\r\n",
      "                                null\r\n",
      "                            ]\r\n",
      "                        ],\r\n",
      "                        \"is_list\": false,\r\n",
      "                        \"is_ragged\": false,\r\n",
      "                        \"dtype_item_size\": 64.0\r\n",
      "                    }\r\n",
      "                ]\r\n",
      "            }\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"event_type\",\r\n",
      "            \"type\": \"INT\",\r\n",
      "            \"intDomain\": {\r\n",
      "                \"name\": \"event_type\",\r\n",
      "                \"max\": \"2\",\r\n",
      "                \"isCategorical\": true\r\n",
      "            },\r\n",
      "            \"annotation\": {\r\n",
      "                \"tag\": [\r\n",
      "                    \"categorical\"\r\n",
      "                ],\r\n",
      "                \"extraMetadata\": [\r\n",
      "                    {\r\n",
      "                        \"num_buckets\": null,\r\n",
      "                        \"freq_threshold\": 0.0,\r\n",
      "                        \"max_size\": 1000.0,\r\n",
      "                        \"start_index\": 0.0,\r\n",
      "                        \"cat_path\": \".//categories/unique.event_type.parquet\",\r\n",
      "                        \"embedding_sizes\": {\r\n",
      "                            \"cardinality\": 3.0,\r\n",
      "                            \"dimension\": 16.0\r\n",
      "                        },\r\n",
      "                        \"_dims\": [\r\n",
      "                            [\r\n",
      "                                0.0,\r\n",
      "                                null\r\n",
      "                            ]\r\n",
      "                        ],\r\n",
      "                        \"is_list\": false,\r\n",
      "                        \"is_ragged\": false,\r\n",
      "                        \"dtype_item_size\": 64.0\r\n",
      "                    }\r\n",
      "                ]\r\n",
      "            }\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"product_action\",\r\n",
      "            \"type\": \"INT\",\r\n",
      "            \"intDomain\": {\r\n",
      "                \"name\": \"product_action\",\r\n",
      "                \"max\": \"5\",\r\n",
      "                \"isCategorical\": true\r\n",
      "            },\r\n",
      "            \"annotation\": {\r\n",
      "                \"tag\": [\r\n",
      "                    \"categorical\"\r\n",
      "                ],\r\n",
      "                \"extraMetadata\": [\r\n",
      "                    {\r\n",
      "                        \"num_buckets\": null,\r\n",
      "                        \"freq_threshold\": 0.0,\r\n",
      "                        \"max_size\": 1000.0,\r\n",
      "                        \"start_index\": 0.0,\r\n",
      "                        \"cat_path\": \".//categories/unique.product_action.parquet\",\r\n",
      "                        \"embedding_sizes\": {\r\n",
      "                            \"cardinality\": 6.0,\r\n",
      "                            \"dimension\": 16.0\r\n",
      "                        },\r\n",
      "                        \"_dims\": [\r\n",
      "                            [\r\n",
      "                                0.0,\r\n",
      "                                null\r\n",
      "                            ]\r\n",
      "                        ],\r\n",
      "                        \"is_list\": false,\r\n",
      "                        \"is_ragged\": false,\r\n",
      "                        \"dtype_item_size\": 64.0\r\n",
      "                    }\r\n",
      "                ]\r\n",
      "            }\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"product_sku_hash\",\r\n",
      "            \"type\": \"INT\",\r\n",
      "            \"intDomain\": {\r\n",
      "                \"name\": \"product_sku_hash\",\r\n",
      "                \"max\": \"999\",\r\n",
      "                \"isCategorical\": true\r\n",
      "            },\r\n",
      "            \"annotation\": {\r\n",
      "                \"tag\": [\r\n",
      "                    \"categorical\"\r\n",
      "                ],\r\n",
      "                \"extraMetadata\": [\r\n",
      "                    {\r\n",
      "                        \"num_buckets\": null,\r\n",
      "                        \"freq_threshold\": 0.0,\r\n",
      "                        \"max_size\": 1000.0,\r\n",
      "                        \"start_index\": 0.0,\r\n",
      "                        \"cat_path\": \".//categories/unique.product_sku_hash.parquet\",\r\n",
      "                        \"embedding_sizes\": {\r\n",
      "                            \"cardinality\": 1000.0,\r\n",
      "                            \"dimension\": 77.0\r\n",
      "                        },\r\n",
      "                        \"_dims\": [\r\n",
      "                            [\r\n",
      "                                0.0,\r\n",
      "                                null\r\n",
      "                            ]\r\n",
      "                        ],\r\n",
      "                        \"is_list\": false,\r\n",
      "                        \"is_ragged\": false,\r\n",
      "                        \"dtype_item_size\": 64.0\r\n",
      "                    }\r\n",
      "                ]\r\n",
      "            }\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"hashed_url\",\r\n",
      "            \"type\": \"INT\",\r\n",
      "            \"intDomain\": {\r\n",
      "                \"name\": \"hashed_url\",\r\n",
      "                \"max\": \"999\",\r\n",
      "                \"isCategorical\": true\r\n",
      "            },\r\n",
      "            \"annotation\": {\r\n",
      "                \"tag\": [\r\n",
      "                    \"categorical\"\r\n",
      "                ],\r\n",
      "                \"extraMetadata\": [\r\n",
      "                    {\r\n",
      "                        \"num_buckets\": null,\r\n",
      "                        \"freq_threshold\": 0.0,\r\n",
      "                        \"max_size\": 1000.0,\r\n",
      "                        \"start_index\": 0.0,\r\n",
      "                        \"cat_path\": \".//categories/unique.hashed_url.parquet\",\r\n",
      "                        \"embedding_sizes\": {\r\n",
      "                            \"cardinality\": 1000.0,\r\n",
      "                            \"dimension\": 77.0\r\n",
      "                        },\r\n",
      "                        \"_dims\": [\r\n",
      "                            [\r\n",
      "                                0.0,\r\n",
      "                                null\r\n",
      "                            ]\r\n",
      "                        ],\r\n",
      "                        \"is_list\": false,\r\n",
      "                        \"is_ragged\": false,\r\n",
      "                        \"dtype_item_size\": 64.0\r\n",
      "                    }\r\n",
      "                ]\r\n",
      "            }\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"server_timestamp_epoch_ms\",\r\n",
      "            \"type\": \"FLOAT\",\r\n",
      "            \"annotation\": {\r\n",
      "                \"tag\": [\r\n",
      "                    \"continuous\"\r\n",
      "                ],\r\n",
      "                \"extraMetadata\": [\r\n",
      "                    {\r\n",
      "                        \"_dims\": [\r\n",
      "                            [\r\n",
      "                                0.0,\r\n",
      "                                null\r\n",
      "                            ]\r\n",
      "                        ],\r\n",
      "                        \"is_list\": false,\r\n",
      "                        \"is_ragged\": false,\r\n",
      "                        \"dtype_item_size\": 64.0\r\n",
      "                    }\r\n",
      "                ]\r\n",
      "            }\r\n",
      "        }\r\n",
      "    ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "from merlin.schema.io.tensorflow_metadata import TensorflowMetadata\n",
    "\n",
    "pb = TensorflowMetadata.from_proto_text_file(path='ds_out')\n",
    "pb.to_json_file(path='ds_out')\n",
    "\n",
    "!python3 -m json.tool ds_out/schema.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ea8e4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.datasets.synthetic import generate_data\n",
    "\n",
    "ds_done = generate_data('ds_out/schema.json', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e3de1ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>hashed_url</th>\n",
       "      <th>server_timestamp_epoch_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>612</td>\n",
       "      <td>0.993113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>665</td>\n",
       "      <td>514</td>\n",
       "      <td>0.017887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>336</td>\n",
       "      <td>994</td>\n",
       "      <td>0.507542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>434</td>\n",
       "      <td>555</td>\n",
       "      <td>0.178694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>412</td>\n",
       "      <td>0.630324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id_hash  event_type  product_action  product_sku_hash  hashed_url  \\\n",
       "0               25           1               2                 0         612   \n",
       "1              179           0               3               665         514   \n",
       "2              173           0               4               336         994   \n",
       "3                4           1               4               434         555   \n",
       "4               10           1               3               123         412   \n",
       "\n",
       "   server_timestamp_epoch_ms  \n",
       "0                   0.993113  \n",
       "1                   0.017887  \n",
       "2                   0.507542  \n",
       "3                   0.178694  \n",
       "4                   0.630324  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_done.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9e5a5200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_done.compute().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b702ce75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11     43\n",
       "9      43\n",
       "6      35\n",
       "4      34\n",
       "8      31\n",
       "       ..\n",
       "162     1\n",
       "160     1\n",
       "175     1\n",
       "76      1\n",
       "248     1\n",
       "Name: session_id_hash, Length: 127, dtype: int32"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_done.compute()['session_id_hash'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a39bb",
   "metadata": {},
   "source": [
    "Ok, so we got the schema  But the question is what to do with the sku data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c2a59d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>description_vector</th>\n",
       "      <th>category_hash</th>\n",
       "      <th>image_vector</th>\n",
       "      <th>price_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26ce7b47f4c46e4087e83e54d2f7ddc7ea57862fed2e2a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6383992be772b204a9ab75f86c86f5583d1bdd1222952d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a2c3e2430c6ef9770b903ad08fa067a6b2b9db28f06e1b...</td>\n",
       "      <td>[0.27629122138023376, -0.15763211250305176, 0....</td>\n",
       "      <td>06fa312761d4b39e2f649781514ac69a4c1505c221fc46...</td>\n",
       "      <td>[340.3592564184389, -220.19025864725685, 154.0...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1028ef615e425c328e7b95010dfb1fb93cf63749a1bc80...</td>\n",
       "      <td>[0.4058118760585785, -0.03595402091741562, 0.2...</td>\n",
       "      <td>115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...</td>\n",
       "      <td>[180.3463662921092, 222.702322343354, -8.88703...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9870c682d0d52d635501249da0eeaa118fad430b695ea1...</td>\n",
       "      <td>[-0.3206155300140381, 0.01991105079650879, 0.0...</td>\n",
       "      <td>0665a81d19c89281cc00e7f7d779ded2ed42c933838602...</td>\n",
       "      <td>[-114.81079301576219, 84.55770104232334, 85.51...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    product_sku_hash  \\\n",
       "0  26ce7b47f4c46e4087e83e54d2f7ddc7ea57862fed2e2a...   \n",
       "1  6383992be772b204a9ab75f86c86f5583d1bdd1222952d...   \n",
       "2  a2c3e2430c6ef9770b903ad08fa067a6b2b9db28f06e1b...   \n",
       "3  1028ef615e425c328e7b95010dfb1fb93cf63749a1bc80...   \n",
       "4  9870c682d0d52d635501249da0eeaa118fad430b695ea1...   \n",
       "\n",
       "                                  description_vector  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  [0.27629122138023376, -0.15763211250305176, 0....   \n",
       "3  [0.4058118760585785, -0.03595402091741562, 0.2...   \n",
       "4  [-0.3206155300140381, 0.01991105079650879, 0.0...   \n",
       "\n",
       "                                       category_hash  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  06fa312761d4b39e2f649781514ac69a4c1505c221fc46...   \n",
       "3  115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...   \n",
       "4  0665a81d19c89281cc00e7f7d779ded2ed42c933838602...   \n",
       "\n",
       "                                        image_vector  price_bucket  \n",
       "0                                                NaN           NaN  \n",
       "1                                                NaN           NaN  \n",
       "2  [340.3592564184389, -220.19025864725685, 154.0...           7.0  \n",
       "3  [180.3463662921092, 222.702322343354, -8.88703...           8.0  \n",
       "4  [-114.81079301576219, 84.55770104232334, 85.51...           2.0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skus = pd.read_csv('/workspace/sigir_dataset/train/sku_to_content.csv')\n",
    "skus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d1a18",
   "metadata": {},
   "source": [
    "I would suggest that in the example we create two branches here, if someone is using the full dataset, they can map the sku information to the product information using the dict we created above like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7a8b7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus['product_sku_hash'] = skus['product_sku_hash'].map(hash_to_cat_idx).fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bbb63f",
   "metadata": {},
   "source": [
    "And for the people taking the synthetic data route we can generate the sku information (description vectors and potentially also image vectors) as a separate branch.\n",
    "\n",
    "Once done, the two branches will merge and the rest of the example will be the same for both of the groups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
