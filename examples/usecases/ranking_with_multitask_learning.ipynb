{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f49a48e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5b7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img2 src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_models_03-exploring-different-models/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Multi-Task Learning for Ranking\n",
    "\n",
    "This notebook is created using the latest stable [merlin-tensorflow](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags) container. \n",
    "    \n",
    "In the industry, it is common to find scenarios where you need to score the likelihood of different user events regarding items, e.g., clicking, liking, sharing, commenting, following the author, etc. Instead of spending computational resources to train and deploy different models for each task, Multi-Task Learning (MTL) techniques have been popular to train a single model that are able to predict multiple targets.\n",
    "\n",
    "In this example, we demonstrate how to build and train ranking models with multiple targets. We introduce the building blocks Merlin Models provide for MTL support and also MTL-specific architectures designed for accuracy improvement of many different tasks: **MMoE**, **CGC** and **PLE**.\n",
    "\n",
    "In this example notebook, we use synthetic data based on the schema of a dataset released publicly by Tencent in the [TenRec paper](https://arxiv.org/abs/2210.10629), which is suitable for multi-task learning for providing multiple targets (types of user-item events). \n",
    "\n",
    "### Learning objectives\n",
    "- Getting to know the buiilding blocks Merlin provides for MTL\n",
    "- Training different deep learning-based ranking models with multi-task learning using Merlin Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3b8fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 21:34:55.025153: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-10 21:34:57.441575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-10 21:34:59.594193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 29249 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n",
      "2023-01-10 21:34:59.595309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30625 MB memory:  -> device: 1, name: Quadro GV100, pci bus id: 0000:2d:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "os.environ[\"TF_MEMORY_ALLOCATION\"] = \"0.9\"\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b124794",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a0c62",
   "metadata": {},
   "source": [
    "Here we generate synthetic dataset based on the schema of the `tenrec-video` dataset. The original dataset was released publicly by Tencent in the [TenRec paper](https://arxiv.org/abs/2210.10629), and is suitable for multi-task learning for providing multiple targets (types of user-item events).  \n",
    "P.s. To make the synthetic data more realistic, our data generator takes into account the original cardinalities of categorical features and the dependency of user features to user id and item features to item id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42727f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreira/projects/nvidia/nvidia_merlin/core/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/home/gmoreira/projects/nvidia/nvidia_merlin/core/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from merlin.datasets.synthetic import generate_data\n",
    "\n",
    "NUM_ROWS = os.environ.get(\"NUM_ROWS\", 100_000)\n",
    "\n",
    "train_ds, valid_ds = generate_data(\"tenrec-video\", int(NUM_ROWS), set_sizes=(0.8, 0.2))\n",
    "schema = train_ds.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea991536",
   "metadata": {},
   "source": [
    "By inspecting the columns tagging on the dataset schema, we can notice that there are number of user features (`user_id`, `gender`, `age`) and item features (`item_id`, `video_category`). There are also four binary classification targets (`click`, `follow`, `like`, and `share`) and one regression target (`watching_times`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28589d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_id</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER_ID, Tags.USER, Ta...</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.user_id.parquet</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2633851.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2633851.0</td>\n",
       "      <td>user_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_id</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL, Tags.ID, Tags.IT...</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id.parquet</td>\n",
       "      <td>512.0</td>\n",
       "      <td>179280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179280.0</td>\n",
       "      <td>item_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video_category</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.video_category.parquet</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>video_category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.gender.parquet</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.age.parquet</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>click</td>\n",
       "      <td>(Tags.BINARY_CLASSIFICATION, Tags.BINARY, Tags...</td>\n",
       "      <td>int8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>follow</td>\n",
       "      <td>(Tags.BINARY_CLASSIFICATION, Tags.BINARY, Tags...</td>\n",
       "      <td>int8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like</td>\n",
       "      <td>(Tags.BINARY_CLASSIFICATION, Tags.BINARY, Tags...</td>\n",
       "      <td>int8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>share</td>\n",
       "      <td>(Tags.BINARY_CLASSIFICATION, Tags.BINARY, Tags...</td>\n",
       "      <td>int8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>watching_times</td>\n",
       "      <td>(Tags.TARGET, Tags.REGRESSION)</td>\n",
       "      <td>int16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>watching_times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'user_id', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER_ID: 'user_id'>, <Tags.USER: 'user'>, <Tags.ID: 'id'>}, 'properties': {'max_size': 0.0, 'freq_threshold': 0.0, 'cat_path': './/categories/unique.user_id.parquet', 'embedding_sizes': {'dimension': 512.0, 'cardinality': 2633851.0}, 'num_buckets': None, 'start_index': 1.0, 'domain': {'min': 0, 'max': 2633851, 'name': 'user_id'}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'item_id', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ID: 'id'>, <Tags.ITEM_ID: 'item_id'>}, 'properties': {'start_index': 1.0, 'cat_path': './/categories/unique.item_id.parquet', 'freq_threshold': 0.0, 'max_size': 0.0, 'embedding_sizes': {'dimension': 512.0, 'cardinality': 179280.0}, 'num_buckets': None, 'domain': {'min': 0, 'max': 179280, 'name': 'item_id'}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'video_category', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'cat_path': './/categories/unique.video_category.parquet', 'embedding_sizes': {'dimension': 16.0, 'cardinality': 5.0}, 'num_buckets': None, 'max_size': 0.0, 'start_index': 1.0, 'freq_threshold': 0.0, 'domain': {'min': 0, 'max': 5, 'name': 'video_category'}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'gender', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'freq_threshold': 0.0, 'num_buckets': None, 'embedding_sizes': {'dimension': 16.0, 'cardinality': 5.0}, 'max_size': 0.0, 'start_index': 1.0, 'cat_path': './/categories/unique.gender.parquet', 'domain': {'min': 0, 'max': 5, 'name': 'gender'}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'age', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'cat_path': './/categories/unique.age.parquet', 'embedding_sizes': {'dimension': 16.0, 'cardinality': 10.0}, 'freq_threshold': 0.0, 'start_index': 1.0, 'max_size': 0.0, 'domain': {'min': 0, 'max': 10, 'name': 'age'}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'click', 'tags': {<Tags.BINARY_CLASSIFICATION: 'binary_classification'>, <Tags.BINARY: 'binary'>, <Tags.TARGET: 'target'>}, 'properties': {}, 'dtype': dtype('int8'), 'is_list': False, 'is_ragged': False}, {'name': 'follow', 'tags': {<Tags.BINARY_CLASSIFICATION: 'binary_classification'>, <Tags.BINARY: 'binary'>, <Tags.TARGET: 'target'>}, 'properties': {}, 'dtype': dtype('int8'), 'is_list': False, 'is_ragged': False}, {'name': 'like', 'tags': {<Tags.BINARY_CLASSIFICATION: 'binary_classification'>, <Tags.BINARY: 'binary'>, <Tags.TARGET: 'target'>}, 'properties': {}, 'dtype': dtype('int8'), 'is_list': False, 'is_ragged': False}, {'name': 'share', 'tags': {<Tags.BINARY_CLASSIFICATION: 'binary_classification'>, <Tags.BINARY: 'binary'>, <Tags.TARGET: 'target'>}, 'properties': {}, 'dtype': dtype('int8'), 'is_list': False, 'is_ragged': False}, {'name': 'watching_times', 'tags': {<Tags.TARGET: 'target'>, <Tags.REGRESSION: 'regression'>}, 'properties': {'domain': {'min': 0, 'max': 5, 'name': 'watching_times'}}, 'dtype': dtype('int16'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5caa9151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>item_id</th>\n",
       "      <th>video_category</th>\n",
       "      <th>click</th>\n",
       "      <th>follow</th>\n",
       "      <th>like</th>\n",
       "      <th>share</th>\n",
       "      <th>watching_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  gender  age  item_id  video_category  click  follow  like  share  \\\n",
       "0       26       1    1       11               1      1       1     1      1   \n",
       "1       25       1    1       54               1      0       0     0      1   \n",
       "2       68       1    1       11               1      0       1     0      0   \n",
       "3       45       1    1       26               1      0       1     0      0   \n",
       "4        4       1    1       12               1      1       0     0      0   \n",
       "\n",
       "   watching_times  \n",
       "0               1  \n",
       "1               1  \n",
       "2               3  \n",
       "3               2  \n",
       "4               4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing first rows of the generated dataframe\n",
    "train_ds.to_ddf().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f155bd",
   "metadata": {},
   "source": [
    "## Building and training MTL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a71708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4 * 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc4e12",
   "metadata": {},
   "source": [
    "The simplest way to build a model with Merlin Models is using `InputBlockV2` and `OutputBlock` building blocks, that infer the input features and target columns from the schema.\n",
    "The `InputBlockV2` creates the embedding layers for categorical features and concatenates all features. The `OutputBlock` creates a head `ModelOutput` for each target depending on the task type (tagged in the column schema), e.g. `RegressionOutput()` for regression, `BinaryOuput()` for binary classification, `CategoricalOutput` for multi-class classification.  \n",
    "\n",
    "You can inspect below a multi-task learning model created for this dataset with just four lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81465998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (blocks): _TupleWrapper((ParallelBlock(\n",
       "    (_aggregation): ConcatFeatures()\n",
       "    (parallel_layers): Dict(\n",
       "      (categorical): ParallelBlock(\n",
       "        (parallel_layers): Dict(\n",
       "          (user_id): EmbeddingTable(\n",
       "            (features): Dict(\n",
       "              (user_id): ColumnSchema(name='user_id', tags={<Tags.CATEGORICAL: 'categorical'>, <Tags.USER_ID: 'user_id'>, <Tags.USER: 'user'>, <Tags.ID: 'id'>}, properties={'max_size': 0.0, 'freq_threshold': 0.0, 'cat_path': './/categories/unique.user_id.parquet', 'embedding_sizes': {'dimension': 512.0, 'cardinality': 2633851.0}, 'num_buckets': None, 'start_index': 1.0, 'domain': {'min': 0, 'max': 2633851, 'name': 'user_id'}}, dtype=dtype('int32'), is_list=False, is_ragged=False)\n",
       "            )\n",
       "            (table): Embedding()\n",
       "          )\n",
       "          (item_id): EmbeddingTable(\n",
       "            (features): Dict(\n",
       "              (item_id): ColumnSchema(name='item_id', tags={<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ID: 'id'>, <Tags.ITEM_ID: 'item_id'>}, properties={'start_index': 1.0, 'cat_path': './/categories/unique.item_id.parquet', 'freq_threshold': 0.0, 'max_size': 0.0, 'embedding_sizes': {'dimension': 512.0, 'cardinality': 179280.0}, 'num_buckets': None, 'domain': {'min': 0, 'max': 179280, 'name': 'item_id'}}, dtype=dtype('int32'), is_list=False, is_ragged=False)\n",
       "            )\n",
       "            (table): Embedding()\n",
       "          )\n",
       "          (video_category): EmbeddingTable(\n",
       "            (features): Dict(\n",
       "              (video_category): ColumnSchema(name='video_category', tags={<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, properties={'cat_path': './/categories/unique.video_category.parquet', 'embedding_sizes': {'dimension': 16.0, 'cardinality': 5.0}, 'num_buckets': None, 'max_size': 0.0, 'start_index': 1.0, 'freq_threshold': 0.0, 'domain': {'min': 0, 'max': 5, 'name': 'video_category'}}, dtype=dtype('int32'), is_list=False, is_ragged=False)\n",
       "            )\n",
       "            (table): Embedding()\n",
       "          )\n",
       "          (gender): EmbeddingTable(\n",
       "            (features): Dict(\n",
       "              (gender): ColumnSchema(name='gender', tags={<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, properties={'freq_threshold': 0.0, 'num_buckets': None, 'embedding_sizes': {'dimension': 16.0, 'cardinality': 5.0}, 'max_size': 0.0, 'start_index': 1.0, 'cat_path': './/categories/unique.gender.parquet', 'domain': {'min': 0, 'max': 5, 'name': 'gender'}}, dtype=dtype('int32'), is_list=False, is_ragged=False)\n",
       "            )\n",
       "            (table): Embedding()\n",
       "          )\n",
       "          (age): EmbeddingTable(\n",
       "            (features): Dict(\n",
       "              (age): ColumnSchema(name='age', tags={<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, properties={'num_buckets': None, 'cat_path': './/categories/unique.age.parquet', 'embedding_sizes': {'dimension': 16.0, 'cardinality': 10.0}, 'freq_threshold': 0.0, 'start_index': 1.0, 'max_size': 0.0, 'domain': {'min': 0, 'max': 10, 'name': 'age'}}, dtype=dtype('int32'), is_list=False, is_ragged=False)\n",
       "            )\n",
       "            (table): Embedding()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  ), MLPBlock(\n",
       "    (layers): List(\n",
       "      (0): _Dense(\n",
       "        (dense): Dense(32, activation=relu, use_bias=True)\n",
       "      )\n",
       "      (1): _Dense(\n",
       "        (dense): Dense(16, activation=relu, use_bias=True)\n",
       "      )\n",
       "    )\n",
       "  ), ParallelBlock(\n",
       "    (parallel_layers): Dict(\n",
       "      (click/binary_output): BinaryOutput(\n",
       "        (to_call): Dense(1, activation=sigmoid, use_bias=True)\n",
       "      )\n",
       "      (follow/binary_output): BinaryOutput(\n",
       "        (to_call): Dense(1, activation=sigmoid, use_bias=True)\n",
       "      )\n",
       "      (like/binary_output): BinaryOutput(\n",
       "        (to_call): Dense(1, activation=sigmoid, use_bias=True)\n",
       "      )\n",
       "      (share/binary_output): BinaryOutput(\n",
       "        (to_call): Dense(1, activation=sigmoid, use_bias=True)\n",
       "      )\n",
       "      (watching_times/regression_output): RegressionOutput(\n",
       "        (to_call): Dense(1, activation=linear, use_bias=True)\n",
       "      )\n",
       "    )\n",
       "  )))\n",
       "  (context): ModelContext()\n",
       "  (process_list): ProcessList()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mm.Model(\n",
    "    mm.InputBlockV2(schema),\n",
    "    mm.MLPBlock([32,16]),\n",
    "    mm.OutputBlock(schema)\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a8c333",
   "metadata": {},
   "source": [
    "*Note*: If you want to build a model for just a subset of the target features, you can either remove the unwanted columns from schema: `schema.without([\"like\", \"follow\", \"share\"])`\n",
    "\n",
    "OR you can replace `mm.OutputBlock(schema)` by a `ParallelBlock` with only the desired targets:\n",
    "```python\n",
    "mm.ParallelBlock(\n",
    "  mm.BinaryOutput(\"click\"), mm.RegressionOutput(\"watching_times\")\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d685284",
   "metadata": {},
   "source": [
    "### Train and evaluation of MTL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea008b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreira/projects/nvidia/nvidia_merlin/core/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/home/gmoreira/projects/nvidia/nvidia_merlin/core/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 6s 79ms/step - loss: 8.6304 - click/binary_output_loss: 0.6932 - follow/binary_output_loss: 0.6932 - like/binary_output_loss: 0.6932 - share/binary_output_loss: 0.6945 - watching_times/regression_output_loss: 5.8563 - click/binary_output/precision: 0.5030 - click/binary_output/recall: 0.5568 - click/binary_output/binary_accuracy: 0.5007 - click/binary_output/auc: 0.5009 - follow/binary_output/precision: 0.5003 - follow/binary_output/recall: 0.5084 - follow/binary_output/binary_accuracy: 0.4986 - follow/binary_output/auc: 0.4975 - like/binary_output/precision: 0.5015 - like/binary_output/recall: 0.6516 - like/binary_output/binary_accuracy: 0.4998 - like/binary_output/auc: 0.4973 - share/binary_output/precision: 0.4838 - share/binary_output/recall: 0.0179 - share/binary_output/binary_accuracy: 0.4984 - share/binary_output/auc: 0.4961 - watching_times/regression_output/root_mean_squared_error: 2.4200 - regularization_loss: 0.0000e+00 - loss_batch: 8.6123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f594b26f520>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", run_eagerly=False)\n",
    "model.fit(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80157c3f",
   "metadata": {},
   "source": [
    "By inspecting the metrics output from model evaluation, we can observe that there are specific default metrics to each target; for binary classification (`precision`, `recall`, `binary_accuracy`, `auc`) and for regression (`root_mean_squared_error`) tasks.  \n",
    "Each task has its own loss (e.g. `click/binary_output_loss`, `watching_times/regression_output_loss`) and the `loss` is the sum of all tasks losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ed0567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 17ms/step - loss: 8.3259 - click/binary_output_loss: 0.6933 - follow/binary_output_loss: 0.6933 - like/binary_output_loss: 0.6931 - share/binary_output_loss: 0.6981 - watching_times/regression_output_loss: 5.5482 - click/binary_output/precision: 0.4777 - click/binary_output/recall: 0.0989 - click/binary_output/binary_accuracy: 0.4967 - click/binary_output/auc: 0.4955 - follow/binary_output/precision: 0.4951 - follow/binary_output/recall: 0.1938 - follow/binary_output/binary_accuracy: 0.4987 - follow/binary_output/auc: 0.4952 - like/binary_output/precision: 0.4951 - like/binary_output/recall: 0.2530 - like/binary_output/binary_accuracy: 0.5016 - like/binary_output/auc: 0.5072 - share/binary_output/precision: 0.0000e+00 - share/binary_output/recall: 0.0000e+00 - share/binary_output/binary_accuracy: 0.5016 - share/binary_output/auc: 0.4965 - watching_times/regression_output/root_mean_squared_error: 2.3555 - regularization_loss: 0.0000e+00 - loss_batch: 8.3274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 8.325882911682129,\n",
       " 'click/binary_output_loss': 0.6932552456855774,\n",
       " 'follow/binary_output_loss': 0.6932500600814819,\n",
       " 'like/binary_output_loss': 0.6930577158927917,\n",
       " 'share/binary_output_loss': 0.6981387734413147,\n",
       " 'watching_times/regression_output_loss': 5.548181056976318,\n",
       " 'click/binary_output/precision': 0.4777131676673889,\n",
       " 'click/binary_output/recall': 0.09886693954467773,\n",
       " 'click/binary_output/binary_accuracy': 0.49674999713897705,\n",
       " 'click/binary_output/auc': 0.4955274164676666,\n",
       " 'follow/binary_output/precision': 0.4951406717300415,\n",
       " 'follow/binary_output/recall': 0.1938326060771942,\n",
       " 'follow/binary_output/binary_accuracy': 0.49869999289512634,\n",
       " 'follow/binary_output/auc': 0.49518218636512756,\n",
       " 'like/binary_output/precision': 0.4950670897960663,\n",
       " 'like/binary_output/recall': 0.2529999017715454,\n",
       " 'like/binary_output/binary_accuracy': 0.5016499757766724,\n",
       " 'like/binary_output/auc': 0.5072351694107056,\n",
       " 'share/binary_output/precision': 0.0,\n",
       " 'share/binary_output/recall': 0.0,\n",
       " 'share/binary_output/binary_accuracy': 0.5016000270843506,\n",
       " 'share/binary_output/auc': 0.49647319316864014,\n",
       " 'watching_times/regression_output/root_mean_squared_error': 2.3554577827453613,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 8.334197044372559}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_ds, batch_size=BATCH_SIZE, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec16ffbb",
   "metadata": {},
   "source": [
    "### Setting loss weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831b6a5a",
   "metadata": {},
   "source": [
    "You can balance the importance of individual task losses into the final `loss` by setting `loss_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106c0e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 78ms/step - loss: 14.7591 - click/binary_output_loss: 0.6933 - follow/binary_output_loss: 0.6933 - like/binary_output_loss: 0.6939 - share/binary_output_loss: 0.7154 - watching_times/regression_output_loss: 4.9844 - click/binary_output/precision: 0.4961 - click/binary_output/recall: 0.0330 - click/binary_output/binary_accuracy: 0.4971 - click/binary_output/auc: 0.5036 - follow/binary_output/precision: 0.4995 - follow/binary_output/recall: 0.2712 - follow/binary_output/binary_accuracy: 0.4980 - follow/binary_output/auc: 0.4991 - like/binary_output/precision: 0.5057 - like/binary_output/recall: 0.0703 - like/binary_output/binary_accuracy: 0.4986 - like/binary_output/auc: 0.5012 - share/binary_output/precision: 0.0000e+00 - share/binary_output/recall: 0.0000e+00 - share/binary_output/binary_accuracy: 0.4990 - share/binary_output/auc: 0.5023 - watching_times/regression_output/root_mean_squared_error: 2.2326 - regularization_loss: 0.0000e+00 - loss_batch: 14.7168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f594b3d3e20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_weights = {\n",
    "        \"click/binary_output\": 5.0,\n",
    "        \"like/binary_output\": 4.0,\n",
    "        \"share/binary_output\": 3.0,\n",
    "        \"follow/binary_output\": 2.0,\n",
    "        \"watching_times/regression_output\": 1.0,        \n",
    "    }\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", run_eagerly=False, loss_weights=loss_weights)\n",
    "model.fit(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03486667",
   "metadata": {},
   "source": [
    "### Setting task-specific class / sample weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab76244",
   "metadata": {},
   "source": [
    "Keras supports setting `class_weight` and `sample_weight` for **single-task models** in `model.fit()`.  \n",
    "\n",
    "The `class_weight` allows weighting the classes of categorical/binary target in the loss, so that model training can pay more attention to samples from an under-represented class.  \n",
    "\n",
    "The `sample_weight` allows weighting data samples which should account more or less for the loss during training. If `weighted_metrics` is provided in `model.compile()`, then those metrics will also be weighted by `sample_weight` during training and testing.\n",
    "\n",
    "Merlin Models provides building blocks for **tasks-specific class and sample weights** with the `ColumnBasedSampleWeight` block. Here are some examples for different use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31678e8f",
   "metadata": {},
   "source": [
    "#### 1. Setting class weights per task\n",
    "Here we create an MTL model to predict `click` and `like` targets. We set negative events (0s) to have weight 1.0 and positive events (1s) to have a higher weight. As `like` target is a more rare event (sparser) than `click`  we should use higher sample weight for positive examples for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c681d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_block = mm.ParallelBlock(\n",
    "  mm.BinaryOutput(\"click\",\n",
    "                  post=mm.ColumnBasedSampleWeight(\n",
    "                        binary_class_weights=(1.0, 5.0), \n",
    "                  )), \n",
    "  mm.BinaryOutput(\"like\",\n",
    "                  post=mm.ColumnBasedSampleWeight(\n",
    "                        binary_class_weights=(1.0, 20.0), \n",
    "                  ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a749a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 73ms/step - loss: 8.6117 - click/binary_output_loss: 1.9861 - like/binary_output_loss: 6.6256 - click/binary_output/precision: 0.5018 - click/binary_output/recall: 0.9527 - click/binary_output/binary_accuracy: 0.5009 - click/binary_output/auc: 0.4943 - like/binary_output/precision: 0.5020 - like/binary_output/recall: 0.9908 - like/binary_output/binary_accuracy: 0.5019 - like/binary_output/auc: 0.5023 - regularization_loss: 0.0000e+00 - loss_batch: 8.5445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f594b57bf10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mm.Model(\n",
    "    mm.InputBlockV2(schema),\n",
    "    mm.MLPBlock([32,16]),\n",
    "    output_block\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", run_eagerly=False)\n",
    "model.fit(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572cb7c6",
   "metadata": {},
   "source": [
    "#### 2. Using other target / feature as weight per task\n",
    "Another use case would be using a feature or other target for sample weight. Just as a didactic example, we use the `user_age` feature for weighting `click` loss, and `watching_times` target column to weight `like` loss, so that examples with higher values for that column would be more accountable for the final loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5cfb4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_block = mm.ParallelBlock(\n",
    "  mm.BinaryOutput(\"click\",\n",
    "                  post=mm.ColumnBasedSampleWeight(\"age\")\n",
    "                 ), \n",
    "  mm.BinaryOutput(\"like\",\n",
    "                  post=mm.ColumnBasedSampleWeight(\"watching_times\")\n",
    "                 )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4465730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 73ms/step - loss: 2.0863 - click/binary_output_loss: 0.7007 - like/binary_output_loss: 1.3856 - click/binary_output/precision: 0.5020 - click/binary_output/recall: 0.9401 - click/binary_output/binary_accuracy: 0.5011 - click/binary_output/auc: 0.4976 - like/binary_output/precision: 0.5043 - like/binary_output/recall: 0.5230 - like/binary_output/binary_accuracy: 0.5023 - like/binary_output/auc: 0.5024 - regularization_loss: 0.0000e+00 - loss_batch: 2.0869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59486d4910>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mm.Model(\n",
    "    mm.InputBlockV2(schema),\n",
    "    mm.MLPBlock([32,16]),\n",
    "    output_block\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", run_eagerly=False)\n",
    "model.fit(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827c9df",
   "metadata": {},
   "source": [
    "#### 3. Using another binary target as sample space\n",
    "In some cases, a target might be conditioned to another binary target. For example, there might some event dependency in the system the user is interacting, so that the user can only `like` or `share` if `click` event happened first. As the more specific events are usually much less frequent than `click`, they are sparser thus suffer more from unbalanced class training. In such cases, as you can only have a positive event (i.e., `like=1`) if `click=1`, we can use that as the sample space for training `like`, i.e., the sample is only considered for `like` loss if `click=1`. Here is how you can set such sample space dependency among targets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93740d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_block = mm.ParallelBlock(\n",
    "  mm.BinaryOutput(\"click\"), \n",
    "  mm.BinaryOutput(\"like\", post=mm.ColumnBasedSampleWeight(\"click\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a4062",
   "metadata": {},
   "source": [
    "In such cases you might want to compute metrics for `like` considering only its sample space, rather than the entire space. The **`weighed_metrics`** can be used for that, as regular metrics are not influenced by sample weights.  \n",
    "We also demonstrate below how to override the default **`metrics`** per task. Metrics can be either Keras-like metrics or string aliases supported by Merlin Models (e.g., \"auc\", \"precision\", \"recall\", \"binary_accuracy\", \"rmse\", \"mse\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b8e1924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 73ms/step - loss: 1.0417 - click/binary_output_loss: 0.6932 - like/binary_output_loss: 0.3485 - click/binary_output/auc: 0.4979 - click/binary_output/weighted_auc: 0.4979 - like/binary_output/auc: 0.4991 - like/binary_output/weighted_auc: 0.4935 - regularization_loss: 0.0000e+00 - loss_batch: 1.0412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59481e9e20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mm.Model(\n",
    "    mm.InputBlockV2(schema),\n",
    "    mm.MLPBlock([32,16]),\n",
    "    output_block\n",
    ")\n",
    "\n",
    "metrics = {\n",
    "        \"click/binary_output\": [tf.keras.metrics.AUC(name=\"auc\", num_thresholds=200)],\n",
    "        \"like/binary_output\": [\"auc\"],\n",
    "    }\n",
    "\n",
    "weighted_metrics = {\n",
    "        \"click/binary_output\": [\"auc\"],\n",
    "        \"like/binary_output\": [\"auc\"],\n",
    "    }\n",
    "\n",
    "model.compile(optimizer=\"adam\", run_eagerly=False, metrics=metrics, weighted_metrics=weighted_metrics)\n",
    "model.fit(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902eec69",
   "metadata": {},
   "source": [
    "You can notice that when `weighted_metrics` are set we get the specified metrics prefixed by `weighted_`. The regular metrics for `like` (`auc`) differs from the weighted metrics (`weighted_auc`) because the latter are affected by sample weights, i.e., computed only for samples where `click=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8327b1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 9ms/step - loss: 1.0389 - click/binary_output_loss: 0.6932 - like/binary_output_loss: 0.3457 - click/binary_output/auc: 0.4990 - click/binary_output/weighted_auc: 0.4990 - like/binary_output/auc: 0.5015 - like/binary_output/weighted_auc: 0.5000 - regularization_loss: 0.0000e+00 - loss_batch: 1.0390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.038915991783142,\n",
       " 'click/binary_output_loss': 0.6932337880134583,\n",
       " 'like/binary_output_loss': 0.34568217396736145,\n",
       " 'click/binary_output/auc': 0.49904555082321167,\n",
       " 'click/binary_output/weighted_auc': 0.49904555082321167,\n",
       " 'like/binary_output/auc': 0.5014902949333191,\n",
       " 'like/binary_output/weighted_auc': 0.5000181198120117,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 1.0394577980041504}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_ds, batch_size=BATCH_SIZE, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb83a6e",
   "metadata": {},
   "source": [
    "## Multi-task learning architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44517f",
   "metadata": {},
   "source": [
    "In this section we describe different architectures for multi-task learning, which are summarized in the following illustration. The blue shapes are the ones that are shared for all tasks, and the other colored shapes are task-specific ones. We explain each of those architectures in the next sub-sections.\n",
    "\n",
    "<img src=\"../images/mtl_architectures.png\"  width=\"90%\">\n",
    "\n",
    "Image adapted from: [Progressive Layered Extraction (PLE): A Novel Multi-Task\n",
    "Learning (MTL) Model for Personalized Recommendations](https://dl.acm.org/doi/10.1145/3383313.3412236)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d9ba78",
   "metadata": {},
   "source": [
    "### Hard parameter sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0878e7",
   "metadata": {},
   "source": [
    "The examples above used a **hard parameter sharing**, where all tasks share MLP layers in the bottom, and each task has a specific single-layer MLP tower that projects the shared-bottom output to a single neuron per task (for binary classification / regression tasks).  \n",
    "We can specify more powerful task towers, so that tasks have more freedom to learn different things, with either of the following examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f55315b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_block = mm.OutputBlock(schema, task_blocks=mm.MLPBlock([32]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6aab4",
   "metadata": {},
   "source": [
    "or..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4196806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_block = mm.ParallelBlock(\n",
    "  mm.BinaryOutput(\"click\", pre=mm.MLPBlock([64])), \n",
    "  mm.BinaryOutput(\"like\",  pre=mm.MLPBlock([32]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47a1a5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 75ms/step - loss: 1.3863 - click/binary_output_loss: 0.6931 - like/binary_output_loss: 0.6932 - click/binary_output/precision: 0.5025 - click/binary_output/recall: 0.6237 - click/binary_output/binary_accuracy: 0.5004 - click/binary_output/auc: 0.5011 - like/binary_output/precision: 0.5016 - like/binary_output/recall: 0.4478 - like/binary_output/binary_accuracy: 0.4993 - like/binary_output/auc: 0.4997 - regularization_loss: 0.0000e+00 - loss_batch: 1.3863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5941ac81c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mm.Model(\n",
    "    mm.InputBlockV2(schema),\n",
    "    mm.MLPBlock([32,16]),\n",
    "    output_block\n",
    ")\n",
    "model.compile(optimizer=\"adam\", run_eagerly=False)\n",
    "model.fit(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc18f7f1",
   "metadata": {},
   "source": [
    "### MMoE architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f3d66",
   "metadata": {},
   "source": [
    "The [**Multi-gate Mixture-of-Experts (MMoE)**](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007) architecture was introduced in 2018 and is one of the most popular models for multi-task learning on tabular data. It is based on the former one-gate **Mixture of Experts (MoE)**, which proposed having different sub-networks (experts) projecting the inputs independently and then having the experts outputs weighted averaged by a gate to for a shared representation to be used for all tasks. The MMoE architecture took a step further and proposed having an independent gate for each task, so that they could choose how better combine the experts outputs. You can find more details in the [MMoE paper](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007).\n",
    "\n",
    "The MMoE architecture can be created for your dataset by with just a few lines of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97dfb313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (blocks): _TupleWrapper((ParallelBlock(\n",
      "    (_aggregation): ConcatFeatures()\n",
      "    (parallel_layers): Dict(\n",
      "      (categorical): ParallelBlock(\n",
      "        (parallel_layers): Dict(\n",
      "          (user_id): EmbeddingTable(\n",
      "            (features): Dict(\n",
      "              (user_id): ColumnSchema(name='user_id', tags={<Tags.CATEGORICAL: 'categorical'>, <Tags.USER_ID: 'user_id'>, <Tags.USER: 'user'>, <Tags.ID: 'id'>}, properties={'max_size': 0.0, 'freq_threshold': 0.0, 'cat_path': './/categories/unique.user_id.parquet', 'embedding_sizes': {'dimension': 512.0, 'cardinality': 2633851.0}, 'num_buckets': None, 'start_index': 1.0, 'domain': {'min': 0, 'max': 2633851, 'name': 'user_id'}}, dtype=dtype('int32'), is_list=False, is_ragged=False)\n",
      "            )\n",
      "            (table): Embedding()\n",
      "          )\n",
      "          (item_id): EmbeddingTable(\n",
      "            (features): Dict(\n",
      "              (item_id): ColumnSchema(name='item_id', tags={<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ID: 'id'>, <Tags.ITEM_ID: 'item_id'>}, properties={'start_index': 1.0, 'cat_path': './/categories/unique.item_id.parquet', 'freq_threshold': 0.0, 'max_size': 0.0, 'embedding_sizes': {'dimension': 512.0, 'cardinality': 179280.0}, 'num_buckets': None, 'domain': {'min': 0, 'max': 179280, 'name': 'item_id'}}, dtype=dtype('int32'), is_list=False, is_ragged=False)\n",
      "            )\n",
      "            (table): Embedding()\n",
      "          )\n",
      "          (video_category): EmbeddingTable(\n",
      "            (features): Dict(\n",
      "              (video_category): ColumnSchema(name='video_category', tags={<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, properties={'cat_path': './/categories/unique.video_category.parquet', 'embedding_sizes': {'dimension': 16.0, 'cardinality': 5.0}, 'num_buckets': None, 'max_size': 0.0, 'start_index': 1.0, 'freq_threshold': 0.0, 'domain': {'min': 0, 'max': 5, 'name': 'video_category'}}, dtype=dtype('int32'), is_list=False, is_ragged=False)\n",
      "            )\n",
      "            (table): Embedding()\n",
      "          )\n",
      "          (gender): EmbeddingTable(\n",
      "            (features): Dict(\n",
      "              (gender): ColumnSchema(name='gender', tags={<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, properties={'freq_threshold': 0.0, 'num_buckets': None, 'embedding_sizes': {'dimension': 16.0, 'cardinality': 5.0}, 'max_size': 0.0, 'start_index': 1.0, 'cat_path': './/categories/unique.gender.parquet', 'domain': {'min': 0, 'max': 5, 'name': 'gender'}}, dtype=dtype('int32'), is_list=False, is_ragged=False)\n",
      "            )\n",
      "            (table): Embedding()\n",
      "          )\n",
      "          (age): EmbeddingTable(\n",
      "            (features): Dict(\n",
      "              (age): ColumnSchema(name='age', tags={<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, properties={'num_buckets': None, 'cat_path': './/categories/unique.age.parquet', 'embedding_sizes': {'dimension': 16.0, 'cardinality': 10.0}, 'freq_threshold': 0.0, 'start_index': 1.0, 'max_size': 0.0, 'domain': {'min': 0, 'max': 10, 'name': 'age'}}, dtype=dtype('int32'), is_list=False, is_ragged=False)\n",
      "            )\n",
      "            (table): Embedding()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  ), mmoe(\n",
      "    (layers): List(\n",
      "      (0): WithShortcut(\n",
      "        (parallel_layers): Dict(\n",
      "          (experts): ParallelBlock(\n",
      "            (_aggregation): StackFeatures()\n",
      "            (parallel_layers): Dict(\n",
      "              (expert_0): SequentialBlock(\n",
      "                (layers): List(\n",
      "                  (0): _Dense(\n",
      "                    (dense): Dense(16, activation=relu, use_bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (expert_1): SequentialBlock(\n",
      "                (layers): List(\n",
      "                  (0): _Dense(\n",
      "                    (dense): Dense(16, activation=relu, use_bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (expert_2): SequentialBlock(\n",
      "                (layers): List(\n",
      "                  (0): _Dense(\n",
      "                    (dense): Dense(16, activation=relu, use_bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (expert_3): SequentialBlock(\n",
      "                (layers): List(\n",
      "                  (0): _Dense(\n",
      "                    (dense): Dense(16, activation=relu, use_bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (shortcut): NoOp()\n",
      "        )\n",
      "      )\n",
      "      (1): ParallelBlock(\n",
      "        (parallel_layers): Dict(\n",
      "          (click/binary_output): ExpertsGate(\n",
      "            (gate_block): SequentialBlock(\n",
      "              (layers): List(\n",
      "                (0): _Dense(\n",
      "                  (dense): Dense(16, activation=relu, use_bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (gate_final): Dense(4, activation=linear, use_bias=False)\n",
      "          )\n",
      "          (follow/binary_output): ExpertsGate(\n",
      "            (gate_block): SequentialBlock(\n",
      "              (layers): List(\n",
      "                (0): _Dense(\n",
      "                  (dense): Dense(16, activation=relu, use_bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (gate_final): Dense(4, activation=linear, use_bias=False)\n",
      "          )\n",
      "          (like/binary_output): ExpertsGate(\n",
      "            (gate_block): SequentialBlock(\n",
      "              (layers): List(\n",
      "                (0): _Dense(\n",
      "                  (dense): Dense(16, activation=relu, use_bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (gate_final): Dense(4, activation=linear, use_bias=False)\n",
      "          )\n",
      "          (share/binary_output): ExpertsGate(\n",
      "            (gate_block): SequentialBlock(\n",
      "              (layers): List(\n",
      "                (0): _Dense(\n",
      "                  (dense): Dense(16, activation=relu, use_bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (gate_final): Dense(4, activation=linear, use_bias=False)\n",
      "          )\n",
      "          (watching_times/regression_output): ExpertsGate(\n",
      "            (gate_block): SequentialBlock(\n",
      "              (layers): List(\n",
      "                (0): _Dense(\n",
      "                  (dense): Dense(16, activation=relu, use_bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (gate_final): Dense(4, activation=linear, use_bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  ), ParallelBlock(\n",
      "    (parallel_layers): Dict(\n",
      "      (click/binary_output): BinaryOutput(\n",
      "        (to_call): Dense(1, activation=sigmoid, use_bias=True)\n",
      "        (pre): SequentialBlock(\n",
      "          (layers): List(\n",
      "            (0): _Dense(\n",
      "              (dense): Dense(16, activation=relu, use_bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (follow/binary_output): BinaryOutput(\n",
      "        (to_call): Dense(1, activation=sigmoid, use_bias=True)\n",
      "        (pre): SequentialBlock(\n",
      "          (layers): List(\n",
      "            (0): _Dense(\n",
      "              (dense): Dense(16, activation=relu, use_bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (like/binary_output): BinaryOutput(\n",
      "        (to_call): Dense(1, activation=sigmoid, use_bias=True)\n",
      "        (pre): SequentialBlock(\n",
      "          (layers): List(\n",
      "            (0): _Dense(\n",
      "              (dense): Dense(16, activation=relu, use_bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (share/binary_output): BinaryOutput(\n",
      "        (to_call): Dense(1, activation=sigmoid, use_bias=True)\n",
      "        (pre): SequentialBlock(\n",
      "          (layers): List(\n",
      "            (0): _Dense(\n",
      "              (dense): Dense(16, activation=relu, use_bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (watching_times/regression_output): RegressionOutput(\n",
      "        (to_call): Dense(1, activation=linear, use_bias=True)\n",
      "        (pre): SequentialBlock(\n",
      "          (layers): List(\n",
      "            (0): _Dense(\n",
      "              (dense): Dense(16, activation=relu, use_bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )))\n",
      "  (context): ModelContext()\n",
      "  (process_list): ProcessList()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "inputs = mm.InputBlockV2(schema)\n",
    "output_block = mm.OutputBlock(schema, task_blocks=mm.MLPBlock([16]))\n",
    "mmoe = mm.MMOEBlock(\n",
    "    output_block,\n",
    "    expert_block=mm.MLPBlock([16]),\n",
    "    num_experts=4,\n",
    "    gate_block=mm.MLPBlock([16]),\n",
    ")\n",
    "model = mm.Model(inputs, mmoe, output_block)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2389cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 5s 82ms/step - loss: 8.4915 - click/binary_output_loss: 0.6932 - follow/binary_output_loss: 0.6931 - like/binary_output_loss: 0.6932 - share/binary_output_loss: 0.6932 - watching_times/regression_output_loss: 5.7188 - click/binary_output/precision: 0.5070 - click/binary_output/recall: 0.2953 - click/binary_output/binary_accuracy: 0.5015 - click/binary_output/auc: 0.4997 - follow/binary_output/precision: 0.5036 - follow/binary_output/recall: 0.4298 - follow/binary_output/binary_accuracy: 0.5013 - follow/binary_output/auc: 0.5019 - like/binary_output/precision: 0.4915 - like/binary_output/recall: 0.0289 - like/binary_output/binary_accuracy: 0.4973 - like/binary_output/auc: 0.5016 - share/binary_output/precision: 0.5010 - share/binary_output/recall: 0.5466 - share/binary_output/binary_accuracy: 0.5001 - share/binary_output/auc: 0.5006 - watching_times/regression_output/root_mean_squared_error: 2.3914 - regularization_loss: 0.0000e+00 - loss_batch: 8.4638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59414de040>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", run_eagerly=False)\n",
    "model.fit(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c04d721",
   "metadata": {},
   "source": [
    "### CGC and PLE architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cda70f",
   "metadata": {},
   "source": [
    "The **PLE** architecture was introduced in 2020 in this [paper](https://dl.acm.org/doi/10.1145/3383313.3412236). The authors observed that architectures like **MMoE** presented a \"seesaw\" phenomenon, where improving the accuracy of one task hurts the accuracy of other tasks.  \n",
    "So instead of having all tasks sharing all the experts, the proposed allowing for some task-specific experts and shared experts, which they named **Customized Gate Control (CGC) Model**, for which we provide a building block.   \n",
    "Notice that `CGCBlock` has separate arguments for `num_task_experts` and `num_shared_experts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db017305",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = mm.InputBlockV2(schema)\n",
    "output_block = mm.OutputBlock(schema, task_blocks=mm.MLPBlock([16]))\n",
    "\n",
    "cgc = mm.CGCBlock(\n",
    "    output_block,\n",
    "    expert_block=mm.MLPBlock([16]),\n",
    "    num_task_experts=2,\n",
    "    num_shared_experts=3,\n",
    "    schema=schema,\n",
    ")\n",
    "model = mm.Model(inputs, cgc, output_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beb41d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 6s 92ms/step - loss: 8.3485 - click/binary_output_loss: 0.6932 - follow/binary_output_loss: 0.6932 - like/binary_output_loss: 0.6932 - share/binary_output_loss: 0.6932 - watching_times/regression_output_loss: 5.5758 - click/binary_output/precision: 0.5015 - click/binary_output/recall: 0.5126 - click/binary_output/binary_accuracy: 0.4989 - click/binary_output/auc: 0.4988 - follow/binary_output/precision: 0.5007 - follow/binary_output/recall: 0.8231 - follow/binary_output/binary_accuracy: 0.4994 - follow/binary_output/auc: 0.4988 - like/binary_output/precision: 0.5046 - like/binary_output/recall: 0.6862 - like/binary_output/binary_accuracy: 0.5041 - like/binary_output/auc: 0.5018 - share/binary_output/precision: 0.5010 - share/binary_output/recall: 0.9992 - share/binary_output/binary_accuracy: 0.5011 - share/binary_output/auc: 0.5003 - watching_times/regression_output/root_mean_squared_error: 2.3613 - regularization_loss: 0.0000e+00 - loss_batch: 8.3093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59409ba310>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", run_eagerly=False)\n",
    "model.fit(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4839e",
   "metadata": {},
   "source": [
    "Furthermore, the [paper](https://dl.acm.org/doi/10.1145/3383313.3412236) authors proposed stacking multiple **CGC** model on top of each other to form a multi-level MTL model, which they called **Progressive Layered Extraction (PLE)**. The `PLEBlock` introduces the `num_layers`, which controls the number of levels.   \n",
    "\n",
    "You can see how easy is to use such a state-of-the-art MTL model with just a few lines of code with Merlin Models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "292fc1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = mm.InputBlockV2(schema)\n",
    "output_block = mm.OutputBlock(schema, task_blocks=mm.MLPBlock([16]))\n",
    "\n",
    "ple = mm.PLEBlock(\n",
    "    num_layers=2,\n",
    "    outputs=output_block,\n",
    "    expert_block=mm.MLPBlock([16]),\n",
    "    num_task_experts=2,\n",
    "    num_shared_experts=1,\n",
    ")\n",
    "model = mm.Model(inputs, ple, output_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e83b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 6s 90ms/step - loss: 8.5055 - click/binary_output_loss: 0.6932 - follow/binary_output_loss: 0.6932 - like/binary_output_loss: 0.6932 - share/binary_output_loss: 0.6932 - watching_times/regression_output_loss: 5.7328 - click/binary_output/precision: 0.5004 - click/binary_output/recall: 0.5308 - click/binary_output/binary_accuracy: 0.4978 - click/binary_output/auc: 0.4974 - follow/binary_output/precision: 0.5017 - follow/binary_output/recall: 0.9253 - follow/binary_output/binary_accuracy: 0.5015 - follow/binary_output/auc: 0.4972 - like/binary_output/precision: 0.5029 - like/binary_output/recall: 0.1909 - like/binary_output/binary_accuracy: 0.4989 - like/binary_output/auc: 0.5003 - share/binary_output/precision: 0.4974 - share/binary_output/recall: 0.4365 - share/binary_output/binary_accuracy: 0.4967 - share/binary_output/auc: 0.4996 - watching_times/regression_output/root_mean_squared_error: 2.3943 - regularization_loss: 0.0000e+00 - loss_batch: 8.4802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5927bce7f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", run_eagerly=False)\n",
    "model.fit(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14b446f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 24ms/step - loss: 8.0857 - click/binary_output_loss: 0.6932 - follow/binary_output_loss: 0.6932 - like/binary_output_loss: 0.6931 - share/binary_output_loss: 0.6931 - watching_times/regression_output_loss: 5.3131 - click/binary_output/precision: 0.5066 - click/binary_output/recall: 0.0726 - click/binary_output/binary_accuracy: 0.5023 - click/binary_output/auc: 0.4978 - follow/binary_output/precision: 0.4993 - follow/binary_output/recall: 0.9997 - follow/binary_output/binary_accuracy: 0.4992 - follow/binary_output/auc: 0.4951 - like/binary_output/precision: 0.4930 - like/binary_output/recall: 0.1340 - like/binary_output/binary_accuracy: 0.5023 - like/binary_output/auc: 0.5016 - share/binary_output/precision: 0.5007 - share/binary_output/recall: 0.7635 - share/binary_output/binary_accuracy: 0.5027 - share/binary_output/auc: 0.5005 - watching_times/regression_output/root_mean_squared_error: 2.3050 - regularization_loss: 0.0000e+00 - loss_batch: 8.0871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 8.085714340209961,\n",
       " 'click/binary_output_loss': 0.693152666091919,\n",
       " 'follow/binary_output_loss': 0.693204402923584,\n",
       " 'like/binary_output_loss': 0.6931298971176147,\n",
       " 'share/binary_output_loss': 0.6931481957435608,\n",
       " 'watching_times/regression_output_loss': 5.313078880310059,\n",
       " 'click/binary_output/precision': 0.5066480040550232,\n",
       " 'click/binary_output/recall': 0.0725960060954094,\n",
       " 'click/binary_output/binary_accuracy': 0.5023000240325928,\n",
       " 'click/binary_output/auc': 0.49784404039382935,\n",
       " 'follow/binary_output/precision': 0.49932488799095154,\n",
       " 'follow/binary_output/recall': 0.9996996521949768,\n",
       " 'follow/binary_output/binary_accuracy': 0.49924999475479126,\n",
       " 'follow/binary_output/auc': 0.495095431804657,\n",
       " 'like/binary_output/precision': 0.49295252561569214,\n",
       " 'like/binary_output/recall': 0.13401229679584503,\n",
       " 'like/binary_output/binary_accuracy': 0.5022500157356262,\n",
       " 'like/binary_output/auc': 0.5016313195228577,\n",
       " 'share/binary_output/precision': 0.500723659992218,\n",
       " 'share/binary_output/recall': 0.7635433673858643,\n",
       " 'share/binary_output/binary_accuracy': 0.5026999711990356,\n",
       " 'share/binary_output/auc': 0.5005159974098206,\n",
       " 'watching_times/regression_output/root_mean_squared_error': 2.305011510848999,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 8.093406677246094}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_results = model.evaluate(valid_ds, batch_size=BATCH_SIZE, return_dict=True)\n",
    "metrics_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "merlin": {
   "containers": [
    "nvcr.io/nvidia/merlin/merlin-tensorflow:latest"
   ]
  },
  "vscode": {
   "interpreter": {
    "hash": "67b01b24cb2518309f0749863665ff82dad1ad60adc88cabbb59c99b73117545"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
