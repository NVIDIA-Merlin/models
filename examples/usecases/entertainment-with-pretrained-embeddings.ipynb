{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e97432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/examples/usecases\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028dc96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120df1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697d1452",
   "metadata": {},
   "source": [
    "In this use case we will consider how we might train with pretrained embeddings.\n",
    "\n",
    "Pretrained embeddings can allow our model to include information from other modalities (for instance, we might want to grab CNN descriptors of product images). They can also come from other models that we train on our data. For example, we might train a word2vec model on the sequence of purchased items by a customer and want to include this information in our retrieval or ranking model.\n",
    "\n",
    "The use cases are many, but this particular example will focus just on the technical aspects of working with pretrained embeddings.\n",
    "\n",
    "We will use the MovieLens 100k dataset and emulate a scenario where we would have a pretrained embedding for each of the movies in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c63b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 04:02:20.693184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 04:02:20.693584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 04:02:20.693744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 04:02:20.715031: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-13 04:02:20.715735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 04:02:20.715924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 04:02:20.716074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 04:02:21.398757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 04:02:21.398961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 04:02:21.399109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 04:02:21.399237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24576 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import merlin.models.tf as mm\n",
    "from merlin.datasets.entertainment import get_movielens\n",
    "from merlin.schema.tags import Tags\n",
    "import tensorflow as tf\n",
    "from merlin.models.tf.prediction_tasks.classification import BinaryClassificationTask\n",
    "from merlin.models.tf.blocks import *\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13fed8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1292: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train, valid = get_movielens(variant=\"ml-100k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffcd098e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rating_binary'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = train.schema.select_by_tag(Tags.TARGET).column_names[1]\n",
    "target_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60873da",
   "metadata": {},
   "source": [
    "From the schema, we can tell that there are 1681 known movie ids in the dataset. The movideId to movie mapping is stored in `.//categories/unique.movieId.parquet`. Let's read the file and take a closer look at the situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58c9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "movieIds = cudf.read_parquet('.//categories/unique.movieId.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32b861e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>movieId_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>1678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1681 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieId  movieId_size\n",
       "0       <NA>             0\n",
       "1         50           495\n",
       "2        100           443\n",
       "3        181           439\n",
       "4        258           412\n",
       "...      ...           ...\n",
       "1676    1678             1\n",
       "1677    1679             1\n",
       "1678    1680             1\n",
       "1679    1681             1\n",
       "1680    1682             1\n",
       "\n",
       "[1681 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieIds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d624d4",
   "metadata": {},
   "source": [
    "The highest movie id in the train dataset is 1682 with movie ID 0 being left for movies not seen in the train set.\n",
    "\n",
    "Let's create a mock embedding matrix. In a regular scenario, that is where our pretrained embeddings would go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc919e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_movie_embs = np.random.random((1682, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dec89b",
   "metadata": {},
   "source": [
    "Let us now feed this into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22af1945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 04:02:21.868740: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "model = mm.DCNModel(\n",
    "train.schema,\n",
    "    depth=2,\n",
    "    deep_block=mm.MLPBlock([64, 32]),\n",
    "    prediction_tasks=mm.BinaryClassificationTask(target_column),\n",
    "    embedding_options=mm.EmbeddingOptions(\n",
    "        embeddings_initializers={\n",
    "            \"movieId\": mm.TensorInitializer(pretrained_movie_embs),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d78213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "89/89 [==============================] - 3s 9ms/step - loss: 0.6272 - auc: 0.6957 - val_loss: 0.6297 - val_auc: 0.6856\n",
      "Epoch 2/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.6159 - auc: 0.7136 - val_loss: 0.6318 - val_auc: 0.6870\n",
      "Epoch 3/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.6138 - auc: 0.7162 - val_loss: 0.6323 - val_auc: 0.6888\n",
      "Epoch 4/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.6111 - auc: 0.7198 - val_loss: 0.6346 - val_auc: 0.6920\n",
      "Epoch 5/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.6045 - auc: 0.7277 - val_loss: 0.6242 - val_auc: 0.6989\n",
      "Epoch 6/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.5895 - auc: 0.7456 - val_loss: 0.6092 - val_auc: 0.7096\n",
      "Epoch 7/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.5771 - auc: 0.7599 - val_loss: 0.6026 - val_auc: 0.7189\n",
      "Epoch 8/10\n",
      "89/89 [==============================] - 1s 5ms/step - loss: 0.5698 - auc: 0.7679 - val_loss: 0.5973 - val_auc: 0.7258\n",
      "Epoch 9/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.5664 - auc: 0.7717 - val_loss: 0.5990 - val_auc: 0.7311\n",
      "Epoch 10/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.5636 - auc: 0.7746 - val_loss: 0.5907 - val_auc: 0.7354\n",
      "CPU times: user 13 s, sys: 1.15 s, total: 14.2 s\n",
      "Wall time: 8.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3a516d910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "opt = tf.keras.optimizers.Adagrad(learning_rate=1e-1)\n",
    "model.compile(optimizer=opt, run_eagerly=False, metrics=[tf.keras.metrics.AUC()])\n",
    "model.fit(train, validation_data=valid, batch_size=1024, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96ac21",
   "metadata": {},
   "source": [
    "The model trains and we have utilized pretrained embeddings "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
