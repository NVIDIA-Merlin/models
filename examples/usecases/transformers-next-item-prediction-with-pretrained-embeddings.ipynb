{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0df10e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# cd /core\n",
    "# git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "# pip install . --no-deps\n",
    "\n",
    "# cd /dataloader\n",
    "# git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "# pip install . --no-deps\n",
    "\n",
    "# cd /nvtabular\n",
    "# git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "# pip install . --no-deps\n",
    "\n",
    "# cd /systems\n",
    "# git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "# pip install . --no-deps\n",
    "\n",
    "# cd /transformers4rec\n",
    "# git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "# pip install . --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b545747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions anda\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6d3b8",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_models-transformers-net-item-prediction/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Transformer-based architecture for next-item prediction task with pretrained embeddings\n",
    "\n",
    "This notebook is created using the latest stable [merlin-tensorflow](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags) container.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this use case we will train a Transformer-based architecture for next-item prediction task with pretrained embeddings.\n",
    "\n",
    "**You can chose to download the full dataset manually or use synthetic data.**\n",
    "\n",
    "We will use the [SIGIR eCOM 2021 Data Challenge Dataset](https://github.com/coveooss/SIGIR-ecom-data-challenge) to train a session-based model. The dataset contains 36M events of users browsing an online store.\n",
    "\n",
    "We will reshape the data to organize it into 'sessions'. Each session will be a full customer online journey in chronological order. The goal will be to predict the `url` of the next action taken.\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Training a Transformer-based architecture for next-item prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b847f",
   "metadata": {},
   "source": [
    "## Downloading and preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dd7827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nvtabular as nvt\n",
    "from merlin.schema import ColumnSchema, Schema, Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b470a6",
   "metadata": {},
   "source": [
    "You can download the full dataset by registering [here](https://www.coveo.com/en/ailabs/sigir-ecom-data-challenge). If you chose to download the data, please place it alongside this notebook in the `sigir_dataset` directory and extract it.\n",
    "\n",
    "To process the downloaded data uncomment the cell below.\n",
    "\n",
    "By default, in this notebook, we will be using synthetically generated data based on the SIGIR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ccad8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unocomment this cell to use the original SIGIR dataset.\n",
    "\n",
    "# train = nvt.Dataset('/workspace/sigir_dataset/train/browsing_train.csv', part_size='500MB')\n",
    "# skus = nvt.Dataset('/workspace/sigir_dataset/train/sku_to_content.csv')\n",
    "\n",
    "# skus = pd.read_csv('/workspace/sigir_dataset/train/sku_to_content.csv')\n",
    "\n",
    "# skus['description_vector'] = skus['description_vector'].replace(np.nan, '')\n",
    "# skus['image_vector'] = skus['image_vector'].replace(np.nan, '')\n",
    "\n",
    "# skus['description_vector'] = skus['description_vector'].apply(lambda x: [] if len(x) == 0 else eval(x))\n",
    "# skus['image_vector'] = skus['image_vector'].apply(lambda x: [] if len(x) == 0 else eval(x))\n",
    "# skus = skus[skus.description_vector.apply(len) > 0]\n",
    "# skus = nvt.Dataset(skus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b96e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.datasets.synthetic import generate_data\n",
    "\n",
    "train = generate_data('sigir-browsing', 1000)\n",
    "skus = generate_data('sigir-sku', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac47bc4e",
   "metadata": {},
   "source": [
    "The `skus` dataset contains the mapping between the `product_sku_hash` (essentially an item id) to the `description_vector` -- an embedding obtained from the description.\n",
    "\n",
    "To use this information in our model, we need to map the `product_sku_hash` information to an id.\n",
    "\n",
    "But we need to make sure that the way we process `skus` and the `train` dataset (event information) is consistent. That the same `product_sku_hash` is mapped to the same id both when processing `skus` and `train`.\n",
    "\n",
    "We do so by defining and fitting a `Categorify` op and using it to process both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b187289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>hashed_url</th>\n",
       "      <th>server_timestamp_epoch_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>375</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>570</td>\n",
       "      <td>0.136624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>403</td>\n",
       "      <td>0.393882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>549</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>505</td>\n",
       "      <td>0.612437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>328</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>253</td>\n",
       "      <td>0.575691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_sku_hash  event_type  product_action  session_id_hash  hashed_url  \\\n",
       "0               375           3               5               15         570   \n",
       "1                23           4               4               13         403   \n",
       "2               549           4               3               12           3   \n",
       "3               148           3               5               28         505   \n",
       "4               328           3               3               31         253   \n",
       "\n",
       "   server_timestamp_epoch_ms  \n",
       "0                   0.136624  \n",
       "1                   0.393882  \n",
       "2                   0.557738  \n",
       "3                   0.612437  \n",
       "4                   0.575691  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_op = nvt.ops.Categorify()\n",
    "out = ['product_sku_hash'] >> cat_op >> nvt.ops.TagAsItemID()\n",
    "out += ['event_type', 'product_action', 'session_id_hash', 'hashed_url'] >> nvt.ops.Categorify()\n",
    "out += ['server_timestamp_epoch_ms'] >> nvt.ops.NormalizeMinMax()\n",
    "\n",
    "wf = nvt.Workflow(out)\n",
    "\n",
    "train = wf.fit_transform(train)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f12dbd",
   "metadata": {},
   "source": [
    "Now that we have processed the train set, we can use the mapping preserved in the `cat_op` to process the `skus` dataset containing the embeddings we are after.\n",
    "\n",
    "Let's now `Categorify` the `product_sku_hash` in `skus` and grab just the description embedding information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313808d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>description_vector</th>\n",
       "      <th>category_hash</th>\n",
       "      <th>price_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>[0.19074470948308836, -0.03131100529154618, 0....</td>\n",
       "      <td>26</td>\n",
       "      <td>0.092083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>[-0.2518207082929709, -0.20303765932361634, 0....</td>\n",
       "      <td>54</td>\n",
       "      <td>0.043740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>[-0.3638074882104804, -0.10183149710489742, -0...</td>\n",
       "      <td>99</td>\n",
       "      <td>0.185579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>[-0.38035569346313397, 0.06832374946505887, -0...</td>\n",
       "      <td>33</td>\n",
       "      <td>0.497887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>[0.35193821537813347, 0.41277890253984556, 0.1...</td>\n",
       "      <td>82</td>\n",
       "      <td>0.544694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_sku_hash                                 description_vector  \\\n",
       "0                49  [0.19074470948308836, -0.03131100529154618, 0....   \n",
       "1                32  [-0.2518207082929709, -0.20303765932361634, 0....   \n",
       "2                 9  [-0.3638074882104804, -0.10183149710489742, -0...   \n",
       "3                97  [-0.38035569346313397, 0.06832374946505887, -0...   \n",
       "4                14  [0.35193821537813347, 0.41277890253984556, 0.1...   \n",
       "\n",
       "   category_hash  price_bucket  \n",
       "0             26      0.092083  \n",
       "1             54      0.043740  \n",
       "2             99      0.185579  \n",
       "3             33      0.497887  \n",
       "4             82      0.544694  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfad1bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>description_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.19074470948308836, -0.03131100529154618, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>[-0.2518207082929709, -0.20303765932361634, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.3638074882104804, -0.10183149710489742, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298</td>\n",
       "      <td>[-0.38035569346313397, 0.06832374946505887, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270</td>\n",
       "      <td>[0.35193821537813347, 0.41277890253984556, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_sku_hash                                 description_vector\n",
       "0                 2  [0.19074470948308836, -0.03131100529154618, 0....\n",
       "1               106  [-0.2518207082929709, -0.20303765932361634, 0....\n",
       "2                 2  [-0.3638074882104804, -0.10183149710489742, -0...\n",
       "3               298  [-0.38035569346313397, 0.06832374946505887, -0...\n",
       "4               270  [0.35193821537813347, 0.41277890253984556, 0.1..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = ['product_sku_hash'] >> cat_op\n",
    "wf = nvt.Workflow(out + 'description_vector')\n",
    "skus_ds = wf.transform(skus)\n",
    "\n",
    "skus_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9bcc1",
   "metadata": {},
   "source": [
    "Let us now export the embedding information to a `numpy` array and write it to disk.\n",
    "\n",
    "We will later pass this information so that the `Loader` will load the correct emebedding for the products corresponding to the given step of a customer journey.\n",
    "\n",
    "The embeddings are linked to the train set using the `product_sku_hash` information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99dfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus_ds.to_npy('skus.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3906a7",
   "metadata": {},
   "source": [
    "How will the `Loader` know which embedding to associated with a given row of the train set?\n",
    "\n",
    "The `product_sku_hash` ids have been exported along with the embeddings and are contained in the first column of the output `numpy` array.\n",
    "\n",
    "Here is the id of the first embedding stored in `skus.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60c6651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('skus.npy')[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5aba4",
   "metadata": {},
   "source": [
    "and here is the embedding vector corresponding to `product_sku_hash` of id referenced above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd613cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19074471, -0.03131101,  0.0201479 ,  0.53804358,  0.39359061,\n",
       "       -0.32382233,  0.51149587,  0.49506202,  0.60158905,  0.3474365 ,\n",
       "        0.47490941,  0.3104798 , -0.2218935 , -0.34076992, -0.24330408,\n",
       "       -0.39893738,  0.26564596,  0.58610945,  0.40313457,  0.13064291,\n",
       "        0.34864956,  0.1488015 , -0.38335331,  0.42396508, -0.0792708 ,\n",
       "        0.56811159, -0.38731376, -0.43323464, -0.3575653 ,  0.02976547,\n",
       "        0.3375143 , -0.39471757, -0.11737858,  0.57075452,  0.14806672,\n",
       "       -0.01940817,  0.20723742,  0.07139346, -0.28549599,  0.44750621,\n",
       "       -0.28758708, -0.25481674,  0.06444519,  0.43473896, -0.33112008,\n",
       "        0.58701177,  0.47687082, -0.25761298,  0.37786294,  0.35886267])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('skus.npy')[0, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8085dc88",
   "metadata": {},
   "source": [
    "Let us now construct the `Loader` that will provide the data to our model.\n",
    "\n",
    "Let us first rearrange the `train` dataset to group the actions by `session_id_hash`. Actions within a session will be contained in a single row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51160169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>product_sku_hash_list</th>\n",
       "      <th>event_type_list</th>\n",
       "      <th>product_action_list</th>\n",
       "      <th>hashed_url_list</th>\n",
       "      <th>server_timestamp_epoch_ms_list</th>\n",
       "      <th>hashed_url_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[237, 261, 88, 22, 610, 159, 275, 156, 611, 48...</td>\n",
       "      <td>[4, 4, 4, 3, 4, 3, 3, 4, 4, 3, 4, 4, 3, 4, 4, ...</td>\n",
       "      <td>[3, 4, 3, 3, 4, 6, 4, 4, 3, 5, 6, 5, 6, 5, 4, ...</td>\n",
       "      <td>[435, 3, 35, 272, 167, 42, 502, 512, 180, 146,...</td>\n",
       "      <td>[0.004735263430550937, 0.050407877989059435, 0...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>[154, 78, 417, 162, 71, 6, 3, 369, 91, 259, 25...</td>\n",
       "      <td>[3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 4, ...</td>\n",
       "      <td>[4, 3, 6, 4, 5, 3, 5, 3, 3, 4, 5, 6, 5, 5, 3, ...</td>\n",
       "      <td>[75, 29, 175, 212, 423, 134, 8, 485, 61, 245, ...</td>\n",
       "      <td>[0.026263786969227345, 0.0973746012991237, 0.1...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[508, 117, 85, 43, 40, 15, 128, 170, 578, 87, ...</td>\n",
       "      <td>[4, 4, 3, 4, 4, 4, 3, 3, 4, 3, 4, 3, 3, 3, 4, ...</td>\n",
       "      <td>[4, 5, 5, 4, 6, 4, 3, 4, 3, 6, 5, 4, 6, 4, 5, ...</td>\n",
       "      <td>[18, 611, 140, 17, 140, 90, 96, 162, 230, 68, ...</td>\n",
       "      <td>[0.004323552121669836, 0.030039676699837904, 0...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[222, 566, 505, 210, 266, 138, 43, 142, 41, 27...</td>\n",
       "      <td>[3, 4, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 3, 3, ...</td>\n",
       "      <td>[4, 5, 3, 6, 3, 4, 5, 3, 6, 6, 4, 5, 3, 6, 4, ...</td>\n",
       "      <td>[256, 368, 10, 251, 325, 72, 173, 181, 585, 19...</td>\n",
       "      <td>[0.03764613117847081, 0.1714338844084301, 0.17...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[307, 367, 284, 305, 354, 9, 183, 205, 112, 27...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 4, 4, 3, ...</td>\n",
       "      <td>[4, 3, 6, 4, 3, 4, 5, 5, 4, 4, 6, 5, 4, 5, 4, ...</td>\n",
       "      <td>[14, 321, 580, 54, 108, 574, 181, 427, 566, 58...</td>\n",
       "      <td>[0.024009896481330915, 0.054163690625947336, 0...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id_hash                              product_sku_hash_list  \\\n",
       "0                3  [237, 261, 88, 22, 610, 159, 275, 156, 611, 48...   \n",
       "1                4  [154, 78, 417, 162, 71, 6, 3, 369, 91, 259, 25...   \n",
       "2                5  [508, 117, 85, 43, 40, 15, 128, 170, 578, 87, ...   \n",
       "3                6  [222, 566, 505, 210, 266, 138, 43, 142, 41, 27...   \n",
       "4                7  [307, 367, 284, 305, 354, 9, 183, 205, 112, 27...   \n",
       "\n",
       "                                     event_type_list  \\\n",
       "0  [4, 4, 4, 3, 4, 3, 3, 4, 4, 3, 4, 4, 3, 4, 4, ...   \n",
       "1  [3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 4, ...   \n",
       "2  [4, 4, 3, 4, 4, 4, 3, 3, 4, 3, 4, 3, 3, 3, 4, ...   \n",
       "3  [3, 4, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 3, 3, ...   \n",
       "4  [3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 4, 4, 3, ...   \n",
       "\n",
       "                                 product_action_list  \\\n",
       "0  [3, 4, 3, 3, 4, 6, 4, 4, 3, 5, 6, 5, 6, 5, 4, ...   \n",
       "1  [4, 3, 6, 4, 5, 3, 5, 3, 3, 4, 5, 6, 5, 5, 3, ...   \n",
       "2  [4, 5, 5, 4, 6, 4, 3, 4, 3, 6, 5, 4, 6, 4, 5, ...   \n",
       "3  [4, 5, 3, 6, 3, 4, 5, 3, 6, 6, 4, 5, 3, 6, 4, ...   \n",
       "4  [4, 3, 6, 4, 3, 4, 5, 5, 4, 4, 6, 5, 4, 5, 4, ...   \n",
       "\n",
       "                                     hashed_url_list  \\\n",
       "0  [435, 3, 35, 272, 167, 42, 502, 512, 180, 146,...   \n",
       "1  [75, 29, 175, 212, 423, 134, 8, 485, 61, 245, ...   \n",
       "2  [18, 611, 140, 17, 140, 90, 96, 162, 230, 68, ...   \n",
       "3  [256, 368, 10, 251, 325, 72, 173, 181, 585, 19...   \n",
       "4  [14, 321, 580, 54, 108, 574, 181, 427, 566, 58...   \n",
       "\n",
       "                      server_timestamp_epoch_ms_list  hashed_url_count  \n",
       "0  [0.004735263430550937, 0.050407877989059435, 0...                36  \n",
       "1  [0.026263786969227345, 0.0973746012991237, 0.1...                31  \n",
       "2  [0.004323552121669836, 0.030039676699837904, 0...                31  \n",
       "3  [0.03764613117847081, 0.1714338844084301, 0.17...                31  \n",
       "4  [0.024009896481330915, 0.054163690625947336, 0...                29  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_features = train.head().columns.tolist() >> nvt.ops.Groupby(\n",
    "    groupby_cols=['session_id_hash'],\n",
    "    aggs={\n",
    "        'product_sku_hash': ['list'],\n",
    "        'event_type': ['list'],\n",
    "        'product_action': ['list'],\n",
    "        'hashed_url': ['list', 'count'],\n",
    "        'server_timestamp_epoch_ms': ['list']\n",
    "    },\n",
    "    sort_cols=\"server_timestamp_epoch_ms\"\n",
    ")\n",
    "\n",
    "MINIMUM_SESSION_LENGTH = 5\n",
    "filtered_sessions = groupby_features >> nvt.ops.Filter(f=lambda df: df[\"hashed_url_count\"] >= MINIMUM_SESSION_LENGTH) \n",
    "\n",
    "wf = nvt.Workflow(filtered_sessions)\n",
    "train_processed = wf.fit_transform(train)\n",
    "\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74874dee",
   "metadata": {},
   "source": [
    "We are now ready to construct the `Loader` that will feed the data to our model.\n",
    "\n",
    "We begin by reading in the embeddings information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36c44b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('skus.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af71341d",
   "metadata": {},
   "source": [
    "Let's disard from the schema the columns that we will not be using to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c0122da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed.schema = train_processed.schema.remove_col('session_id_hash').remove_col('hashed_url_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f0368",
   "metadata": {},
   "source": [
    "We are now ready to define the `Loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdbe801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/dataloader/tensorflow.py:65: UserWarning: Due to a CUDA memory alignment issue in some Tensorflow operations such as Embedding ops, we recommend that 'batch_size' be at least 16 and also a power of two. Please change 'batch_size' to a number that is a power of two that is greater than or equal to 16.\n",
      "  warnings.warn(\n",
      "2023-06-13 02:31:28.552435: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 02:31:28.553593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 02:31:28.553786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 02:31:28.553930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 02:31:28.554148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 02:31:28.554300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 02:31:28.554446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 02:31:28.554559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24576 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from merlin.dataloader.tensorflow import Loader\n",
    "from merlin.dataloader.ops.embeddings import EmbeddingOperator\n",
    "\n",
    "loader = Loader(\n",
    "    train_processed,\n",
    "    batch_size=10,\n",
    "    transforms=[\n",
    "        EmbeddingOperator(\n",
    "            embeddings[:, 1:],\n",
    "            id_lookup_table=embeddings[:, 0].astype(int),\n",
    "            lookup_key=\"product_sku_hash_list\",\n",
    "        )\n",
    "    ],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db925ff0",
   "metadata": {},
   "source": [
    "Using the `EmbeddingOperator` object we referenced our `embeddings` and advised the model what to use as a key to look up the information.\n",
    "\n",
    "Below is an example batch of data that our model will consume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c164b141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'product_sku_hash_list__values': <tf.Tensor: shape=(161,), dtype=int64, numpy=\n",
       "  array([356,  46, 592, 500, 501, 434, 509, 556, 320, 210, 604, 247, 140,\n",
       "         539, 557, 257, 182, 526, 232, 165, 160, 222, 566, 505, 210, 266,\n",
       "         138,  43, 142,  41, 279, 493,  97, 269, 163,   6, 131, 147, 110,\n",
       "          89, 494,  40, 258, 231,   8, 461, 173,  33, 227,  59, 585, 391,\n",
       "          42, 516,  72, 545,  48, 410, 426,  17,  69, 436, 148, 530,  78,\n",
       "         189, 330,  48, 215, 250, 402, 271, 327, 571, 261, 342,  50, 560,\n",
       "          89, 529, 339,  20, 113, 130, 144, 203, 125, 169, 129, 254, 104,\n",
       "         364, 147, 300,  55, 119,  70,  11, 180, 491, 221,  65, 127, 111,\n",
       "         109, 120, 393, 224, 547, 467, 554, 312, 158, 387,   9, 343, 407,\n",
       "         468,  60, 552, 374, 238, 419, 109, 466, 255, 453,  56,  64,  23,\n",
       "           6, 365,  96, 217, 181,  79,  90, 175, 422, 187,  68, 490, 247,\n",
       "          16, 230,  18,   8, 583,  15,  28, 270,  55,   4, 215,  88, 581,\n",
       "          26, 175,  45,  86,  52])>,\n",
       "  'product_sku_hash_list__offsets': <tf.Tensor: shape=(11,), dtype=int32, numpy=array([  0,  13,  21,  52,  66,  90, 112, 120, 135, 150, 161], dtype=int32)>,\n",
       "  'event_type_list__values': <tf.Tensor: shape=(161,), dtype=int64, numpy=\n",
       "  array([4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 4, 3,\n",
       "         4, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4, 3, 4, 3,\n",
       "         4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 3,\n",
       "         4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4,\n",
       "         3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 4,\n",
       "         3, 3, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3,\n",
       "         3, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 3, 3, 4, 4, 3, 3, 3, 4,\n",
       "         3, 3, 3, 4, 3, 3, 3])>,\n",
       "  'event_type_list__offsets': <tf.Tensor: shape=(11,), dtype=int32, numpy=array([  0,  13,  21,  52,  66,  90, 112, 120, 135, 150, 161], dtype=int32)>,\n",
       "  'product_action_list__values': <tf.Tensor: shape=(161,), dtype=int64, numpy=\n",
       "  array([6, 4, 6, 3, 4, 6, 4, 3, 3, 6, 5, 4, 5, 3, 4, 3, 3, 5, 4, 3, 6, 4,\n",
       "         5, 3, 6, 3, 4, 5, 3, 6, 6, 4, 5, 3, 6, 4, 3, 4, 5, 3, 3, 4, 4, 5,\n",
       "         6, 6, 4, 4, 3, 5, 4, 5, 5, 4, 4, 3, 5, 4, 4, 6, 4, 4, 5, 5, 6, 3,\n",
       "         5, 3, 5, 3, 3, 3, 6, 5, 6, 3, 5, 3, 6, 6, 5, 5, 6, 6, 4, 4, 4, 6,\n",
       "         4, 5, 5, 4, 5, 5, 3, 3, 3, 6, 3, 6, 4, 4, 4, 6, 3, 3, 5, 6, 4, 6,\n",
       "         3, 6, 3, 4, 5, 3, 6, 3, 5, 6, 6, 4, 4, 5, 4, 6, 4, 3, 3, 5, 6, 4,\n",
       "         3, 3, 6, 4, 4, 3, 6, 3, 6, 4, 3, 5, 5, 5, 6, 3, 3, 3, 3, 5, 5, 5,\n",
       "         5, 6, 5, 5, 3, 5, 4])>,\n",
       "  'product_action_list__offsets': <tf.Tensor: shape=(11,), dtype=int32, numpy=array([  0,  13,  21,  52,  66,  90, 112, 120, 135, 150, 161], dtype=int32)>,\n",
       "  'hashed_url_list__values': <tf.Tensor: shape=(161,), dtype=int64, numpy=\n",
       "  array([103, 104,  39,  64,  77, 101, 169, 381, 345, 178, 628, 456,  91,\n",
       "         246, 278,  22,  21,  67, 484, 110, 284, 256, 368,  10, 251, 325,\n",
       "          72, 173, 181, 585, 190,  30, 233, 492, 525,  30, 143, 517, 173,\n",
       "           7,   5,  82, 191, 376, 116,   7,  20, 584, 209, 225, 503,  15,\n",
       "          89, 363, 424, 159,  14, 625, 220, 442, 210,  20, 505, 406, 300,\n",
       "         640,  72,   9,  41, 163,   4, 516,  37, 236, 466, 449,  59,  83,\n",
       "          64, 416,  13, 235,  85,  55,  48,  36, 361, 145,  15,  28, 311,\n",
       "         469, 100,  81, 488,  28, 350,  61,  63,   5, 410, 635,  43,  42,\n",
       "          52, 577, 601,  15, 206,  18,  35, 565, 499, 407, 271, 489,  74,\n",
       "         555,  14,  21,  73, 179,  20, 166, 259,  91, 182, 383,  54, 238,\n",
       "         359, 450, 405, 115, 530, 629, 234, 185, 198, 591, 107,   3, 366,\n",
       "         229,  20, 132, 360, 111, 292,  87, 223, 618, 184, 150, 123, 237,\n",
       "         241, 319, 114, 139, 124])>,\n",
       "  'hashed_url_list__offsets': <tf.Tensor: shape=(11,), dtype=int32, numpy=array([  0,  13,  21,  52,  66,  90, 112, 120, 135, 150, 161], dtype=int32)>,\n",
       "  'server_timestamp_epoch_ms_list__values': <tf.Tensor: shape=(161,), dtype=float64, numpy=\n",
       "  array([8.25980681e-02, 1.05257217e-01, 1.62374008e-01, 2.71591022e-01,\n",
       "         3.55430019e-01, 5.65068952e-01, 7.07825985e-01, 7.25769209e-01,\n",
       "         7.57551286e-01, 7.80794068e-01, 9.24108334e-01, 9.34602851e-01,\n",
       "         9.94891779e-01, 1.85496519e-01, 2.76405425e-01, 4.34988078e-01,\n",
       "         5.72755908e-01, 6.35218782e-01, 6.85114184e-01, 8.16051158e-01,\n",
       "         9.84128522e-01, 3.76461312e-02, 1.71433884e-01, 1.76407089e-01,\n",
       "         1.83728282e-01, 2.39082227e-01, 3.35920847e-01, 3.37747696e-01,\n",
       "         3.78924513e-01, 3.93020002e-01, 4.10845132e-01, 4.25420317e-01,\n",
       "         4.36092897e-01, 4.56662989e-01, 4.62409846e-01, 4.81306015e-01,\n",
       "         5.15669796e-01, 5.29190030e-01, 5.82366271e-01, 5.99656128e-01,\n",
       "         6.55783764e-01, 6.77983397e-01, 7.48731863e-01, 7.49762853e-01,\n",
       "         7.60649906e-01, 7.74362337e-01, 8.09237099e-01, 8.41567327e-01,\n",
       "         8.71137641e-01, 8.74819144e-01, 8.84849011e-01, 9.74558485e-01,\n",
       "         2.30423933e-01, 2.33492583e-01, 2.60687026e-01, 3.56733831e-01,\n",
       "         3.60975541e-01, 3.78039693e-01, 4.33853847e-01, 5.47565896e-01,\n",
       "         5.65052633e-01, 6.09568024e-01, 6.12436502e-01, 6.53293147e-01,\n",
       "         7.28780504e-01, 8.14844805e-01, 4.13321794e-05, 8.86285958e-03,\n",
       "         4.86058106e-02, 1.22949096e-01, 1.74524833e-01, 2.17693580e-01,\n",
       "         2.28103386e-01, 2.44236625e-01, 2.76027114e-01, 3.63682809e-01,\n",
       "         3.77754512e-01, 4.03268394e-01, 4.25136734e-01, 4.79533908e-01,\n",
       "         4.98155449e-01, 5.00091996e-01, 5.03365330e-01, 5.05808965e-01,\n",
       "         5.07299037e-01, 5.15137522e-01, 5.19881963e-01, 6.51821441e-01,\n",
       "         7.33460299e-01, 8.88409489e-01, 6.27724580e-02, 1.26457071e-01,\n",
       "         1.36120111e-01, 1.44450600e-01, 2.08970979e-01, 2.30759631e-01,\n",
       "         3.42999477e-01, 3.62918179e-01, 3.79806286e-01, 3.86169197e-01,\n",
       "         3.87235876e-01, 4.00738972e-01, 4.29240770e-01, 4.57955063e-01,\n",
       "         4.77287260e-01, 5.52786607e-01, 5.56189930e-01, 6.00187693e-01,\n",
       "         6.25603567e-01, 6.56511161e-01, 9.43381900e-01, 9.86187256e-01,\n",
       "         1.72116634e-02, 6.47805144e-02, 6.61775849e-02, 1.96166234e-01,\n",
       "         2.77882141e-01, 3.42128130e-01, 5.10274320e-01, 5.11050138e-01,\n",
       "         1.73329365e-02, 1.71556565e-01, 1.82499039e-01, 2.64092875e-01,\n",
       "         3.46119446e-01, 3.84160069e-01, 4.96390236e-01, 5.34139372e-01,\n",
       "         6.56171639e-01, 6.62352144e-01, 6.98355375e-01, 7.25245434e-01,\n",
       "         8.10814791e-01, 8.14547189e-01, 9.10677382e-01, 2.08365591e-02,\n",
       "         1.40124393e-01, 2.11391198e-01, 2.37855283e-01, 2.91070241e-01,\n",
       "         3.11896144e-01, 3.90895302e-01, 6.26708495e-01, 6.53799943e-01,\n",
       "         6.58033202e-01, 6.63556334e-01, 7.08237286e-01, 7.95509808e-01,\n",
       "         8.53056250e-01, 9.93277464e-01, 1.76166581e-01, 2.13490338e-01,\n",
       "         2.46318896e-01, 3.47980782e-01, 4.64514631e-01, 5.27617720e-01,\n",
       "         6.28984096e-01, 6.42343699e-01, 6.84451029e-01, 6.96978071e-01,\n",
       "         7.54113398e-01])>,\n",
       "  'server_timestamp_epoch_ms_list__offsets': <tf.Tensor: shape=(11,), dtype=int32, numpy=array([  0,  13,  21,  52,  66,  90, 112, 120, 135, 150, 161], dtype=int32)>,\n",
       "  'embeddings__values': <tf.Tensor: shape=(161, 50), dtype=float64, numpy=\n",
       "  array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]])>,\n",
       "  'embeddings__offsets': <tf.Tensor: shape=(11,), dtype=int32, numpy=array([  0,  13,  21,  52,  66,  90, 112, 120, 135, 150, 161], dtype=int32)>},\n",
       " None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = loader.peek()\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facd4dbd",
   "metadata": {},
   "source": [
    "We are now read to construct our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6867c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import merlin.models.tf as mm\n",
    "\n",
    "input_block = mm.InputBlockV2(\n",
    "    loader.output_schema,\n",
    "    embeddings=mm.Embeddings(\n",
    "        loader.output_schema.select_by_tag(Tags.CATEGORICAL),\n",
    "        sequence_combiner=None,\n",
    "    ),\n",
    "    pretrained_embeddings=mm.PretrainedEmbeddings(\n",
    "        loader.output_schema.select_by_tag(Tags.EMBEDDING),\n",
    "        sequence_combiner=None,\n",
    "        normalizer=\"l2-norm\",\n",
    "        output_dims={\"embeddings\": 128},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aba049",
   "metadata": {},
   "source": [
    "We have now constructed an `input_block` that will take our batch and transform it in a fashion that will make it amenable for further processing by subsequent layers of our model.\n",
    "\n",
    "To test that everything has worked okay, we can pass our exemplary `batch` through the `input_block`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f89e79fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "as_list() is not defined on an unknown TensorShape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minput_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/tabular.py:480\u001b[0m, in \u001b[0;36m_tabular_call\u001b[0;34m(self, inputs, pre, post, merge_with, aggregation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_call(inputs, transformations\u001b[38;5;241m=\u001b[39mpre)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# This will call the `call` method implemented by the super class.\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    483\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[1;32m    484\u001b[0m         outputs, transformations\u001b[38;5;241m=\u001b[39mpost, merge_with\u001b[38;5;241m=\u001b[39mmerge_with, aggregation\u001b[38;5;241m=\u001b[39maggregation\n\u001b[1;32m    485\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/config/schema.py:58\u001b[0m, in \u001b[0;36mSchemaMixin.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_schema()\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py:595\u001b[0m, in \u001b[0;36mParallelBlock.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    592\u001b[0m     layer_input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_filter_layer_inputs_using_schema(\n\u001b[1;32m    593\u001b[0m         name, layer, input_shape\n\u001b[1;32m    594\u001b[0m     )\n\u001b[0;32m--> 595\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_input_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m     layer_out_shape \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mcompute_output_shape(layer_input_shape)\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_pruning \u001b[38;5;129;01mand\u001b[39;00m layer_out_shape \u001b[38;5;241m==\u001b[39m {}:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py:595\u001b[0m, in \u001b[0;36mParallelBlock.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    592\u001b[0m     layer_input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_filter_layer_inputs_using_schema(\n\u001b[1;32m    593\u001b[0m         name, layer, input_shape\n\u001b[1;32m    594\u001b[0m     )\n\u001b[0;32m--> 595\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_input_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m     layer_out_shape \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mcompute_output_shape(layer_input_shape)\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_pruning \u001b[38;5;129;01mand\u001b[39;00m layer_out_shape \u001b[38;5;241m==\u001b[39m {}:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/inputs/embedding.py:398\u001b[0m, in \u001b[0;36mEmbeddingTable.build\u001b[0;34m(self, input_shapes)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Builds the EmbeddingTable based on the input shapes.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    The shapes of the input tensors.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(EmbeddingTable, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mbuild(input_shapes)\n",
      "\u001b[0;31mValueError\u001b[0m: as_list() is not defined on an unknown TensorShape."
     ]
    }
   ],
   "source": [
    "input_block(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb9577fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/inputs/embedding.py\u001b[0m(398)\u001b[0;36mbuild\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    396 \u001b[0;31m        \"\"\"\n",
      "\u001b[0m\u001b[0;32m    397 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 398 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    399 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbeddingTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    400 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> input_shapes\n",
      "({'product_sku_hash_list__values': TensorShape([161]), 'product_sku_hash_list__offsets': TensorShape([11]), 'event_type_list__values': TensorShape([161]), 'event_type_list__offsets': TensorShape([11]), 'product_action_list__values': TensorShape([161]), 'product_action_list__offsets': TensorShape([11]), 'hashed_url_list__values': TensorShape([161]), 'hashed_url_list__offsets': TensorShape([11]), 'server_timestamp_epoch_ms_list__values': TensorShape([161]), 'server_timestamp_epoch_ms_list__offsets': TensorShape([11]), 'embeddings__values': TensorShape([161, 50]), 'embeddings__offsets': TensorShape([11])}, None)\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6fe48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02faa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c393c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd991b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce62a0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product_sku_hash_list</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL, Tags.ID)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.product_sku_hash.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57485.0</td>\n",
       "      <td>product_sku_hash</td>\n",
       "      <td>57486.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>event_type_list</td>\n",
       "      <td>(Tags.CATEGORICAL)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.event_type.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>event_type</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_action_list</td>\n",
       "      <td>(Tags.CATEGORICAL)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.product_action.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>product_action</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hashed_url_list</td>\n",
       "      <td>(Tags.CATEGORICAL)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.hashed_url.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>489302.0</td>\n",
       "      <td>hashed_url</td>\n",
       "      <td>489303.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>server_timestamp_epoch_ms_list</td>\n",
       "      <td>(Tags.CONTINUOUS)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'product_sku_hash_list', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ID: 'id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.product_sku_hash.parquet', 'domain': {'min': 0, 'max': 57485, 'name': 'product_sku_hash'}, 'embedding_sizes': {'cardinality': 57486, 'dimension': 512}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'event_type_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.event_type.parquet', 'domain': {'min': 0, 'max': 4, 'name': 'event_type'}, 'embedding_sizes': {'cardinality': 5, 'dimension': 16}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'product_action_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.product_action.parquet', 'domain': {'min': 0, 'max': 6, 'name': 'product_action'}, 'embedding_sizes': {'cardinality': 7, 'dimension': 16}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'hashed_url_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.hashed_url.parquet', 'domain': {'min': 0, 'max': 489302, 'name': 'hashed_url'}, 'embedding_sizes': {'cardinality': 489303, 'dimension': 512}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'server_timestamp_epoch_ms_list', 'tags': {<Tags.CONTINUOUS: 'continuous'>}, 'properties': {'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.input_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7cd1f5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product_sku_hash_list</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL, Tags.ID)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.product_sku_hash.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57485.0</td>\n",
       "      <td>product_sku_hash</td>\n",
       "      <td>57486.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>event_type_list</td>\n",
       "      <td>(Tags.CATEGORICAL)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.event_type.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>event_type</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_action_list</td>\n",
       "      <td>(Tags.CATEGORICAL)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.product_action.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>product_action</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hashed_url_list</td>\n",
       "      <td>(Tags.CATEGORICAL)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.hashed_url.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>489302.0</td>\n",
       "      <td>hashed_url</td>\n",
       "      <td>489303.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>server_timestamp_epoch_ms_list</td>\n",
       "      <td>(Tags.CONTINUOUS)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>embeddings</td>\n",
       "      <td>(Tags.ITEM, Tags.EMBEDDING)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'product_sku_hash_list', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ID: 'id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.product_sku_hash.parquet', 'domain': {'min': 0, 'max': 57485, 'name': 'product_sku_hash'}, 'embedding_sizes': {'cardinality': 57486, 'dimension': 512}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'event_type_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.event_type.parquet', 'domain': {'min': 0, 'max': 4, 'name': 'event_type'}, 'embedding_sizes': {'cardinality': 5, 'dimension': 16}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'product_action_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.product_action.parquet', 'domain': {'min': 0, 'max': 6, 'name': 'product_action'}, 'embedding_sizes': {'cardinality': 7, 'dimension': 16}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'hashed_url_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.hashed_url.parquet', 'domain': {'min': 0, 'max': 489302, 'name': 'hashed_url'}, 'embedding_sizes': {'cardinality': 489303, 'dimension': 512}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'server_timestamp_epoch_ms_list', 'tags': {<Tags.CONTINUOUS: 'continuous'>}, 'properties': {'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'embeddings', 'tags': {<Tags.ITEM: 'item'>, <Tags.EMBEDDING: 'embedding'>}, 'properties': {'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None), Dimension(min=50, max=50)))), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "575431ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = mm.sample_batch(loader, batch_size=10, include_targets=False, prepare_features=True)\n",
    "input_batch = input_block(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ac383e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, None, 233])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "78b21c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'hashed_url_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bdc8f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel=128\n",
    "mlp_block = mm.MLPBlock(\n",
    "                [128,dmodel],\n",
    "                activation='relu',\n",
    "                no_activation_last_layer=True,\n",
    "            )\n",
    "transformer_block = mm.XLNetBlock(d_model=dmodel, n_head=4, n_layer=2)\n",
    "model = mm.Model(\n",
    "    input_block,\n",
    "    mlp_block,\n",
    "    transformer_block,\n",
    "    mm.CategoricalOutput(\n",
    "        train_processed.schema.select_by_name(target),\n",
    "        default_loss=\"categorical_crossentropy\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbb03f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "2023-06-12 01:00:02.308265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['model_2/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['model_2/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 01:00:24.143373: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_2/xl_net_block_2/sequential_block_21/replace_masked_embeddings_4/RaggedWhere/Assert/AssertGuard/branch_executed/_111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   996/188411 [..............................] - ETA: 2:21:59 - loss: 10.2552 - recall_at_10: 0.1281 - mrr_at_10: 0.0678 - ndcg_at_10: 0.0822 - map_at_10: 0.0678 - precision_at_10: 0.0128 - regularization_loss: 0.0000e+00 - loss_batch: 10.2335"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(run_eagerly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequenceMaskRandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasking_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_block\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/models/base.py:1377\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, train_metrics_steps, pre, **kwargs)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_pre, SequenceTransform):\n\u001b[1;32m   1375\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_pre\u001b[38;5;241m.\u001b[39mconfigure_for_train()\n\u001b[0;32m-> 1377\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre:\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_pre\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(run_eagerly=False, optimizer='adam', loss=\"categorical_crossentropy\")\n",
    "model.fit(loader, batch_size=64, epochs=5, pre=mm.SequenceMaskRandom(schema=schema, target=target, masking_prob=0.3, transformer=transformer_block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f35be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02da1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9594131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd9dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee8d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    embeddings = np.load(npy_path)\n",
    "    # second workflow that categorifies the embedding table data\n",
    "    df = make_df({\"string_id\": np.random.choice(string_ids, 30)})\n",
    "    graph2 = [\"string_id\"] >> cat_op\n",
    "    train_res = Workflow(graph2).transform(Dataset(df, cpu=(cpu is not None)))\n",
    "\n",
    "    data_loader = Loader(\n",
    "        train_res,\n",
    "        batch_size=1,\n",
    "        transforms=[\n",
    "            EmbeddingOperator(\n",
    "                embeddings[:, 1:],\n",
    "                id_lookup_table=embeddings[:, 0].astype(int),\n",
    "                lookup_key=\"string_id\",\n",
    "            )\n",
    "        ],\n",
    "        shuffle=False,\n",
    "        device=cpu,\n",
    "    )\n",
    "    origin_df = train_res.to_ddf().merge(emb_res.to_ddf(), on=\"string_id\", how=\"left\").compute()\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        batch\n",
    "        b_df = batch[0].to_df()\n",
    "        org_df = origin_df.iloc[idx]\n",
    "        if not cpu:\n",
    "            assert (b_df[\"string_id\"].to_numpy() == org_df[\"string_id\"].to_numpy()).all()\n",
    "            assert (b_df[\"embeddings\"].list.leaves == org_df[\"embeddings\"].list.leaves).all()\n",
    "        else:\n",
    "            assert (b_df[\"string_id\"].values == org_df[\"string_id\"]).all()\n",
    "            assert b_df[\"embeddings\"].values[0] == org_df[\"embeddings\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2918edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ef0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame(data={'id': [1,2,3], 'val': [0, np.nan, 10], 'another_col': ['a', 'b', 'c']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe60eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.val[df.val.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.val[~df.val.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e844c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = nvt.Dataset(df)\n",
    "\n",
    "out = ['val'] >> nvt.ops.Filter(f=lambda col: ~col.isna())\n",
    "\n",
    "wf = nvt.Workflow(out)\n",
    "wf.fit_transform(ds).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1824ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ['id', 'val'] >> nvt.ops.Filter(f=lambda df: ~df['val'].isna())\n",
    "\n",
    "wf = nvt.Workflow(out)\n",
    "wf.fit_transform(ds).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ['id', 'val'] >> nvt.ops.Filter(f=lambda df: ~df['val'].isna())\n",
    "\n",
    "wf = nvt.Workflow(out + ['another_col'])\n",
    "wf.fit_transform(ds).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus.to_npy('embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28983810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73636038",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ['product_sku_hash', 'category_hash'] >> nvt.ops.Categorify() >> nvt.ops.TagAsItemID()\n",
    "out += ['description_vector'] >> nvt.ops.TagAsItemFeatures()\n",
    "out += ['price_bucket'] >> nvt.ops.NormalizeMinMax()\n",
    "\n",
    "wf = nvt.Workflow(out)\n",
    "skus = wf.fit_transform(skus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ef176",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aacf74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116220a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f4e4a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame(data={'id': [1,2,3], 'label': [1,2,1]})\n",
    "ds = nvt.Dataset(df)\n",
    "\n",
    "out = ['label'] >> nvt.ops.AddMetadata(Tags.TARGET)\n",
    "\n",
    "wf = nvt.Workflow(out + ['id'])\n",
    "\n",
    "ds_out = wf.fit_transform(ds)\n",
    "\n",
    "loader = Loader(\n",
    "    ds_out,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "loader.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771ea52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3049254",
   "metadata": {},
   "source": [
    "To use synthetically generated data, uncomment the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64305ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /workspace\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: merlin-core>=23.4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (23.5.0+13.gd6720139)\n",
      "Requirement already satisfied: merlin-dataloader>=23.4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (23.5.0+2.g2e05300)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.13.1)\n",
      "Requirement already satisfied: npy-append-array in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (0.9.16)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.22.4)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (4.65.0)\n",
      "Requirement already satisfied: dask>=2022.11.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2023.1.1)\n",
      "Requirement already satisfied: distributed>=2022.11.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2023.1.1)\n",
      "Requirement already satisfied: fsspec>=2022.7.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2023.6.0)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (0.57.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (9.0.0)\n",
      "Requirement already satisfied: pynvml<11.5,>=11.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (11.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (23.1)\n",
      "Requirement already satisfied: pandas<1.6.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.5.2)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (3.20.3)\n",
      "Requirement already satisfied: dask-cuda>=22.12.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (22.12.0)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.59.0)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (0.4.4)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (6.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.4.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (8.1.3)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (0.12.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.0.5)\n",
      "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (5.9.5)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.7.0)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /usr/lib/python3/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.25.8)\n",
      "Requirement already satisfied: zict>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (3.0.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2.4.0)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.0.0)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (3.1.2)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (6.3.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (6.6.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (0.40.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2.8.2)\n",
      "Requirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (6.0.4)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (4.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10.3->distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.54->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (3.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0dev0,>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.14.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (4.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (6.0.1)\n",
      "Building wheels for collected packages: merlin-models\n",
      "  Building wheel for merlin-models (PEP 517): started\n",
      "  Building wheel for merlin-models (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-models: filename=merlin_models-23.5.dev0+63.g6d83a8b1.dirty-py3-none-any.whl size=384113 sha256=743286edc1e20e76705ea7980a6cbe6f45accd6b753f72a0815da260a3102641\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-myac_4jv/wheels/59/14/70/d94958f41745fe226f3bc60bb3cabbbc8a98e4d6679e91038a\n",
      "Successfully built merlin-models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: transformers4rec 23.5.0+9.gf4946bfa requires torchmetrics>=0.10.0, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: merlin-models\n",
      "  Attempting uninstall: merlin-models\n",
      "    Found existing installation: merlin-models 23.5.dev0+57.gad9fa2bb.dirty\n",
      "    Uninstalling merlin-models-23.5.dev0+57.gad9fa2bb.dirty:\n",
      "      Successfully uninstalled merlin-models-23.5.dev0+57.gad9fa2bb.dirty\n",
      "Successfully installed merlin-models-23.5.dev0+63.g6d83a8b1.dirty\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /workspace && pip install . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14a4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.datasets.synthetic import KNOWN_DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595ef5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e-commerce': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/small'),\n",
       " 'e-commerce-large': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/large'),\n",
       " 'music-streaming': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/music_streaming'),\n",
       " 'social': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/social'),\n",
       " 'testing': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/testing'),\n",
       " 'sequence-testing': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/testing/sequence_testing'),\n",
       " 'movielens-25m': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/movielens/25m'),\n",
       " 'movielens-1m': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/movielens/1m'),\n",
       " 'movielens-1m-raw-ratings': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/movielens/1m-raw/ratings'),\n",
       " 'movielens-100k': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/movielens/100k'),\n",
       " 'tenrec-video': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/tenrec_video'),\n",
       " 'criteo': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/advertising/criteo/transformed'),\n",
       " 'aliccp': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/aliccp/transformed'),\n",
       " 'aliccp-raw': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/aliccp/raw'),\n",
       " 'dressipi2022-preprocessed': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/dressipi/preprocessed'),\n",
       " 'booking.com': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/booking/transformed'),\n",
       " 'booking.com-raw': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/booking/raw'),\n",
       " 'transactions': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/transactions'),\n",
       " 'sigir-browsing': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/sigir/browsing_train'),\n",
       " 'sigir-sku': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/sigir/sku_information')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNOWN_DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895e9266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>hashed_url</th>\n",
       "      <th>server_timestamp_epoch_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>399</td>\n",
       "      <td>949</td>\n",
       "      <td>0.578108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>505</td>\n",
       "      <td>818</td>\n",
       "      <td>0.471705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>423</td>\n",
       "      <td>771</td>\n",
       "      <td>0.613716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>791</td>\n",
       "      <td>49</td>\n",
       "      <td>0.503518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>424</td>\n",
       "      <td>166</td>\n",
       "      <td>0.864198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id_hash  event_type  product_action  product_sku_hash  hashed_url  \\\n",
       "0               50           0               1               399         949   \n",
       "1                8           0               3               505         818   \n",
       "2               16           1               0               423         771   \n",
       "3               87           1               2               791          49   \n",
       "4              378           1               3               424         166   \n",
       "\n",
       "   server_timestamp_epoch_ms  \n",
       "0                   0.578108  \n",
       "1                   0.471705  \n",
       "2                   0.613716  \n",
       "3                   0.503518  \n",
       "4                   0.864198  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d09929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>description_vector</th>\n",
       "      <th>category_hash</th>\n",
       "      <th>price_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>[0.28320169822835645, 0.28876255653408484, 0.3...</td>\n",
       "      <td>114</td>\n",
       "      <td>0.148844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>[0.0498882587601161, 0.4050611778162572, 0.489...</td>\n",
       "      <td>78</td>\n",
       "      <td>0.983131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>[-0.20383781352758598, 0.2821339201063496, -0....</td>\n",
       "      <td>78</td>\n",
       "      <td>0.268082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>[0.08096254937074815, 0.5582722991824396, 0.22...</td>\n",
       "      <td>156</td>\n",
       "      <td>0.310764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>[-0.29878517778423397, -0.3313343019075635, -0...</td>\n",
       "      <td>121</td>\n",
       "      <td>0.097739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_sku_hash                                 description_vector  \\\n",
       "0                35  [0.28320169822835645, 0.28876255653408484, 0.3...   \n",
       "1                11  [0.0498882587601161, 0.4050611778162572, 0.489...   \n",
       "2                12  [-0.20383781352758598, 0.2821339201063496, -0....   \n",
       "3                14  [0.08096254937074815, 0.5582722991824396, 0.22...   \n",
       "4                49  [-0.29878517778423397, -0.3313343019075635, -0...   \n",
       "\n",
       "   category_hash  price_bucket  \n",
       "0            114      0.148844  \n",
       "1             78      0.983131  \n",
       "2             78      0.268082  \n",
       "3            156      0.310764  \n",
       "4            121      0.097739  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
