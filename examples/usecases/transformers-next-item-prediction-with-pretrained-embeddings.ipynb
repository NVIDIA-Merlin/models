{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df10e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/core\n",
      "   d6720139..c5facda7  main       -> origin/main\n",
      "   8110f3b1..9d676718  gh-pages   -> origin/gh-pages\n",
      "Already on 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is behind 'origin/main' by 3 commits, and can be fast-forwarded.\n",
      "  (use \"git pull\" to update your local branch)\n",
      "Processing /core\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: merlin-core\n",
      "  Building wheel for merlin-core (PEP 517): started\n",
      "  Building wheel for merlin-core (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-core: filename=merlin_core-23.5.0+13.gd6720139-py3-none-any.whl size=171826 sha256=61a5c8bca4b016603b3f5e1085eda27324c12b708803229fe080aafc27fcdc02\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6zzemovm/wheels/8f/da/8c/c779661788874afaa32fd10abeac6016635956e3bad9940584\n",
      "Successfully built merlin-core\n",
      "Installing collected packages: merlin-core\n",
      "  Attempting uninstall: merlin-core\n",
      "    Found existing installation: merlin-core 23.5.0+13.gd6720139\n",
      "    Uninstalling merlin-core-23.5.0+13.gd6720139:\n",
      "      Successfully uninstalled merlin-core-23.5.0+13.gd6720139\n",
      "Successfully installed merlin-core-23.5.0+13.gd6720139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/dataloader\n",
      "   2e05300..6d599d5  main       -> origin/main\n",
      "   5463de1..64b31ae  gh-pages   -> origin/gh-pages\n",
      "Already on 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is behind 'origin/main' by 1 commit, and can be fast-forwarded.\n",
      "  (use \"git pull\" to update your local branch)\n",
      "Processing /dataloader\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: merlin-dataloader\n",
      "  Building wheel for merlin-dataloader (PEP 517): started\n",
      "  Building wheel for merlin-dataloader (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-dataloader: filename=merlin_dataloader-23.5.0+2.g2e05300-py3-none-any.whl size=35632 sha256=c87fe331ce20e5e992f474ffab060d3747b291f599b68cdc8d7e1608ca95a7ba\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-97ouurro/wheels/8c/19/5b/15dc04f5a977f6a7f73ed66c91996a687b1d9e3154a4765536\n",
      "Successfully built merlin-dataloader\n",
      "Installing collected packages: merlin-dataloader\n",
      "  Attempting uninstall: merlin-dataloader\n",
      "    Found existing installation: merlin-dataloader 23.5.0+2.g2e05300\n",
      "    Uninstalling merlin-dataloader-23.5.0+2.g2e05300:\n",
      "      Successfully uninstalled merlin-dataloader-23.5.0+2.g2e05300\n",
      "Successfully installed merlin-dataloader-23.5.0+2.g2e05300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/NVTabular\n",
      "   25151f73..d26e776a  main              -> origin/main\n",
      "   9da40a0c..a9b0014e  gh-pages          -> origin/gh-pages\n",
      " * [new branch]        pull-request/1843 -> origin/pull-request/1843\n",
      "Already on 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is behind 'origin/main' by 1 commit, and can be fast-forwarded.\n",
      "  (use \"git pull\" to update your local branch)\n",
      "Processing /nvtabular\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: nvtabular\n",
      "  Building wheel for nvtabular (PEP 517): started\n",
      "  Building wheel for nvtabular (PEP 517): finished with status 'done'\n",
      "  Created wheel for nvtabular: filename=nvtabular-23.5.0+16.g25151f73-cp38-cp38-linux_x86_64.whl size=241878 sha256=896395ca0e51a5193abf5e4cb221532759f93643087e5297d571b5803f7f1990\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4o2n9xx5/wheels/df/bf/c2/9cc2a62fe6da42038c26a9c0c4e25f9767093528b102fa30a2\n",
      "Successfully built nvtabular\n",
      "Installing collected packages: nvtabular\n",
      "  Attempting uninstall: nvtabular\n",
      "    Found existing installation: nvtabular 23.5.0+16.g25151f73\n",
      "    Uninstalling nvtabular-23.5.0+16.g25151f73:\n",
      "      Successfully uninstalled nvtabular-23.5.0+16.g25151f73\n",
      "Successfully installed nvtabular-23.5.0+16.g25151f73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/systems\n",
      "   b23ff21..0d8ca65  main             -> origin/main\n",
      "   344a74a..518a990  gh-pages         -> origin/gh-pages\n",
      " * [new branch]      pull-request/345 -> origin/pull-request/345\n",
      "   dccb618..6b3bf41  pull-request/349 -> origin/pull-request/349\n",
      "Already on 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is behind 'origin/main' by 7 commits, and can be fast-forwarded.\n",
      "  (use \"git pull\" to update your local branch)\n",
      "Processing /systems\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: merlin-systems\n",
      "  Building wheel for merlin-systems (PEP 517): started\n",
      "  Building wheel for merlin-systems (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-systems: filename=merlin_systems-23.5.0+9.gb23ff21-py3-none-any.whl size=82964 sha256=fb043c726ee0601393c4840095068df386c837463af44fdc02db9e162447da02\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zb893449/wheels/1f/e9/71/1b0c6295aa7f4b37cb70292d96d87d9f38204674e6531bdda6\n",
      "Successfully built merlin-systems\n",
      "Installing collected packages: merlin-systems\n",
      "  Attempting uninstall: merlin-systems\n",
      "    Found existing installation: merlin-systems 23.5.0+9.gb23ff21\n",
      "    Uninstalling merlin-systems-23.5.0+9.gb23ff21:\n",
      "      Successfully uninstalled merlin-systems-23.5.0+9.gb23ff21\n",
      "Successfully installed merlin-systems-23.5.0+9.gb23ff21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/NVIDIA-Merlin/Transformers4Rec\n",
      "   6a7c9746..bfcaa303  gh-pages          -> origin/gh-pages\n",
      " * [new branch]        pull-request/720  -> origin/pull-request/720\n",
      " * [new branch]        recall_metric_fix -> origin/recall_metric_fix\n",
      "Already on 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n",
      "Processing /transformers4rec\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: transformers4rec\n",
      "  Building wheel for transformers4rec (PEP 517): started\n",
      "  Building wheel for transformers4rec (PEP 517): finished with status 'done'\n",
      "  Created wheel for transformers4rec: filename=transformers4rec-23.5.0+9.gf4946bfa-py3-none-any.whl size=488200 sha256=811b36c3d15cd2612b338fa3868bdb12a9d0588110e549c241dccebfc0edebbf\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-szzpus_o/wheels/24/44/e3/c29f7de8e7315585705f880ad32ffeae66fcaeb79003405ef6\n",
      "Successfully built transformers4rec\n",
      "Installing collected packages: transformers4rec\n",
      "  Attempting uninstall: transformers4rec\n",
      "    Found existing installation: transformers4rec 23.5.0+9.gf4946bfa\n",
      "    Uninstalling transformers4rec-23.5.0+9.gf4946bfa:\n",
      "      Successfully uninstalled transformers4rec-23.5.0+9.gf4946bfa\n",
      "Successfully installed transformers4rec-23.5.0+9.gf4946bfa\n",
      "Processing /workspace\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: merlin-core>=23.4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-models==23.5.dev0+68.gdc973235.dirty) (23.5.0+13.gd6720139)\n",
      "Requirement already satisfied: merlin-dataloader>=23.4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-models==23.5.dev0+68.gdc973235.dirty) (23.5.0+2.g2e05300)\n",
      "Requirement already satisfied: distributed>=2022.11.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (2023.1.1)\n",
      "Requirement already satisfied: npy-append-array in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (0.9.16)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (0.57.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (23.1)\n",
      "Collecting fsspec>=2022.7.1\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: dask>=2022.11.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (2023.1.1)\n",
      "Requirement already satisfied: pandas<1.6.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.5.2)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (3.20.3)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (4.65.0)\n",
      "Requirement already satisfied: pynvml<11.5,>=11.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (11.4.1)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.22.4)\n",
      "Requirement already satisfied: dask-cuda>=22.12.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (22.12.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (9.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.0.5)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (2.4.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (0.12.0)\n",
      "Requirement already satisfied: zict>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (3.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (2.2.1)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.7.0)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.0.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (6.3.2)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (3.1.2)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /usr/lib/python3/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.25.8)\n",
      "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (5.9.5)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (8.1.3)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (6.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (0.40.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (6.6.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (2.8.2)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.59.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (0.4.4)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10.3->distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.54->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0dev0,>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (1.14.0)\n",
      "Requirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (6.0.4)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (4.1.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+68.gdc973235.dirty) (4.0.0)\n",
      "Building wheels for collected packages: merlin-models\n",
      "  Building wheel for merlin-models (PEP 517): started\n",
      "  Building wheel for merlin-models (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-models: filename=merlin_models-23.5.dev0+68.gdc973235.dirty-py3-none-any.whl size=388538 sha256=45127b65b4ffbb17c10def63f593d7c4453b7c7a439830085b1dc3d317ffba9e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4ac84wqw/wheels/59/14/70/d94958f41745fe226f3bc60bb3cabbbc8a98e4d6679e91038a\n",
      "Successfully built merlin-models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: transformers4rec 23.5.0+9.gf4946bfa requires torchmetrics>=0.10.0, which is not installed.\n",
      "ERROR: dask-cudf 22.12.0 requires cupy-cuda12x, which is not installed.\n",
      "ERROR: cudf 22.12.0 requires cubinlinker, which is not installed.\n",
      "ERROR: cudf 22.12.0 requires cupy-cuda12x, which is not installed.\n",
      "ERROR: cudf 22.12.0 requires ptxcompiler, which is not installed.\n",
      "ERROR: dask-cudf 22.12.0 has requirement dask==2022.11.1, but you'll have dask 2023.1.1 which is incompatible.\n",
      "ERROR: dask-cudf 22.12.0 has requirement distributed==2022.11.1, but you'll have distributed 2023.1.1 which is incompatible.\n",
      "ERROR: dask-cuda 22.12.0 has requirement dask==2022.11.1, but you'll have dask 2023.1.1 which is incompatible.\n",
      "ERROR: dask-cuda 22.12.0 has requirement distributed==2022.11.1, but you'll have distributed 2023.1.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: merlin-models, fsspec\n",
      "  Attempting uninstall: merlin-models\n",
      "    Found existing installation: merlin-models 23.5.dev0+45.g1a80f77e\n",
      "    Uninstalling merlin-models-23.5.dev0+45.g1a80f77e:\n",
      "      Successfully uninstalled merlin-models-23.5.dev0+45.g1a80f77e\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.5.0\n",
      "    Uninstalling fsspec-2022.5.0:\n",
      "      Successfully uninstalled fsspec-2022.5.0\n",
      "Successfully installed fsspec-2023.6.0 merlin-models-23.5.dev0+68.gdc973235.dirty\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /core\n",
    "git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "pip install . --no-deps\n",
    "\n",
    "cd /dataloader\n",
    "git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "pip install . --no-deps\n",
    "\n",
    "cd /nvtabular\n",
    "git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "pip install . --no-deps\n",
    "\n",
    "cd /systems\n",
    "git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "pip install . --no-deps\n",
    "\n",
    "cd /transformers4rec\n",
    "git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\" && git fetch && git checkout main\n",
    "pip install . --no-deps\n",
    "\n",
    "cd /workspace && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b545747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions anda\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6d3b8",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_models-transformers-net-item-prediction/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Transformer-based architecture for next-item prediction task with pretrained embeddings\n",
    "\n",
    "This notebook is created using the latest stable [merlin-tensorflow](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags) container.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this use case we will train a Transformer-based architecture for next-item prediction task with pretrained embeddings.\n",
    "\n",
    "**You can chose to download the full dataset manually or use synthetic data.**\n",
    "\n",
    "We will use the [SIGIR eCOM 2021 Data Challenge Dataset](https://github.com/coveooss/SIGIR-ecom-data-challenge) to train a session-based model. The dataset contains 36M events of users browsing an online store.\n",
    "\n",
    "We will reshape the data to organize it into 'sessions'. Each session will be a full customer online journey in chronological order. The goal will be to predict the `url` of the next action taken.\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Training a Transformer-based architecture for next-item prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b847f",
   "metadata": {},
   "source": [
    "## Downloading and preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd7827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:47:26.139060: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2023-06-13 22:47:27.756014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 22:47:27.756393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 22:47:27.756548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nvtabular as nvt\n",
    "from merlin.schema import ColumnSchema, Schema, Tags\n",
    "\n",
    "OUTPUT_DATA_DIR = os.environ.get('OUTPUT_DATA_DIR', '/workspace/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b470a6",
   "metadata": {},
   "source": [
    "You can download the full dataset by registering [here](https://www.coveo.com/en/ailabs/sigir-ecom-data-challenge). If you chose to download the data, please place it alongside this notebook in the `sigir_dataset` directory and extract it.\n",
    "\n",
    "To process the downloaded data uncomment the cell below.\n",
    "\n",
    "By default, in this notebook, we will be using synthetically generated data based on the SIGIR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccad8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unocomment this cell to use the original SIGIR dataset.\n",
    "\n",
    "# train = nvt.Dataset('/workspace/sigir_dataset/train/browsing_train.csv', part_size='500MB')\n",
    "# skus = nvt.Dataset('/workspace/sigir_dataset/train/sku_to_content.csv')\n",
    "\n",
    "# skus = pd.read_csv('/workspace/sigir_dataset/train/sku_to_content.csv')\n",
    "\n",
    "# skus['description_vector'] = skus['description_vector'].replace(np.nan, '')\n",
    "# skus['image_vector'] = skus['image_vector'].replace(np.nan, '')\n",
    "\n",
    "# skus['description_vector'] = skus['description_vector'].apply(lambda x: [] if len(x) == 0 else eval(x))\n",
    "# skus['image_vector'] = skus['image_vector'].apply(lambda x: [] if len(x) == 0 else eval(x))\n",
    "# skus = skus[skus.description_vector.apply(len) > 0]\n",
    "# skus = nvt.Dataset(skus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8385a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b06021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.datasets.synthetic import generate_data\n",
    "\n",
    "train = generate_data('sigir-browsing', 1000)\n",
    "skus = generate_data('sigir-sku', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac47bc4e",
   "metadata": {},
   "source": [
    "The `skus` dataset contains the mapping between the `product_sku_hash` (essentially an item id) to the `description_vector` -- an embedding obtained from the description.\n",
    "\n",
    "To use this information in our model, we need to map the `product_sku_hash` information to an id.\n",
    "\n",
    "But we need to make sure that the way we process `skus` and the `train` dataset (event information) is consistent. That the same `product_sku_hash` is mapped to the same id both when processing `skus` and `train`.\n",
    "\n",
    "We do so by defining and fitting a `Categorify` op and using it to process both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b5feee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>hashed_url</th>\n",
       "      <th>server_timestamp_epoch_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>556</td>\n",
       "      <td>0.308571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>228</td>\n",
       "      <td>0.126960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>521</td>\n",
       "      <td>0.250921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>146</td>\n",
       "      <td>0.486433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>357</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>598</td>\n",
       "      <td>0.995947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_sku_hash  event_type  product_action  session_id_hash  hashed_url  \\\n",
       "0               116           3               6                8         556   \n",
       "1               138           3               4               39         228   \n",
       "2                 4           4               5               38         521   \n",
       "3               144           4               3               11         146   \n",
       "4               357           3               5               72         598   \n",
       "\n",
       "   server_timestamp_epoch_ms  \n",
       "0                   0.308571  \n",
       "1                   0.126960  \n",
       "2                   0.250921  \n",
       "3                   0.486433  \n",
       "4                   0.995947  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_op = nvt.ops.Categorify()\n",
    "out = ['product_sku_hash'] >> cat_op >> nvt.ops.TagAsItemID()\n",
    "out += ['event_type', 'product_action', 'session_id_hash', 'hashed_url'] >> nvt.ops.Categorify()\n",
    "out += ['server_timestamp_epoch_ms'] >> nvt.ops.NormalizeMinMax()\n",
    "\n",
    "wf = nvt.Workflow(out)\n",
    "\n",
    "train = wf.fit_transform(train)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f12dbd",
   "metadata": {},
   "source": [
    "Now that we have processed the train set, we can use the mapping preserved in the `cat_op` to process the `skus` dataset containing the embeddings we are after.\n",
    "\n",
    "Let's now `Categorify` the `product_sku_hash` in `skus` and grab just the description embedding information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "313808d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>description_vector</th>\n",
       "      <th>category_hash</th>\n",
       "      <th>price_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>[0.5030258913968493, -0.2369859368870373, -0.2...</td>\n",
       "      <td>166</td>\n",
       "      <td>0.504531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>[-0.27927952813507795, -0.12571982175094842, -...</td>\n",
       "      <td>45</td>\n",
       "      <td>0.667857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>[0.016926540097287224, -0.09689305909197432, -...</td>\n",
       "      <td>109</td>\n",
       "      <td>0.058357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>[0.12570724548530426, -0.38832303808920476, 0....</td>\n",
       "      <td>81</td>\n",
       "      <td>0.703043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>[-0.35571435393286094, -0.15758678574249274, -...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.927422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_sku_hash                                 description_vector  \\\n",
       "0                34  [0.5030258913968493, -0.2369859368870373, -0.2...   \n",
       "1                18  [-0.27927952813507795, -0.12571982175094842, -...   \n",
       "2                29  [0.016926540097287224, -0.09689305909197432, -...   \n",
       "3                17  [0.12570724548530426, -0.38832303808920476, 0....   \n",
       "4                13  [-0.35571435393286094, -0.15758678574249274, -...   \n",
       "\n",
       "   category_hash  price_bucket  \n",
       "0            166      0.504531  \n",
       "1             45      0.667857  \n",
       "2            109      0.058357  \n",
       "3             81      0.703043  \n",
       "4             27      0.927422  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfad1bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>description_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282</td>\n",
       "      <td>[0.5030258913968493, -0.2369859368870373, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.27927952813507795, -0.12571982175094842, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.016926540097287224, -0.09689305909197432, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.12570724548530426, -0.38832303808920476, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275</td>\n",
       "      <td>[-0.35571435393286094, -0.15758678574249274, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_sku_hash                                 description_vector\n",
       "0               282  [0.5030258913968493, -0.2369859368870373, -0.2...\n",
       "1                 2  [-0.27927952813507795, -0.12571982175094842, -...\n",
       "2                 2  [0.016926540097287224, -0.09689305909197432, -...\n",
       "3                 2  [0.12570724548530426, -0.38832303808920476, 0....\n",
       "4               275  [-0.35571435393286094, -0.15758678574249274, -..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = ['product_sku_hash'] >> cat_op\n",
    "wf = nvt.Workflow(out + 'description_vector')\n",
    "skus_ds = wf.transform(skus)\n",
    "\n",
    "skus_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360fe65d",
   "metadata": {},
   "source": [
    "Let us now export the embedding information to a `numpy` array and write it to disk.\n",
    "\n",
    "We will later pass this information so that the `Loader` will load the correct emebedding for the products corresponding to the given step of a customer journey.\n",
    "\n",
    "The embeddings are linked to the train set using the `product_sku_hash` information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d99dfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus_ds.to_npy('skus.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d80879",
   "metadata": {},
   "source": [
    "How will the `Loader` know which embedding to associated with a given row of the train set?\n",
    "\n",
    "The `product_sku_hash` ids have been exported along with the embeddings and are contained in the first column of the output `numpy` array.\n",
    "\n",
    "Here is the id of the first embedding stored in `skus.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60c6651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('skus.npy')[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974cf669",
   "metadata": {},
   "source": [
    "and here is the embedding vector corresponding to `product_sku_hash` of id referenced above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2c111fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50302589, -0.23698594, -0.22237178,  0.37565819, -0.40109763,\n",
       "        0.52433208, -0.22718727,  0.49768463,  0.27120078,  0.33389029,\n",
       "       -0.43632066,  0.16756612,  0.23579074,  0.07203988, -0.18235715,\n",
       "        0.29247988, -0.33753078,  0.40044358,  0.24582858,  0.05188859,\n",
       "        0.41445342,  0.5983167 ,  0.12073968,  0.2892152 ,  0.47905396,\n",
       "        0.18011943, -0.42829333,  0.31918082,  0.53689338,  0.46676839,\n",
       "        0.24985316,  0.45173542,  0.52294863,  0.36732186,  0.60181495,\n",
       "        0.08864464, -0.39594477, -0.21260096, -0.31330986, -0.11238062,\n",
       "        0.13390728, -0.17510986,  0.1897205 ,  0.18955799, -0.07695594,\n",
       "        0.39478356,  0.49045375, -0.36894294, -0.04002203,  0.03805285])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('skus.npy')[0, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea5bd3",
   "metadata": {},
   "source": [
    "Let us now construct the `Loader` that will provide the data to our model.\n",
    "\n",
    "Let us first rearrange the `train` dataset to group the actions by `session_id_hash`. Actions within a session will be contained in a single row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51160169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_sku_hash_list</th>\n",
       "      <th>event_type_list</th>\n",
       "      <th>product_action_list</th>\n",
       "      <th>hashed_url_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[237, 617, 69, 364, 424, 179, 18, 328, 38, 188...</td>\n",
       "      <td>[3, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 4, 3, 3, 3, ...</td>\n",
       "      <td>[5, 3, 4, 5, 6, 4, 5, 5, 4, 6, 4, 4, 6, 4, 3, ...</td>\n",
       "      <td>[103, 408, 66, 625, 42, 71, 595, 102, 142, 94,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[261, 288, 79, 360, 517, 56, 216, 102, 85, 200...</td>\n",
       "      <td>[4, 3, 3, 3, 4, 3, 3, 3, 4, 4, 3, 3, 4, 3, 4, ...</td>\n",
       "      <td>[5, 3, 5, 6, 5, 5, 3, 3, 3, 6, 5, 6, 3, 5, 5, ...</td>\n",
       "      <td>[312, 345, 577, 226, 167, 629, 516, 6, 76, 492...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[337, 76, 353, 456, 233, 71, 61, 406, 140, 100...</td>\n",
       "      <td>[4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 4, 4, 3, 3, ...</td>\n",
       "      <td>[6, 5, 5, 6, 4, 4, 6, 6, 6, 3, 6, 6, 4, 4, 3, ...</td>\n",
       "      <td>[216, 352, 178, 141, 398, 479, 164, 455, 90, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[67, 635, 23, 195, 433, 27, 309, 208, 524, 638...</td>\n",
       "      <td>[3, 4, 3, 3, 4, 3, 4, 3, 4, 4, 4, 3, 4, 3, 4, ...</td>\n",
       "      <td>[4, 3, 6, 5, 3, 5, 6, 6, 6, 5, 3, 5, 4, 4, 4, ...</td>\n",
       "      <td>[606, 140, 634, 623, 145, 223, 87, 218, 10, 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[206, 104, 95, 10, 399, 32, 69, 123, 163, 256,...</td>\n",
       "      <td>[3, 3, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, ...</td>\n",
       "      <td>[3, 5, 5, 4, 6, 6, 4, 4, 5, 6, 6, 4, 3, 5, 3, ...</td>\n",
       "      <td>[611, 54, 198, 393, 208, 144, 100, 308, 245, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               product_sku_hash_list  \\\n",
       "0  [237, 617, 69, 364, 424, 179, 18, 328, 38, 188...   \n",
       "1  [261, 288, 79, 360, 517, 56, 216, 102, 85, 200...   \n",
       "2  [337, 76, 353, 456, 233, 71, 61, 406, 140, 100...   \n",
       "3  [67, 635, 23, 195, 433, 27, 309, 208, 524, 638...   \n",
       "4  [206, 104, 95, 10, 399, 32, 69, 123, 163, 256,...   \n",
       "\n",
       "                                     event_type_list  \\\n",
       "0  [3, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 4, 3, 3, 3, ...   \n",
       "1  [4, 3, 3, 3, 4, 3, 3, 3, 4, 4, 3, 3, 4, 3, 4, ...   \n",
       "2  [4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 4, 4, 3, 3, ...   \n",
       "3  [3, 4, 3, 3, 4, 3, 4, 3, 4, 4, 4, 3, 4, 3, 4, ...   \n",
       "4  [3, 3, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, ...   \n",
       "\n",
       "                                 product_action_list  \\\n",
       "0  [5, 3, 4, 5, 6, 4, 5, 5, 4, 6, 4, 4, 6, 4, 3, ...   \n",
       "1  [5, 3, 5, 6, 5, 5, 3, 3, 3, 6, 5, 6, 3, 5, 5, ...   \n",
       "2  [6, 5, 5, 6, 4, 4, 6, 6, 6, 3, 6, 6, 4, 4, 3, ...   \n",
       "3  [4, 3, 6, 5, 3, 5, 6, 6, 6, 5, 3, 5, 4, 4, 4, ...   \n",
       "4  [3, 5, 5, 4, 6, 6, 4, 4, 5, 6, 6, 4, 3, 5, 3, ...   \n",
       "\n",
       "                                     hashed_url_list  \n",
       "0  [103, 408, 66, 625, 42, 71, 595, 102, 142, 94,...  \n",
       "1  [312, 345, 577, 226, 167, 629, 516, 6, 76, 492...  \n",
       "2  [216, 352, 178, 141, 398, 479, 164, 455, 90, 2...  \n",
       "3  [606, 140, 634, 623, 145, 223, 87, 218, 10, 39...  \n",
       "4  [611, 54, 198, 393, 208, 144, 100, 308, 245, 5...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_features = train.head().columns.tolist() >> nvt.ops.Groupby(\n",
    "    groupby_cols=['session_id_hash'],\n",
    "    aggs={\n",
    "        'product_sku_hash': ['list'],\n",
    "        'event_type': ['list'],\n",
    "        'product_action': ['list'],\n",
    "        'hashed_url': ['list', 'count'],\n",
    "        'server_timestamp_epoch_ms': ['list']\n",
    "    },\n",
    "    sort_cols=\"server_timestamp_epoch_ms\"\n",
    ")\n",
    "\n",
    "MINIMUM_SESSION_LENGTH = 5\n",
    "filtered_sessions = groupby_features >> nvt.ops.Filter(f=lambda df: df[\"hashed_url_count\"] >= MINIMUM_SESSION_LENGTH)\n",
    "\n",
    "# We won't be needing the `session_id_hash` nor the `hashed_url_count` any longer\n",
    "wf = nvt.Workflow(\n",
    "    filtered_sessions[\n",
    "        'product_sku_hash_list',\n",
    "        'event_type_list',\n",
    "        'product_action_list',\n",
    "        'hashed_url_list',\n",
    "    ]\n",
    ")\n",
    "train_processed = wf.fit_transform(train)\n",
    "\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e176a",
   "metadata": {},
   "source": [
    "Let us save the workflow -- we will load it later on to serve the trained model using the Triton Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28db42e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.save('data_preprocessing_workflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c4a13",
   "metadata": {},
   "source": [
    "We are now ready to construct the `Loader` that will feed the data to our model.\n",
    "\n",
    "We begin by reading in the embeddings information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51e1f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('skus.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b1f18d",
   "metadata": {},
   "source": [
    "We are now ready to define the `Loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdbe801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "[INFO]: sparse_operation_kit is imported\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.1.4-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.1.4-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Initialize finished, communication tool: horovod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:47:37.225446: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 22:47:37.226307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 22:47:37.226519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 22:47:37.226679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 22:47:37.282038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 22:47:37.282260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 22:47:37.282424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 22:47:37.282532: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-06-13 22:47:37.282553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24576 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dataloader/tensorflow.py:65: UserWarning: Due to a CUDA memory alignment issue in some Tensorflow operations such as Embedding ops, we recommend that 'batch_size' be at least 16 and also a power of two. Please change 'batch_size' to a number that is a power of two that is greater than or equal to 16.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from merlin.dataloader.tensorflow import Loader\n",
    "from merlin.dataloader.ops.embeddings import EmbeddingOperator\n",
    "import merlin.models.tf as mm\n",
    "\n",
    "loader = Loader(\n",
    "    train_processed,\n",
    "    batch_size=10,\n",
    "    transforms=[\n",
    "        EmbeddingOperator(\n",
    "            embeddings[:, 1:],\n",
    "            id_lookup_table=embeddings[:, 0].astype(int),\n",
    "            lookup_key=\"product_sku_hash_list\",\n",
    "        )\n",
    "    ],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f037d5d",
   "metadata": {},
   "source": [
    "Using the `EmbeddingOperator` object we referenced our `embeddings` and advised the model what to use as a key to look up the information.\n",
    "\n",
    "Below is an example batch of data that our model will consume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7371e23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product_sku_hash_list': <tf.RaggedTensor [[[630],\n",
       "   [44],\n",
       "   [500],\n",
       "   [74],\n",
       "   [152],\n",
       "   [278],\n",
       "   [570],\n",
       "   [508],\n",
       "   [61],\n",
       "   [119],\n",
       "   [595],\n",
       "   [9],\n",
       "   [365],\n",
       "   [31],\n",
       "   [45]] , [[398],\n",
       "            [79],\n",
       "            [139],\n",
       "            [123],\n",
       "            [469],\n",
       "            [547],\n",
       "            [485],\n",
       "            [111],\n",
       "            [17],\n",
       "            [146],\n",
       "            [214],\n",
       "            [520],\n",
       "            [22],\n",
       "            [137],\n",
       "            [68],\n",
       "            [35],\n",
       "            [432],\n",
       "            [489],\n",
       "            [573],\n",
       "            [113],\n",
       "            [15],\n",
       "            [124],\n",
       "            [541],\n",
       "            [294],\n",
       "            [206],\n",
       "            [400],\n",
       "            [176],\n",
       "            [60],\n",
       "            [591]], [[584],\n",
       "                     [495],\n",
       "                     [418],\n",
       "                     [446],\n",
       "                     [483]], [[214],\n",
       "                              [23],\n",
       "                              [438],\n",
       "                              [164],\n",
       "                              [439],\n",
       "                              [13],\n",
       "                              [252],\n",
       "                              [29],\n",
       "                              [285],\n",
       "                              [90],\n",
       "                              [506],\n",
       "                              [345],\n",
       "                              [81],\n",
       "                              [372],\n",
       "                              [331],\n",
       "                              [537],\n",
       "                              [197],\n",
       "                              [403],\n",
       "                              [369],\n",
       "                              [615],\n",
       "                              [184],\n",
       "                              [421],\n",
       "                              [363],\n",
       "                              [233],\n",
       "                              [169],\n",
       "                              [130],\n",
       "                              [166],\n",
       "                              [254],\n",
       "                              [54],\n",
       "                              [486]], [[255],\n",
       "                                       [108],\n",
       "                                       [111],\n",
       "                                       [356],\n",
       "                                       [503],\n",
       "                                       [379],\n",
       "                                       [306],\n",
       "                                       [19],\n",
       "                                       [24],\n",
       "                                       [109],\n",
       "                                       [160],\n",
       "                                       [608],\n",
       "                                       [161],\n",
       "                                       [10],\n",
       "                                       [33],\n",
       "                                       [224],\n",
       "                                       [562],\n",
       "                                       [144],\n",
       "                                       [222],\n",
       "                                       [366],\n",
       "                                       [40],\n",
       "                                       [189],\n",
       "                                       [37],\n",
       "                                       [64],\n",
       "                                       [47],\n",
       "                                       [14],\n",
       "                                       [59],\n",
       "                                       [567],\n",
       "                                       [48],\n",
       "                                       [12]] , [[416],\n",
       "                                                [162],\n",
       "                                                [131],\n",
       "                                                [579],\n",
       "                                                [507],\n",
       "                                                [31]] , [[78],\n",
       "                                                         [136],\n",
       "                                                         [621],\n",
       "                                                         [121],\n",
       "                                                         [393],\n",
       "                                                         [39],\n",
       "                                                         [140],\n",
       "                                                         [262],\n",
       "                                                         [91],\n",
       "                                                         [401],\n",
       "                                                         [129],\n",
       "                                                         [120],\n",
       "                                                         [247],\n",
       "                                                         [87],\n",
       "                                                         [42],\n",
       "                                                         [427],\n",
       "                                                         [83],\n",
       "                                                         [257],\n",
       "                                                         [283],\n",
       "                                                         [168],\n",
       "                                                         [514]], [[260],\n",
       "                                                                  [618],\n",
       "                                                                  [628],\n",
       "                                                                  [505],\n",
       "                                                                  [443],\n",
       "                                                                  [134],\n",
       "                                                                  [186],\n",
       "                                                                  [20],\n",
       "                                                                  [188],\n",
       "                                                                  [173],\n",
       "                                                                  [521],\n",
       "                                                                  [93]] ,\n",
       "  [[529],\n",
       "   [269],\n",
       "   [225],\n",
       "   [259],\n",
       "   [510],\n",
       "   [523],\n",
       "   [572],\n",
       "   [25],\n",
       "   [458],\n",
       "   [27],\n",
       "   [59],\n",
       "   [479],\n",
       "   [179],\n",
       "   [94],\n",
       "   [210],\n",
       "   [101],\n",
       "   [513],\n",
       "   [395]], [[51],\n",
       "            [215],\n",
       "            [8],\n",
       "            [555],\n",
       "            [321]]]>,\n",
       " 'event_type_list': <tf.RaggedTensor [[[3],\n",
       "   [4],\n",
       "   [4],\n",
       "   [3],\n",
       "   [4],\n",
       "   [4],\n",
       "   [3],\n",
       "   [4],\n",
       "   [3],\n",
       "   [4],\n",
       "   [3],\n",
       "   [3],\n",
       "   [4],\n",
       "   [3],\n",
       "   [4]], [[3],\n",
       "          [3],\n",
       "          [4],\n",
       "          [4],\n",
       "          [3],\n",
       "          [3],\n",
       "          [3],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [3],\n",
       "          [4],\n",
       "          [3],\n",
       "          [4],\n",
       "          [3],\n",
       "          [3],\n",
       "          [3],\n",
       "          [3],\n",
       "          [4],\n",
       "          [3],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [3],\n",
       "          [4]], [[3],\n",
       "                 [3],\n",
       "                 [4],\n",
       "                 [3],\n",
       "                 [3]], [[4],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [4],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [4],\n",
       "                        [4],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [4],\n",
       "                        [4],\n",
       "                        [3],\n",
       "                        [4],\n",
       "                        [3],\n",
       "                        [4],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [4],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [3],\n",
       "                        [4],\n",
       "                        [4],\n",
       "                        [4]], [[3],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [3],\n",
       "                               [3],\n",
       "                               [3],\n",
       "                               [3],\n",
       "                               [4],\n",
       "                               [3],\n",
       "                               [4],\n",
       "                               [3],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [3],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [3],\n",
       "                               [3],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [3],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [4]], [[4],\n",
       "                                      [4],\n",
       "                                      [4],\n",
       "                                      [4],\n",
       "                                      [3],\n",
       "                                      [4]], [[3],\n",
       "                                             [4],\n",
       "                                             [3],\n",
       "                                             [4],\n",
       "                                             [3],\n",
       "                                             [3],\n",
       "                                             [3],\n",
       "                                             [4],\n",
       "                                             [3],\n",
       "                                             [4],\n",
       "                                             [3],\n",
       "                                             [3],\n",
       "                                             [3],\n",
       "                                             [3],\n",
       "                                             [3],\n",
       "                                             [3],\n",
       "                                             [4],\n",
       "                                             [3],\n",
       "                                             [4],\n",
       "                                             [3],\n",
       "                                             [4]], [[3],\n",
       "                                                    [3],\n",
       "                                                    [3],\n",
       "                                                    [3],\n",
       "                                                    [3],\n",
       "                                                    [3],\n",
       "                                                    [3],\n",
       "                                                    [3],\n",
       "                                                    [4],\n",
       "                                                    [3],\n",
       "                                                    [4],\n",
       "                                                    [4]], [[4],\n",
       "                                                           [4],\n",
       "                                                           [3],\n",
       "                                                           [4],\n",
       "                                                           [3],\n",
       "                                                           [3],\n",
       "                                                           [4],\n",
       "                                                           [3],\n",
       "                                                           [4],\n",
       "                                                           [3],\n",
       "                                                           [4],\n",
       "                                                           [4],\n",
       "                                                           [3],\n",
       "                                                           [4],\n",
       "                                                           [4],\n",
       "                                                           [3],\n",
       "                                                           [4],\n",
       "                                                           [4]], [[4],\n",
       "                                                                  [4],\n",
       "                                                                  [3],\n",
       "                                                                  [4],\n",
       "                                                                  [4]]]>,\n",
       " 'product_action_list': <tf.RaggedTensor [[[5],\n",
       "   [5],\n",
       "   [5],\n",
       "   [5],\n",
       "   [3],\n",
       "   [3],\n",
       "   [3],\n",
       "   [4],\n",
       "   [3],\n",
       "   [6],\n",
       "   [3],\n",
       "   [4],\n",
       "   [3],\n",
       "   [5],\n",
       "   [5]], [[4],\n",
       "          [3],\n",
       "          [6],\n",
       "          [3],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [6],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [6],\n",
       "          [5],\n",
       "          [6],\n",
       "          [5],\n",
       "          [3],\n",
       "          [3],\n",
       "          [4],\n",
       "          [4],\n",
       "          [3],\n",
       "          [3],\n",
       "          [4],\n",
       "          [4],\n",
       "          [6],\n",
       "          [4],\n",
       "          [6],\n",
       "          [6]], [[4],\n",
       "                 [6],\n",
       "                 [6],\n",
       "                 [3],\n",
       "                 [6]], [[3],\n",
       "                        [6],\n",
       "                        [5],\n",
       "                        [5],\n",
       "                        [4],\n",
       "                        [6],\n",
       "                        [5],\n",
       "                        [6],\n",
       "                        [3],\n",
       "                        [4],\n",
       "                        [6],\n",
       "                        [5],\n",
       "                        [6],\n",
       "                        [6],\n",
       "                        [3],\n",
       "                        [5],\n",
       "                        [4],\n",
       "                        [3],\n",
       "                        [4],\n",
       "                        [6],\n",
       "                        [6],\n",
       "                        [5],\n",
       "                        [4],\n",
       "                        [4],\n",
       "                        [5],\n",
       "                        [5],\n",
       "                        [6],\n",
       "                        [6],\n",
       "                        [4],\n",
       "                        [4]], [[4],\n",
       "                               [3],\n",
       "                               [3],\n",
       "                               [6],\n",
       "                               [3],\n",
       "                               [4],\n",
       "                               [6],\n",
       "                               [3],\n",
       "                               [4],\n",
       "                               [5],\n",
       "                               [5],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [4],\n",
       "                               [3],\n",
       "                               [4],\n",
       "                               [6],\n",
       "                               [3],\n",
       "                               [4],\n",
       "                               [6],\n",
       "                               [5],\n",
       "                               [6],\n",
       "                               [4],\n",
       "                               [5],\n",
       "                               [4],\n",
       "                               [6],\n",
       "                               [3],\n",
       "                               [6],\n",
       "                               [6],\n",
       "                               [4]], [[5],\n",
       "                                      [5],\n",
       "                                      [3],\n",
       "                                      [3],\n",
       "                                      [6],\n",
       "                                      [3]], [[6],\n",
       "                                             [4],\n",
       "                                             [3],\n",
       "                                             [5],\n",
       "                                             [5],\n",
       "                                             [6],\n",
       "                                             [3],\n",
       "                                             [3],\n",
       "                                             [4],\n",
       "                                             [3],\n",
       "                                             [4],\n",
       "                                             [6],\n",
       "                                             [5],\n",
       "                                             [5],\n",
       "                                             [3],\n",
       "                                             [4],\n",
       "                                             [4],\n",
       "                                             [4],\n",
       "                                             [6],\n",
       "                                             [4],\n",
       "                                             [6]], [[6],\n",
       "                                                    [3],\n",
       "                                                    [6],\n",
       "                                                    [3],\n",
       "                                                    [5],\n",
       "                                                    [5],\n",
       "                                                    [4],\n",
       "                                                    [3],\n",
       "                                                    [3],\n",
       "                                                    [4],\n",
       "                                                    [3],\n",
       "                                                    [6]], [[6],\n",
       "                                                           [4],\n",
       "                                                           [5],\n",
       "                                                           [5],\n",
       "                                                           [5],\n",
       "                                                           [6],\n",
       "                                                           [5],\n",
       "                                                           [4],\n",
       "                                                           [3],\n",
       "                                                           [6],\n",
       "                                                           [4],\n",
       "                                                           [5],\n",
       "                                                           [4],\n",
       "                                                           [3],\n",
       "                                                           [6],\n",
       "                                                           [3],\n",
       "                                                           [5],\n",
       "                                                           [6]], [[3],\n",
       "                                                                  [5],\n",
       "                                                                  [3],\n",
       "                                                                  [4],\n",
       "                                                                  [3]]]>,\n",
       " 'hashed_url_list': <tf.RaggedTensor [[[348],\n",
       "   [92],\n",
       "   [240],\n",
       "   [48],\n",
       "   [326],\n",
       "   [349],\n",
       "   [137],\n",
       "   [537],\n",
       "   [173],\n",
       "   [482],\n",
       "   [251],\n",
       "   [238],\n",
       "   [182],\n",
       "   [236],\n",
       "   [341]], [[279],\n",
       "            [612],\n",
       "            [585],\n",
       "            [310],\n",
       "            [238],\n",
       "            [85],\n",
       "            [464],\n",
       "            [204],\n",
       "            [27],\n",
       "            [579],\n",
       "            [488],\n",
       "            [172],\n",
       "            [227],\n",
       "            [451],\n",
       "            [603],\n",
       "            [82],\n",
       "            [534],\n",
       "            [70],\n",
       "            [364],\n",
       "            [242],\n",
       "            [115],\n",
       "            [518],\n",
       "            [365],\n",
       "            [22],\n",
       "            [548],\n",
       "            [88],\n",
       "            [27],\n",
       "            [31],\n",
       "            [179]], [[14],\n",
       "                     [18],\n",
       "                     [462],\n",
       "                     [422],\n",
       "                     [249]], [[549],\n",
       "                              [314],\n",
       "                              [73],\n",
       "                              [54],\n",
       "                              [362],\n",
       "                              [29],\n",
       "                              [268],\n",
       "                              [68],\n",
       "                              [257],\n",
       "                              [265],\n",
       "                              [433],\n",
       "                              [163],\n",
       "                              [35],\n",
       "                              [258],\n",
       "                              [135],\n",
       "                              [20],\n",
       "                              [252],\n",
       "                              [15],\n",
       "                              [525],\n",
       "                              [189],\n",
       "                              [183],\n",
       "                              [9],\n",
       "                              [215],\n",
       "                              [260],\n",
       "                              [259],\n",
       "                              [124],\n",
       "                              [79],\n",
       "                              [128],\n",
       "                              [261],\n",
       "                              [460]], [[607],\n",
       "                                       [129],\n",
       "                                       [52],\n",
       "                                       [320],\n",
       "                                       [118],\n",
       "                                       [146],\n",
       "                                       [8],\n",
       "                                       [253],\n",
       "                                       [83],\n",
       "                                       [246],\n",
       "                                       [91],\n",
       "                                       [547],\n",
       "                                       [119],\n",
       "                                       [106],\n",
       "                                       [391],\n",
       "                                       [384],\n",
       "                                       [268],\n",
       "                                       [146],\n",
       "                                       [241],\n",
       "                                       [54],\n",
       "                                       [498],\n",
       "                                       [458],\n",
       "                                       [497],\n",
       "                                       [420],\n",
       "                                       [158],\n",
       "                                       [319],\n",
       "                                       [273],\n",
       "                                       [389],\n",
       "                                       [437],\n",
       "                                       [370]], [[287],\n",
       "                                                [396],\n",
       "                                                [56],\n",
       "                                                [187],\n",
       "                                                [196],\n",
       "                                                [223]], [[217],\n",
       "                                                         [3],\n",
       "                                                         [55],\n",
       "                                                         [269],\n",
       "                                                         [125],\n",
       "                                                         [9],\n",
       "                                                         [555],\n",
       "                                                         [487],\n",
       "                                                         [257],\n",
       "                                                         [77],\n",
       "                                                         [552],\n",
       "                                                         [23],\n",
       "                                                         [271],\n",
       "                                                         [185],\n",
       "                                                         [447],\n",
       "                                                         [157],\n",
       "                                                         [247],\n",
       "                                                         [558],\n",
       "                                                         [626],\n",
       "                                                         [282],\n",
       "                                                         [255]], [[155],\n",
       "                                                                  [95],\n",
       "                                                                  [633],\n",
       "                                                                  [618],\n",
       "                                                                  [231],\n",
       "                                                                  [165],\n",
       "                                                                  [443],\n",
       "                                                                  [334],\n",
       "                                                                  [262],\n",
       "                                                                  [134],\n",
       "                                                                  [49],\n",
       "                                                                  [45]] ,\n",
       "  [[472],\n",
       "   [34],\n",
       "   [554],\n",
       "   [414],\n",
       "   [311],\n",
       "   [84],\n",
       "   [449],\n",
       "   [456],\n",
       "   [550],\n",
       "   [587],\n",
       "   [278],\n",
       "   [624],\n",
       "   [573],\n",
       "   [64],\n",
       "   [242],\n",
       "   [627],\n",
       "   [470],\n",
       "   [240]], [[173],\n",
       "            [139],\n",
       "            [192],\n",
       "            [161],\n",
       "            [80]] ]>,\n",
       " 'embeddings': <tf.RaggedTensor [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [-0.33148777, 0.042811364, 0.54028046, 0.48200518, 0.46572226,\n",
       "    0.108455084, 0.50517094, -0.2328445, 0.010072819, 0.5384407,\n",
       "    -0.061840143, -0.36751026, 0.21108438, -0.17148143, 0.28915682,\n",
       "    -0.41322517, -0.27472058, 0.3624975, -0.39791992, -0.038112126,\n",
       "    -0.2965224, 0.20643266, 0.09248234, 0.16693215, -0.3697677, 0.50352854,\n",
       "    0.5997183, 0.3150954, 0.083656594, 0.16641077, 0.5728771, 0.54310703,\n",
       "    -0.43814805, -0.32540676, -0.15240619, 0.23400714, -0.33402795,\n",
       "    -0.33856383, -0.07228832, 0.010275369, -0.2995882, 0.25717148,\n",
       "    -0.3706656, -0.16644149, -0.24592024, 0.5912373, 0.4505436, -0.23901205,\n",
       "    0.05636491, -0.2636091],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]                                ,\n",
       "  [[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.15178373, -0.06959921, 0.4600072, ..., -0.34715325, -0.40888765,\n",
       "    0.5625491],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   ...,\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0]]                               ,\n",
       "  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]                             ,\n",
       "  [[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [-0.37347263, 0.15264417, -0.42354664, ..., 0.4446932, 0.17538299,\n",
       "    -0.18143843],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   ...,\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0]]                              ,\n",
       "  [[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   ...,\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0]],\n",
       "  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]                             ,\n",
       "  [[0.16118085, 0.103630334, 0.3836858, ..., -0.31941277, 0.5882028,\n",
       "    0.063423455],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   ...,\n",
       "   [0.5802182, -0.39146614, 0.38707653, ..., -0.41235945, 0.4242771,\n",
       "    -0.008394575],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0]]                             ,\n",
       "  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]                             ,\n",
       "  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [-0.27611795, 0.5661896, 0.13777561, 0.22182639, -0.05877591,\n",
       "    0.014681047, 0.101388045, 0.22836637, 0.118923165, 0.07666775,\n",
       "    0.028228143, 0.38929665, -0.3033932, 0.1477, 0.14269409, -0.42184043,\n",
       "    0.0066546546, -0.16822624, -0.34405547, 0.23158285, 0.45302412,\n",
       "    -0.05177951, -0.063466795, 0.33643535, -0.4396951, -0.17523159,\n",
       "    0.099394046, 0.49470326, -0.28308386, 0.05200401, -0.37167448,\n",
       "    -0.19137745, 0.41306695, -0.20229833, 0.08245366, 0.42549554, 0.5552439,\n",
       "    -0.3544073, 0.24832554, -0.18741867, 0.28453752, 0.33857003, 0.08641148,\n",
       "    0.04629373, 0.026196696, 0.33566013, -0.2778643, 0.113621384,\n",
       "    -0.0831963, 0.02918703],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [-0.400719, -0.307807, -0.008609794, 0.029813904, 0.14662908,\n",
       "    0.0039974195, -0.36614874, 0.19191234, -0.05782934, -0.052253228,\n",
       "    0.382025, 0.34291086, 0.3101748, 0.5581092, 0.40836987, 0.48458242,\n",
       "    0.12114907, 0.3469603, 0.04671534, 0.20910645, -0.21120997, -0.3301365,\n",
       "    0.034268137, 0.039072614, -0.42842707, -0.2367593, -0.41626167,\n",
       "    0.3403575, 0.08427354, 0.47587064, -0.2821282, -0.06570399, 0.26273653,\n",
       "    0.47482315, -0.39796752, 0.10335877, -0.13865665, 0.5006734, 0.08796652,\n",
       "    0.50580597, 0.46179947, -0.3377954, 0.1555661, 0.28126514, 0.57293445,\n",
       "    -0.25218347, -0.051277246, -0.08610131, -0.43677366, 0.39654282],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]                                ,\n",
       "  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [-0.23745668, 0.4361812, -0.40558344, 0.29263276, 0.2184941, -0.3091055,\n",
       "    -0.22288653, 0.26747704, 0.5307812, -0.14436378, 0.48452663, 0.37690607,\n",
       "    -0.31540126, 0.25555426, 0.30608538, 0.4768201, -0.3142145, -0.40401337,\n",
       "    -0.4331247, 0.30926654, 0.23772003, 0.3922856, 0.39371127, 0.57374465,\n",
       "    0.5893867, 0.26616338, -0.39884982, 0.07806096, -0.28485057, 0.4985583,\n",
       "    -0.30202222, -0.04703199, 0.46722892, -0.06477662, -0.1219124,\n",
       "    0.21840474, -0.167589, 0.48608643, -0.3185576, -0.25282574, 0.4547178,\n",
       "    0.16550608, -0.34369817, -0.14444843, -0.25264195, -0.2956502,\n",
       "    0.3193974, -0.11221282, -0.22909693, -0.37023956],\n",
       "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "   [-0.17378272, 0.5540751, 0.20313449, 0.09857125, -0.16936128,\n",
       "    -0.22505806, -0.005355112, -0.37744856, 0.23365468, 0.2106992,\n",
       "    0.37227437, -0.03419273, 0.12618087, 0.028105237, -0.3378683,\n",
       "    -0.34816152, 0.36421224, -0.24180578, -0.017228818, -0.42113817,\n",
       "    -0.43914053, -0.10481416, 0.5310645, 0.18112545, 0.16705367, -0.3355088,\n",
       "    -0.16473113, 0.14387442, -0.33599326, 0.15525512, 0.12461086, 0.2756798,\n",
       "    0.06819062, 0.36425903, 0.5903888, -0.33572334, -0.037187077,\n",
       "    -0.055719346, 0.53837895, -0.27602223, 0.21274665, -0.1988884,\n",
       "    -0.3885728, 0.23277982, 0.1297604, -0.2618169, -0.34299353, 0.5888704,\n",
       "    0.18512458, -0.3042517]]                                                ]>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = mm.sample_batch(loader, batch_size=10, include_targets=False, prepare_features=True)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e61e71",
   "metadata": {},
   "source": [
    "## Creating and training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461926e",
   "metadata": {},
   "source": [
    "We are now ready to construct our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6867c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import merlin.models.tf as mm\n",
    "\n",
    "input_block = mm.InputBlockV2(\n",
    "    loader.output_schema,\n",
    "    embeddings=mm.Embeddings(\n",
    "        loader.output_schema.select_by_tag(Tags.CATEGORICAL),\n",
    "        sequence_combiner=None,\n",
    "    ),\n",
    "    pretrained_embeddings=mm.PretrainedEmbeddings(\n",
    "        loader.output_schema.select_by_tag(Tags.EMBEDDING),\n",
    "        sequence_combiner=None,\n",
    "        normalizer=\"l2-norm\",\n",
    "        output_dims={\"embeddings\": 128},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb788f",
   "metadata": {},
   "source": [
    "We have now constructed an `input_block` that will take our batch and transform it in a fashion that will make it amenable for further processing by subsequent layers of our model.\n",
    "\n",
    "To test that everything has worked, we can pass our exmple `batch` through the `input_block`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f8afa56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[[0.0, 0.0, 0.0, ..., 0.033245813, 0.0052459724, 0.009340502],\n",
       "  [0.0, 0.0, 0.0, ..., -0.03912141, -0.028644359, 0.020283107],\n",
       "  [0.0, 0.0, 0.0, ..., -0.043929007, -0.0017804392, -0.024945557],\n",
       "  ...,\n",
       "  [0.0, 0.0, 0.0, ..., -0.011155188, 0.048666093, 0.016707215],\n",
       "  [0.0, 0.0, 0.0, ..., -0.03394983, -0.016113747, -0.007572569],\n",
       "  [0.0, 0.0, 0.0, ..., 0.024669837, -0.008599378, -0.036812913]]  ,\n",
       " [[0.0, 0.0, 0.0, ..., 0.0129964985, 0.037252497, -0.011765491],\n",
       "  [-0.040574208, -0.083892755, -0.045047045, ..., -0.0005783327,\n",
       "   0.030515615, -0.023694146],\n",
       "  [0.0, 0.0, 0.0, ..., 0.005067408, -0.045417883, -0.030529022],\n",
       "  ...,\n",
       "  [0.0, 0.0, 0.0, ..., 0.010716151, -0.03203863, -0.031108761],\n",
       "  [0.0, 0.0, 0.0, ..., -0.03814436, 0.0040722713, 0.04889537],\n",
       "  [0.0, 0.0, 0.0, ..., 0.010288417, 0.009645414, -0.023971736]] ,\n",
       " [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.010860432, -0.027500821, -0.03094474, -0.0032636411,\n",
       "   -0.03352195, -0.013144396, -0.02660929, -0.0026154742, 0.04611892,\n",
       "   0.045896675, -0.019551098, -0.009286128, -0.020806253, 0.034935642,\n",
       "   -0.006945871, -0.027873088, 0.006332565, 0.009951033, -0.015123643,\n",
       "   -0.011763681, 0.009474982, 0.021276187, -0.014602136, 0.02138703,\n",
       "   0.009326994, -0.01934483, 0.034409437, -0.047086846, 0.010280263,\n",
       "   0.0029265285, 0.010297764, -0.040411748, 0.021657709, -0.03631226,\n",
       "   0.008340277, -0.015767574, 0.03564557, -0.039960455, 0.0071345083,\n",
       "   0.018995512, 0.045419242, 0.017645154, 0.03307483, -0.008304726,\n",
       "   -0.03353994, 0.017020296, -0.045442414, -0.005463898],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.010860432, -0.027500821, -0.03094474, -0.0032636411,\n",
       "   -0.03352195, -0.013144396, -0.02660929, -0.0026154742, 0.013902258,\n",
       "   -0.024614453, -0.02329415, -0.028383434, 0.046571974, -0.013302065,\n",
       "   -0.029980827, 0.043782834, -0.043696463, 0.010653377, -0.043459546,\n",
       "   -0.028892076, -0.011752903, 0.042820726, -0.008955598, -0.009228744,\n",
       "   -0.034719586, 0.014549043, 0.0045045502, 0.007896125, -0.00055409595,\n",
       "   0.03505056, 0.032060657, -0.047526706, 0.01721758, -0.0024201386,\n",
       "   -0.041130077, 0.048946027, -0.0040565953, -0.016841065, 0.04415318,\n",
       "   0.047782335, -0.024564613, -0.03632765, -0.02026168, -0.016132712,\n",
       "   -0.031790234, -0.013205241, -0.03315393, 0.008310448],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, -0.044846106, -0.0053237192, 0.0333349, 0.0167627,\n",
       "   -0.008625079, -0.048158277, -0.024700118, 0.0081964135, 0.02565134,\n",
       "   -0.040444873, -0.0077557564, -0.042086996, -0.03267868, -0.019429673,\n",
       "   0.036944877, -0.039541174, 0.006008614, -0.0031566024, 0.015287969,\n",
       "   0.016986635, -0.047043752, 0.03324504, 0.019161213, 0.04992417,\n",
       "   -0.034719586, 0.014549043, 0.0045045502, 0.007896125, -0.00055409595,\n",
       "   0.03505056, 0.032060657, -0.047526706, -0.003913153, 0.022037614,\n",
       "   0.019649472, 0.005081199, 0.023570944, -0.044354834, 0.031905044,\n",
       "   0.0031156316, -0.036762524, 0.0145204775, 0.027398396, -0.039945792,\n",
       "   -0.04074826, -0.038428914, -0.047703255, 0.029859293],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.010860432, -0.027500821, -0.03094474, -0.0032636411,\n",
       "   -0.03352195, -0.013144396, -0.02660929, -0.0026154742, -0.030357255,\n",
       "   0.029023234, -0.03468139, -0.013152003, 0.033370826, 0.030172441,\n",
       "   0.042111184, -0.033307064, 0.0076619014, -0.045505833, -0.047968842,\n",
       "   -0.015073705, 0.0155772455, 0.036287878, 0.047007326, 0.028790403,\n",
       "   -0.04161004, 0.04955243, 0.0072652586, 0.038647998, -0.027222885,\n",
       "   0.022435281, -0.022784805, -0.030534972, 0.046370294, -0.041429736,\n",
       "   -0.030949235, 0.043059554, 0.021033358, -0.02658447, -0.015860092,\n",
       "   -0.003797125, -0.03854028, -0.038503576, -0.035965074, 0.025447395,\n",
       "   0.037013795, -0.0041448697, 0.00049578026, 0.009641934],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.010860432, -0.027500821, -0.03094474, -0.0032636411,\n",
       "   -0.03352195, -0.013144396, -0.02660929, -0.0026154742, -0.00037865713,\n",
       "   -0.0061414614, 0.0014117137, -0.034000028, -0.006700121, 0.023143675,\n",
       "   -0.003331136, -0.025592972, 0.048993174, -0.019668853, 0.04063535,\n",
       "   0.018387843, -0.042947482, 0.02046683, -0.03457948, 0.0421176,\n",
       "   -0.034719586, 0.014549043, 0.0045045502, 0.007896125, -0.00055409595,\n",
       "   0.03505056, 0.032060657, -0.047526706, -0.0357198, 0.042321596,\n",
       "   -0.03895434, 0.00093059614, -0.009396065, -0.047095586, 0.039757553,\n",
       "   0.045122597, -0.0066716447, 0.013952468, -0.018217884, -0.014189757,\n",
       "   0.03706492, 0.04485411, 0.041072164, -0.024925483]]                   ,\n",
       " [[0.0, 0.0, 0.0, ..., -0.034757257, -0.009958614, -0.013385128],\n",
       "  [0.022529965, 0.12307047, 0.08110119, ..., -0.042758454, -0.0053436756,\n",
       "   -0.010925245],\n",
       "  [0.0, 0.0, 0.0, ..., -0.042904843, -0.024806906, -0.03815242],\n",
       "  ...,\n",
       "  [0.0, 0.0, 0.0, ..., -0.00040740892, 0.01825926, 0.008182488],\n",
       "  [0.0, 0.0, 0.0, ..., 0.04179663, -0.049849786, -0.0478019],\n",
       "  [0.0, 0.0, 0.0, ..., 0.0110083, -0.035090853, 0.04283971]]             ,\n",
       " [[0.0, 0.0, 0.0, ..., -0.04299171, 0.026218105, 0.035127316],\n",
       "  [0.0, 0.0, 0.0, ..., -0.021849776, -0.01913252, -0.04110702],\n",
       "  [0.0, 0.0, 0.0, ..., -0.012873746, -0.0321229, 0.008708082],\n",
       "  ...,\n",
       "  [0.0, 0.0, 0.0, ..., -0.043384887, 0.014440801, 0.032367174],\n",
       "  [0.0, 0.0, 0.0, ..., -0.038961887, 0.018235352, 0.0056115612],\n",
       "  [0.0, 0.0, 0.0, ..., 0.01479635, -0.03896283, 0.03752965]]    ,\n",
       " [[0.0, 0.0, 0.0, ..., 0.028539624, -0.04803157, -0.0043517463],\n",
       "  [0.0, 0.0, 0.0, ..., 0.039663162, 0.030939166, -0.040370535],\n",
       "  [0.0, 0.0, 0.0, ..., 0.01220715, -0.021256352, 0.049104754],\n",
       "  [0.0, 0.0, 0.0, ..., -0.028864635, 0.044992317, 0.012974504],\n",
       "  [0.0, 0.0, 0.0, ..., -0.008001018, 0.02026147, 0.02140646],\n",
       "  [0.0, 0.0, 0.0, ..., -0.03394983, -0.016113747, -0.007572569]],\n",
       " [[-0.14187586, 0.11372264, 0.00794608, ..., -0.0036085956, -0.010763776,\n",
       "   0.0046479926],\n",
       "  [0.0, 0.0, 0.0, ..., 0.038471702, -0.035589993, -0.0050429814],\n",
       "  [0.0, 0.0, 0.0, ..., -0.006318271, 0.012074351, 0.0012505539],\n",
       "  ...,\n",
       "  [-0.019819023, -0.021375583, -0.19520089, ..., -0.0006967187,\n",
       "   0.004513599, 0.013593305],\n",
       "  [0.0, 0.0, 0.0, ..., -0.036795534, 0.032288764, 0.021494519],\n",
       "  [0.0, 0.0, 0.0, ..., -0.025200045, -0.024549508, 0.0063008554]]        ,\n",
       " [[0.0, 0.0, 0.0, ..., 0.012031101, 0.0345197, 0.03963152],\n",
       "  [0.0, 0.0, 0.0, ..., -0.030469561, 0.010880373, -0.03497213],\n",
       "  [0.0, 0.0, 0.0, ..., -0.042607393, 0.002041161, 0.001611542],\n",
       "  ...,\n",
       "  [0.0, 0.0, 0.0, ..., 0.048385177, 0.013966229, 0.037750434],\n",
       "  [0.0, 0.0, 0.0, ..., 0.01812223, 0.034357738, -0.008953474],\n",
       "  [0.0, 0.0, 0.0, ..., 0.047143403, -0.012298964, 0.03657634]] ,\n",
       " [[0.0, 0.0, 0.0, ..., 0.033131186, 0.025202882, -0.03662927],\n",
       "  [0.0, 0.0, 0.0, ..., -0.008787036, -0.016754031, -0.03750031],\n",
       "  [0.0, 0.0, 0.0, ..., -0.0012032166, -0.009509932, -0.046484746],\n",
       "  ...,\n",
       "  [0.0, 0.0, 0.0, ..., 0.046090376, 0.011547543, 0.046036217],\n",
       "  [0.0, 0.0, 0.0, ..., -0.03816538, 0.012832645, -0.030255092],\n",
       "  [0.0, 0.0, 0.0, ..., -0.0024570338, 0.01934005, 0.047999788]]   ,\n",
       " [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, -0.044846106, -0.0053237192, 0.0333349, 0.0167627,\n",
       "   -0.008625079, -0.048158277, -0.024700118, 0.0081964135, -0.011866726,\n",
       "   0.014198277, 0.025477145, -0.04412961, 0.027158644, -0.017452192,\n",
       "   -0.003242243, -0.038705565, 0.02832171, -0.013292622, 0.019410383,\n",
       "   0.022137228, 0.025305662, 0.04456326, -0.018786704, -0.04707476,\n",
       "   -0.04161004, 0.04955243, 0.0072652586, 0.038647998, -0.027222885,\n",
       "   0.022435281, -0.022784805, -0.030534972, 0.005525209, -0.035159577,\n",
       "   -0.001411926, -0.02173748, -0.036447406, 0.029615376, -0.044834223,\n",
       "   -0.017227422, -0.048427593, -0.044927288, -0.013659917, -0.045103397,\n",
       "   -0.039201785, 0.02492119, 0.0013615005, 0.042989198],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, -0.044846106, -0.0053237192, 0.0333349, 0.0167627,\n",
       "   -0.008625079, -0.048158277, -0.024700118, 0.0081964135, -0.020353545,\n",
       "   -0.0068659186, 0.013433721, 0.014971349, -0.04543929, -0.02153523,\n",
       "   0.007867776, -0.042571258, 0.0034503452, 0.035648827, -0.04326309,\n",
       "   -0.044250917, 0.035362456, 0.04486629, 0.011673164, -0.03277985,\n",
       "   -0.027971102, 0.02274951, -0.041536607, 0.009886466, 0.04782616,\n",
       "   -0.040393878, -0.028982569, -0.0028223507, -0.014691673, 0.04648084,\n",
       "   0.018042747, -0.008507658, -0.009705555, 0.037596848, 0.042849932,\n",
       "   0.013700988, 0.048641685, 0.0068841465, -0.0061390996, -0.034400035,\n",
       "   -0.023724604, 0.046302486, 0.031237613, -0.00880301],\n",
       "  [-0.14749196, 0.09923253, 0.058175687, -0.08288857, -0.03208487,\n",
       "   0.035318296, 0.02122597, 0.09415446, -0.028794343, 0.123818785,\n",
       "   -0.12368974, 0.07123028, 0.009835051, -0.06684358, 0.04409614,\n",
       "   0.011175744, 0.09416911, 0.105204985, 0.06590392, 0.045014698,\n",
       "   -0.10226461, -0.053025104, -0.14689413, 0.056244247, -0.11165976,\n",
       "   -0.0058447444, -0.007661338, -0.107812904, 0.08735069, -0.18779895,\n",
       "   0.014545427, -0.045351114, 0.00673955, 0.058432218, 0.046157893,\n",
       "   -0.007869651, 0.011307512, -0.04283641, -0.027851226, -0.010458762,\n",
       "   -0.11624539, 0.11675688, -0.012395178, -0.020842833, 0.052795533,\n",
       "   -0.008284585, -0.000403943, -0.050116684, 0.14143607, 0.20406312,\n",
       "   0.12437207, -0.03197311, 0.045214392, -0.047580887, 0.0842539,\n",
       "   -0.16188252, -0.16964176, -0.0052979817, -0.014725618, 0.03891907,\n",
       "   -0.14045922, 0.10227133, 0.057006646, -0.019775476, 0.07594905,\n",
       "   -0.04233873, 0.033077303, 0.05448917, 0.022574706, 0.18181118,\n",
       "   -0.06417777, -0.026681023, -0.10212319, 0.030756073, 0.05767462,\n",
       "   -0.0126245115, -0.13388492, 0.094449595, -0.1618987, 0.09549588,\n",
       "   0.03864649, 0.004090808, 0.059361115, -0.14067104, 0.05748215,\n",
       "   0.050990496, -0.058745, -0.0817768, 0.056974914, -0.06743032,\n",
       "   0.0039805463, 0.11129629, -0.043779675, 0.018448612, 0.16788624,\n",
       "   0.07950111, -0.06316401, 0.051003184, 0.09168561, 0.0054090293,\n",
       "   0.039107885, 0.06754421, -0.054902125, 0.024986729, -0.06108436,\n",
       "   0.099467464, 0.146807, 0.122197144, -0.052597743, -0.29578835,\n",
       "   -0.22659658, 0.033178236, -0.07756142, -0.11547835, 0.049692824,\n",
       "   -0.13423932, 0.15214714, 0.0725775, 0.1231022, 0.08578145,\n",
       "   -0.0026877418, 0.07017418, 0.024927316, -0.012192597, -0.045817304,\n",
       "   0.036619734, 0.009720584, 0.07444365, 0.010860432, -0.027500821,\n",
       "   -0.03094474, -0.0032636411, -0.03352195, -0.013144396, -0.02660929,\n",
       "   -0.0026154742, 0.03016815, -0.01734054, -0.019183194, 0.019154754,\n",
       "   -0.020658707, -0.010045432, -0.0028807633, -0.008184433, 0.024840388,\n",
       "   0.044898305, 0.031911302, 0.0115093365, -0.02379303, 0.015181612,\n",
       "   -0.032255366, 0.03216925, -0.04161004, 0.04955243, 0.0072652586,\n",
       "   0.038647998, -0.027222885, 0.022435281, -0.022784805, -0.030534972,\n",
       "   -0.03646058, -0.040254544, -0.02670361, 0.045474816, 0.021845665,\n",
       "   -0.04760493, -0.012912344, 0.027038876, 0.003945984, -0.0020345673,\n",
       "   -0.04788971, 0.0220103, 0.037950803, 0.023674931, 0.04329821,\n",
       "   0.035323393],\n",
       "  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "   0.0, 0.0, -0.044846106, -0.0053237192, 0.0333349, 0.0167627,\n",
       "   -0.008625079, -0.048158277, -0.024700118, 0.0081964135, 0.007866144,\n",
       "   -0.03209839, 0.046582613, 0.043507013, -0.020906402, 0.008381367,\n",
       "   0.013294112, 0.027497206, -0.004698027, -0.049694728, 0.031078134,\n",
       "   0.008630812, 0.043953706, 0.022663716, -0.039167725, -0.002308689,\n",
       "   0.009326994, -0.01934483, 0.034409437, -0.047086846, 0.010280263,\n",
       "   0.0029265285, 0.010297764, -0.040411748, -0.0019460097, -0.030261815,\n",
       "   0.027550284, -0.046140697, -0.02106501, 0.023643326, 0.011916578,\n",
       "   -0.04226444, -0.049855243, 0.026705477, 0.012643602, -0.0064373724,\n",
       "   0.017789971, 0.033036713, 0.033496868, 0.00620538],\n",
       "  [-0.055040445, -0.19243965, 0.119336836, 0.11237359, -0.053843684,\n",
       "   0.041454513, 0.014623246, -0.20678172, 0.008719674, 0.08104023,\n",
       "   -0.19455622, 0.120194204, 0.06595733, -0.07550021, -0.066786215,\n",
       "   0.08292728, -0.06717223, 0.21587624, 0.11766015, 0.099798225,\n",
       "   0.099800445, 0.18003929, -0.0032472373, -0.049862478, 0.17650887,\n",
       "   -0.028004909, -0.059108224, 0.030470897, 0.23429053, 0.040506706,\n",
       "   0.08719174, -0.058794614, 0.115339346, 0.0978026, 0.03315754,\n",
       "   0.014203197, -0.020169469, 0.049199957, 0.041750856, 0.0044337227,\n",
       "   0.018275477, 0.19651629, -0.056741226, 0.031752694, -0.07751842,\n",
       "   -0.09031689, -0.01921216, -0.045058798, -0.08004419, -0.046970412,\n",
       "   0.07141859, 0.09966025, -0.016926203, 0.053163875, -0.07166918,\n",
       "   0.0053269095, 0.047719773, -0.027973227, 0.028711537, 0.108715504,\n",
       "   0.12587012, -0.01968675, 0.087074526, -0.108198375, -0.06705334,\n",
       "   -0.021674193, 0.16722664, 0.053305615, 0.039231915, 0.06713001,\n",
       "   -0.10944505, -0.06824015, 0.0051487815, 0.025110573, 0.08091153,\n",
       "   -0.020445215, -0.016269272, 0.17308377, 0.099063076, -0.03333246,\n",
       "   -0.0177043, -0.07437155, 0.04298738, 0.07654516, -0.09686542,\n",
       "   0.09549771, 0.010748412, 0.0037430972, -0.046883106, -0.11443123,\n",
       "   -0.09054958, 0.061737373, 0.08884913, -0.08082301, -0.20028949,\n",
       "   0.04635108, -0.01937626, -0.06636422, -0.012397871, -0.080997564,\n",
       "   -0.14483532, 0.092948645, 0.04930788, -0.0018163591, -0.0036597743,\n",
       "   -0.041608296, 0.029186394, 0.04300208, 0.10207797, 0.10992314,\n",
       "   0.056170203, -0.08982978, -0.118020095, -0.070991814, -0.04159628,\n",
       "   -0.17065647, -0.04078532, -0.02345191, 0.12611663, 0.057444718,\n",
       "   0.090198286, 0.10074847, 0.03040875, 0.09026444, 0.030704597,\n",
       "   0.03849397, -0.026155533, 0.05409053, -0.044846106, -0.0053237192,\n",
       "   0.0333349, 0.0167627, -0.008625079, -0.048158277, -0.024700118,\n",
       "   0.0081964135, -0.02782656, 0.024856891, 0.039045703, -0.047049988,\n",
       "   -0.02429582, -0.036406506, -0.028359462, -0.0044570193, 0.014375303,\n",
       "   -0.045669507, 0.0063163154, 0.0052627325, 0.026336517, 0.018355045,\n",
       "   0.019157063, 0.021789204, -0.04161004, 0.04955243, 0.0072652586,\n",
       "   0.038647998, -0.027222885, 0.022435281, -0.022784805, -0.030534972,\n",
       "   -0.039380193, 0.046266783, -0.033573795, 0.03693079, -0.030576289,\n",
       "   0.0020003207, -0.009075273, -0.040805876, -0.013585746, -0.019157385,\n",
       "   -0.040608726, 0.012401916, 0.014986265, -0.011232041, -0.02965547,\n",
       "   -0.021696806]]                                                       ]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch = input_block(batch)\n",
    "input_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a70fe",
   "metadata": {},
   "source": [
    "Let us now construct the remaining layers of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78b21c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'hashed_url_list'\n",
    "\n",
    "dmodel=128\n",
    "mlp_block = mm.MLPBlock(\n",
    "                [128,dmodel],\n",
    "                activation='relu',\n",
    "                no_activation_last_layer=True,\n",
    "            )\n",
    "transformer_block = mm.XLNetBlock(d_model=dmodel, n_head=4, n_layer=2)\n",
    "model = mm.Model(\n",
    "    input_block,\n",
    "    mlp_block,\n",
    "    transformer_block,\n",
    "    mm.CategoricalOutput(\n",
    "        train_processed.schema.select_by_name(target),\n",
    "        default_loss=\"categorical_crossentropy\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b54d19",
   "metadata": {},
   "source": [
    "And let us train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbb03f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:47:44.859610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['model/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['model/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:47:55.766700: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model/xl_net_block/sequential_block_7/replace_masked_embeddings/RaggedWhere/Assert/AssertGuard/branch_executed/_95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 12s 19ms/step - loss: 6.6471 - recall_at_10: 0.0339 - mrr_at_10: 0.0123 - ndcg_at_10: 0.0171 - map_at_10: 0.0123 - precision_at_10: 0.0034 - regularization_loss: 0.0000e+00 - loss_batch: 6.6151\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.6437 - recall_at_10: 0.0210 - mrr_at_10: 0.0062 - ndcg_at_10: 0.0097 - map_at_10: 0.0062 - precision_at_10: 0.0021 - regularization_loss: 0.0000e+00 - loss_batch: 6.5486\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.6829 - recall_at_10: 0.0297 - mrr_at_10: 0.0096 - ndcg_at_10: 0.0142 - map_at_10: 0.0096 - precision_at_10: 0.0030 - regularization_loss: 0.0000e+00 - loss_batch: 6.6923\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.6273 - recall_at_10: 0.0196 - mrr_at_10: 0.0030 - ndcg_at_10: 0.0067 - map_at_10: 0.0030 - precision_at_10: 0.0020 - regularization_loss: 0.0000e+00 - loss_batch: 6.4448             \n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.6547 - recall_at_10: 0.0359 - mrr_at_10: 0.0107 - ndcg_at_10: 0.0164 - map_at_10: 0.0107 - precision_at_10: 0.0036 - regularization_loss: 0.0000e+00 - loss_batch: 6.4384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56381be790>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(run_eagerly=False, optimizer='adam', loss=\"categorical_crossentropy\")\n",
    "model.fit(loader, batch_size=64, epochs=5, pre=mm.SequenceMaskRandom(schema=loader.output_schema, target=target, masking_prob=0.3, transformer=transformer_block))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56256d5c",
   "metadata": {},
   "source": [
    "Let's save the model so that we can use it for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47b9b571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, sequence_mask_random_layer_call_fn, sequence_mask_random_layer_call_and_return_conditional_losses, prepare_list_features_1_layer_call_fn while saving (showing 5 of 110). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model/assets\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/models/tf/utils/tf_utils.py:101: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config[key] = tf.keras.utils.serialize_keras_object(maybe_value)\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py:288: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config[i] = tf.keras.utils.serialize_keras_object(layer)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return serialization.serialize_keras_object(obj)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.save('trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ab17b",
   "metadata": {},
   "source": [
    "## Serving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18f19033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.systems.dag.ops.tensorflow import PredictTensorflow\n",
    "from merlin.systems.dag.ensemble import Ensemble\n",
    "from merlin.systems.dag.ops.workflow import TransformWorkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa8ee6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_op = EmbeddingOperator(\n",
    "    embeddings[:, 1:].astype(np.float32),\n",
    "    id_lookup_table=embeddings[:, 0].astype(int),\n",
    "    lookup_key=\"product_sku_hash_list\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "385aba04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n",
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, sequence_mask_random_layer_call_fn, sequence_mask_random_layer_call_and_return_conditional_losses, prepare_list_features_1_layer_call_fn while saving (showing 5 of 110). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppt201_31/model.savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppt201_31/model.savedmodel/assets\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/models/tf/utils/tf_utils.py:101: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config[key] = tf.keras.utils.serialize_keras_object(maybe_value)\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py:288: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config[i] = tf.keras.utils.serialize_keras_object(layer)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return serialization.serialize_keras_object(obj)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "inference_operators = wf.input_schema.column_names >> TransformWorkflow(wf) >> emb_op >> PredictTensorflow(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41fc3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /workspace/data/ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c14a25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(\n",
      "  (_feature_shapes): Dict(\n",
      "    (product_sku_hash_list): TensorShape([10, None, 1])\n",
      "    (event_type_list): TensorShape([10, None, 1])\n",
      "    (product_action_list): TensorShape([10, None, 1])\n",
      "    (hashed_url_list): TensorShape([10, None, 1])\n",
      "    (embeddings): TensorShape([10, None, 50])\n",
      "  )\n",
      "  (_feature_dtypes): Dict(\n",
      "    (product_sku_hash_list): tf.int64\n",
      "    (event_type_list): tf.int64\n",
      "    (product_action_list): tf.int64\n",
      "    (hashed_url_list): tf.int64\n",
      "    (embeddings): tf.float32\n",
      "  )\n",
      "), because it is not built.\n",
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, sequence_mask_random_layer_call_fn, sequence_mask_random_layer_call_and_return_conditional_losses, prepare_list_features_1_layer_call_fn while saving (showing 5 of 110). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/data/ensemble/1_predicttensorflowtriton/1/model.savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/data/ensemble/1_predicttensorflowtriton/1/model.savedmodel/assets\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/models/tf/utils/tf_utils.py:101: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config[key] = tf.keras.utils.serialize_keras_object(maybe_value)\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py:288: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config[i] = tf.keras.utils.serialize_keras_object(layer)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return serialization.serialize_keras_object(obj)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "ensemble = Ensemble(inference_operators, wf.input_schema)\n",
    "ensemble.export(os.path.join(OUTPUT_DATA_DIR, 'ensemble'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb008215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the triton server\n",
    "# tritonserver --model-repository=/workspace/data/ensemble\n",
    "# the error should appear in the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f94754b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0613 23:45:59.553813 669 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7ff6a6000000' with size 268435456\n",
      "I0613 23:45:59.554145 669 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "I0613 23:45:59.556339 669 model_lifecycle.cc:459] loading: 0_transformworkflowtriton:1\n",
      "I0613 23:45:59.556362 669 model_lifecycle.cc:459] loading: 1_predicttensorflowtriton:1\n",
      "I0613 23:45:59.556377 669 model_lifecycle.cc:459] loading: executor_model:1\n",
      "I0613 23:45:59.754050 669 tensorflow.cc:2570] TRITONBACKEND_Initialize: tensorflow\n",
      "I0613 23:45:59.754069 669 tensorflow.cc:2580] Triton TRITONBACKEND API version: 1.11\n",
      "I0613 23:45:59.754075 669 tensorflow.cc:2586] 'tensorflow' TRITONBACKEND API version: 1.11\n",
      "I0613 23:45:59.754079 669 tensorflow.cc:2610] backend configuration:\n",
      "{\"cmdline\":{\"auto-complete-config\":\"true\",\"min-compute-capability\":\"6.000000\",\"backend-directory\":\"/opt/tritonserver/backends\",\"default-max-batch-size\":\"4\"}}\n",
      "2023-06-13 23:46:01.065613: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2023-06-13 23:46:02.580974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:02.581381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:02.581556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I0613 23:46:04.607044 669 tensorflow.cc:2676] TRITONBACKEND_ModelInitialize: 1_predicttensorflowtriton (version 1)\n",
      "2023-06-13 23:46:04.607495: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /workspace/data/ensemble/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-06-13 23:46:04.647299: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-06-13 23:46:04.647348: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /workspace/data/ensemble/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-06-13 23:46:04.647462: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 23:46:04.648390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:04.670197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:04.670384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:04.680390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:04.680553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:04.680682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:04.680812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45958 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "2023-06-13 23:46:04.794156: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-06-13 23:46:04.824708: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-06-13 23:46:05.084523: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /workspace/data/ensemble/1_predicttensorflowtriton/1/model.savedmodel\n",
      "2023-06-13 23:46:05.246052: I tensorflow/cc/saved_model/loader.cc:325] SavedModel load for tags { serve }; Status: success: OK. Took 638565 microseconds.\n",
      "I0613 23:46:05.300410 669 tensorflow.cc:2702] TRITONBACKEND_ModelFinalize: delete model state\n",
      "E0613 23:46:05.300452 669 model_lifecycle.cc:597] failed to load '1_predicttensorflowtriton' version 1: Internal: unable to autofill for '1_predicttensorflowtriton', model tensor configurations are contradicting each other in terms of whether batching is supported\n",
      "2023-06-13 23:46:06.570797: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2023-06-13 23:46:08.074113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:08.074469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:08.074624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I0613 23:46:10.145653 669 python_be.cc:1858] TRITONBACKEND_ModelInstanceInitialize: 0_transformworkflowtriton_0 (GPU device 0)\n",
      "2023-06-13 23:46:11.435365: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2023-06-13 23:46:12.938886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:12.939242: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:12.939397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0613 23:46:13.372700 669 python_be.cc:1858] TRITONBACKEND_ModelInstanceInitialize: executor_model_0 (GPU device 0)\n",
      "I0613 23:46:13.372842 669 model_lifecycle.cc:694] successfully loaded '0_transformworkflowtriton' version 1\n",
      "2023-06-13 23:46:14.649261: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2023-06-13 23:46:16.146938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:16.147310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-13 23:46:16.147459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I0613 23:46:16.597567 669 model_lifecycle.cc:694] successfully loaded 'executor_model' version 1\n",
      "I0613 23:46:16.597643 669 server.cc:563] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0613 23:46:16.597692 669 server.cc:590] \n",
      "+------------+-------------------------------+-------------------------------+\n",
      "| Backend    | Path                          | Config                        |\n",
      "+------------+-------------------------------+-------------------------------+\n",
      "| python     | /opt/tritonserver/backends/py | {\"cmdline\":{\"auto-complete-co |\n",
      "|            | thon/libtriton_python.so      | nfig\":\"true\",\"min-compute-cap |\n",
      "|            |                               | ability\":\"6.000000\",\"backend- |\n",
      "|            |                               | directory\":\"/opt/tritonserver |\n",
      "|            |                               | /backends\",\"default-max-batch |\n",
      "|            |                               | -size\":\"4\"}}                  |\n",
      "|            |                               |                               |\n",
      "| tensorflow | /opt/tritonserver/backends/te | {\"cmdline\":{\"auto-complete-co |\n",
      "|            | nsorflow2/libtriton_tensorflo | nfig\":\"true\",\"min-compute-cap |\n",
      "|            | w2.so                         | ability\":\"6.000000\",\"backend- |\n",
      "|            |                               | directory\":\"/opt/tritonserver |\n",
      "|            |                               | /backends\",\"default-max-batch |\n",
      "|            |                               | -size\":\"4\"}}                  |\n",
      "|            |                               |                               |\n",
      "|            |                               |                               |\n",
      "+------------+-------------------------------+-------------------------------+\n",
      "\n",
      "I0613 23:46:16.597737 669 server.cc:633] \n",
      "+---------------------------+---------+---------------------------------------+\n",
      "| Model                     | Version | Status                                |\n",
      "+---------------------------+---------+---------------------------------------+\n",
      "| 0_transformworkflowtriton | 1       | READY                                 |\n",
      "| 1_predicttensorflowtriton | 1       | UNAVAILABLE: Internal: unable to auto |\n",
      "|                           |         | fill for '1_predicttensorflowtriton', |\n",
      "|                           |         |  model tensor configurations are cont |\n",
      "|                           |         | radicting each other in terms of whet |\n",
      "|                           |         | her batching is supported             |\n",
      "| executor_model            | 1       | READY                                 |\n",
      "+---------------------------+---------+---------------------------------------+\n",
      "\n",
      "I0613 23:46:16.624342 669 metrics.cc:864] Collecting metrics for GPU 0: Quadro RTX 8000\n",
      "I0613 23:46:16.624524 669 metrics.cc:757] Collecting CPU metrics\n",
      "I0613 23:46:16.624639 669 tritonserver.cc:2264] \n",
      "+----------------------------------+------------------------------------------+\n",
      "| Option                           | Value                                    |\n",
      "+----------------------------------+------------------------------------------+\n",
      "| server_id                        | triton                                   |\n",
      "| server_version                   | 2.31.0                                   |\n",
      "| server_extensions                | classification sequence model_repository |\n",
      "|                                  |  model_repository(unload_dependents) sch |\n",
      "|                                  | edule_policy model_configuration system_ |\n",
      "|                                  | shared_memory cuda_shared_memory binary_ |\n",
      "|                                  | tensor_data statistics trace logging     |\n",
      "| model_repository_path[0]         | /workspace/data/ensemble                 |\n",
      "| model_control_mode               | MODE_NONE                                |\n",
      "| strict_model_config              | 0                                        |\n",
      "| rate_limit                       | OFF                                      |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                 |\n",
      "| response_cache_byte_size         | 0                                        |\n",
      "| min_supported_compute_capability | 6.0                                      |\n",
      "| strict_readiness                 | 1                                        |\n",
      "| exit_timeout                     | 30                                       |\n",
      "+----------------------------------+------------------------------------------+\n",
      "\n",
      "I0613 23:46:16.624658 669 server.cc:264] Waiting for in-flight requests to complete.\n",
      "I0613 23:46:16.624663 669 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences\n",
      "I0613 23:46:16.624708 669 server.cc:295] All models are stopped, unloading models\n",
      "I0613 23:46:16.624713 669 server.cc:302] Timeout 30: Found 2 live models and 0 in-flight non-inference requests\n",
      "I0613 23:46:17.624788 669 server.cc:302] Timeout 29: Found 2 live models and 0 in-flight non-inference requests\n",
      "I0613 23:46:18.249977 669 model_lifecycle.cc:579] successfully unloaded 'executor_model' version 1\n",
      "I0613 23:46:18.315118 669 model_lifecycle.cc:579] successfully unloaded '0_transformworkflowtriton' version 1\n",
      "I0613 23:46:18.624868 669 server.cc:302] Timeout 28: Found 0 live models and 0 in-flight non-inference requests\n",
      "error: creating server: Internal - failed to load all models\n"
     ]
    }
   ],
   "source": [
    "!tritonserver --model-repository=/workspace/data/ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a861f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154fc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324fca85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb3c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a126e94b",
   "metadata": {},
   "source": [
    "Let's attempt prediction on a couple of rows from our train set, just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.systems.triton import convert_df_to_triton_input\n",
    "\n",
    "inputs = convert_df_to_triton_input(wf.input_schema, train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f71a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "\n",
    "with grpcclient.InferenceServerClient(\"localhost:8001\") as client:\n",
    "    response = client.infer('executor_model', inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a01fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9594131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd9dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee8d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    embeddings = np.load(npy_path)\n",
    "    # second workflow that categorifies the embedding table data\n",
    "    df = make_df({\"string_id\": np.random.choice(string_ids, 30)})\n",
    "    graph2 = [\"string_id\"] >> cat_op\n",
    "    train_res = Workflow(graph2).transform(Dataset(df, cpu=(cpu is not None)))\n",
    "\n",
    "    data_loader = Loader(\n",
    "        train_res,\n",
    "        batch_size=1,\n",
    "        transforms=[\n",
    "            EmbeddingOperator(\n",
    "                embeddings[:, 1:],\n",
    "                id_lookup_table=embeddings[:, 0].astype(int),\n",
    "                lookup_key=\"string_id\",\n",
    "            )\n",
    "        ],\n",
    "        shuffle=False,\n",
    "        device=cpu,\n",
    "    )\n",
    "    origin_df = train_res.to_ddf().merge(emb_res.to_ddf(), on=\"string_id\", how=\"left\").compute()\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        batch\n",
    "        b_df = batch[0].to_df()\n",
    "        org_df = origin_df.iloc[idx]\n",
    "        if not cpu:\n",
    "            assert (b_df[\"string_id\"].to_numpy() == org_df[\"string_id\"].to_numpy()).all()\n",
    "            assert (b_df[\"embeddings\"].list.leaves == org_df[\"embeddings\"].list.leaves).all()\n",
    "        else:\n",
    "            assert (b_df[\"string_id\"].values == org_df[\"string_id\"]).all()\n",
    "            assert b_df[\"embeddings\"].values[0] == org_df[\"embeddings\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2918edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ef0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame(data={'id': [1,2,3], 'val': [0, np.nan, 10], 'another_col': ['a', 'b', 'c']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe60eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.val[df.val.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.val[~df.val.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e844c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = nvt.Dataset(df)\n",
    "\n",
    "out = ['val'] >> nvt.ops.Filter(f=lambda col: ~col.isna())\n",
    "\n",
    "wf = nvt.Workflow(out)\n",
    "wf.fit_transform(ds).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1824ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ['id', 'val'] >> nvt.ops.Filter(f=lambda df: ~df['val'].isna())\n",
    "\n",
    "wf = nvt.Workflow(out)\n",
    "wf.fit_transform(ds).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ['id', 'val'] >> nvt.ops.Filter(f=lambda df: ~df['val'].isna())\n",
    "\n",
    "wf = nvt.Workflow(out + ['another_col'])\n",
    "wf.fit_transform(ds).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus.to_npy('embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28983810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73636038",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ['product_sku_hash', 'category_hash'] >> nvt.ops.Categorify() >> nvt.ops.TagAsItemID()\n",
    "out += ['description_vector'] >> nvt.ops.TagAsItemFeatures()\n",
    "out += ['price_bucket'] >> nvt.ops.NormalizeMinMax()\n",
    "\n",
    "wf = nvt.Workflow(out)\n",
    "skus = wf.fit_transform(skus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ef176",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aacf74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116220a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f4e4a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame(data={'id': [1,2,3], 'label': [1,2,1]})\n",
    "ds = nvt.Dataset(df)\n",
    "\n",
    "out = ['label'] >> nvt.ops.AddMetadata(Tags.TARGET)\n",
    "\n",
    "wf = nvt.Workflow(out + ['id'])\n",
    "\n",
    "ds_out = wf.fit_transform(ds)\n",
    "\n",
    "loader = Loader(\n",
    "    ds_out,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "loader.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771ea52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3049254",
   "metadata": {},
   "source": [
    "To use synthetically generated data, uncomment the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64305ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /workspace\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: merlin-core>=23.4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (23.5.0+13.gd6720139)\n",
      "Requirement already satisfied: merlin-dataloader>=23.4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (23.5.0+2.g2e05300)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.13.1)\n",
      "Requirement already satisfied: npy-append-array in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (0.9.16)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.22.4)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (4.65.0)\n",
      "Requirement already satisfied: dask>=2022.11.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2023.1.1)\n",
      "Requirement already satisfied: distributed>=2022.11.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2023.1.1)\n",
      "Requirement already satisfied: fsspec>=2022.7.1 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2023.6.0)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (0.57.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (9.0.0)\n",
      "Requirement already satisfied: pynvml<11.5,>=11.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (11.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (23.1)\n",
      "Requirement already satisfied: pandas<1.6.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.5.2)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (3.20.3)\n",
      "Requirement already satisfied: dask-cuda>=22.12.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (22.12.0)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.59.0)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (0.4.4)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (6.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.4.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (8.1.3)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (0.12.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.0.5)\n",
      "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (5.9.5)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.7.0)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /usr/lib/python3/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.25.8)\n",
      "Requirement already satisfied: zict>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (3.0.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2.4.0)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.0.0)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (3.1.2)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (6.3.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (6.6.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (0.40.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2.8.2)\n",
      "Requirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (6.0.4)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (4.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10.3->distributed>=2022.11.1->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.54->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (3.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0dev0,>=1.2.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (1.14.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (4.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=23.4.0->merlin-models==23.5.dev0+63.g6d83a8b1.dirty) (6.0.1)\n",
      "Building wheels for collected packages: merlin-models\n",
      "  Building wheel for merlin-models (PEP 517): started\n",
      "  Building wheel for merlin-models (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-models: filename=merlin_models-23.5.dev0+63.g6d83a8b1.dirty-py3-none-any.whl size=384113 sha256=743286edc1e20e76705ea7980a6cbe6f45accd6b753f72a0815da260a3102641\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-myac_4jv/wheels/59/14/70/d94958f41745fe226f3bc60bb3cabbbc8a98e4d6679e91038a\n",
      "Successfully built merlin-models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: transformers4rec 23.5.0+9.gf4946bfa requires torchmetrics>=0.10.0, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: merlin-models\n",
      "  Attempting uninstall: merlin-models\n",
      "    Found existing installation: merlin-models 23.5.dev0+57.gad9fa2bb.dirty\n",
      "    Uninstalling merlin-models-23.5.dev0+57.gad9fa2bb.dirty:\n",
      "      Successfully uninstalled merlin-models-23.5.dev0+57.gad9fa2bb.dirty\n",
      "Successfully installed merlin-models-23.5.dev0+63.g6d83a8b1.dirty\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /workspace && pip install . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14a4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.datasets.synthetic import KNOWN_DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595ef5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e-commerce': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/small'),\n",
       " 'e-commerce-large': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/large'),\n",
       " 'music-streaming': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/music_streaming'),\n",
       " 'social': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/social'),\n",
       " 'testing': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/testing'),\n",
       " 'sequence-testing': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/testing/sequence_testing'),\n",
       " 'movielens-25m': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/movielens/25m'),\n",
       " 'movielens-1m': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/movielens/1m'),\n",
       " 'movielens-1m-raw-ratings': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/movielens/1m-raw/ratings'),\n",
       " 'movielens-100k': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/movielens/100k'),\n",
       " 'tenrec-video': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/entertainment/tenrec_video'),\n",
       " 'criteo': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/advertising/criteo/transformed'),\n",
       " 'aliccp': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/aliccp/transformed'),\n",
       " 'aliccp-raw': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/aliccp/raw'),\n",
       " 'dressipi2022-preprocessed': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/dressipi/preprocessed'),\n",
       " 'booking.com': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/booking/transformed'),\n",
       " 'booking.com-raw': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/booking/raw'),\n",
       " 'transactions': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/transactions'),\n",
       " 'sigir-browsing': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/sigir/browsing_train'),\n",
       " 'sigir-sku': PosixPath('/usr/local/lib/python3.8/dist-packages/merlin/datasets/ecommerce/sigir/sku_information')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNOWN_DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895e9266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>hashed_url</th>\n",
       "      <th>server_timestamp_epoch_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>399</td>\n",
       "      <td>949</td>\n",
       "      <td>0.578108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>505</td>\n",
       "      <td>818</td>\n",
       "      <td>0.471705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>423</td>\n",
       "      <td>771</td>\n",
       "      <td>0.613716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>791</td>\n",
       "      <td>49</td>\n",
       "      <td>0.503518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>424</td>\n",
       "      <td>166</td>\n",
       "      <td>0.864198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id_hash  event_type  product_action  product_sku_hash  hashed_url  \\\n",
       "0               50           0               1               399         949   \n",
       "1                8           0               3               505         818   \n",
       "2               16           1               0               423         771   \n",
       "3               87           1               2               791          49   \n",
       "4              378           1               3               424         166   \n",
       "\n",
       "   server_timestamp_epoch_ms  \n",
       "0                   0.578108  \n",
       "1                   0.471705  \n",
       "2                   0.613716  \n",
       "3                   0.503518  \n",
       "4                   0.864198  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d09929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>description_vector</th>\n",
       "      <th>category_hash</th>\n",
       "      <th>price_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>[0.28320169822835645, 0.28876255653408484, 0.3...</td>\n",
       "      <td>114</td>\n",
       "      <td>0.148844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>[0.0498882587601161, 0.4050611778162572, 0.489...</td>\n",
       "      <td>78</td>\n",
       "      <td>0.983131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>[-0.20383781352758598, 0.2821339201063496, -0....</td>\n",
       "      <td>78</td>\n",
       "      <td>0.268082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>[0.08096254937074815, 0.5582722991824396, 0.22...</td>\n",
       "      <td>156</td>\n",
       "      <td>0.310764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>[-0.29878517778423397, -0.3313343019075635, -0...</td>\n",
       "      <td>121</td>\n",
       "      <td>0.097739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_sku_hash                                 description_vector  \\\n",
       "0                35  [0.28320169822835645, 0.28876255653408484, 0.3...   \n",
       "1                11  [0.0498882587601161, 0.4050611778162572, 0.489...   \n",
       "2                12  [-0.20383781352758598, 0.2821339201063496, -0....   \n",
       "3                14  [0.08096254937074815, 0.5582722991824396, 0.22...   \n",
       "4                49  [-0.29878517778423397, -0.3313343019075635, -0...   \n",
       "\n",
       "   category_hash  price_bucket  \n",
       "0            114      0.148844  \n",
       "1             78      0.983131  \n",
       "2             78      0.268082  \n",
       "3            156      0.310764  \n",
       "4            121      0.097739  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
