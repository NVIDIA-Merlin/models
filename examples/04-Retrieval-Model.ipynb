{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5622b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e00f62",
   "metadata": {},
   "source": [
    "## Building Retrieval Models easily with Merlin Models\n",
    "\n",
    "In large scale recommender systems pipelines, the size of the item catalog (number of unique items) might be in the order of millions. At such scale, a typical setup is having two-stage pipeline, where a faster candidate retrieval model quickly extracts thousands of relevant items and a then a more powerful ranking model (i.e. with more features and more powerful architecture) ranks the top-k items that are going to be displayed to the user. For ML-based candidate retrieval model, as it needs to quickly score millions of items for a given user, a popular choices are models that can produce recommendation scores by just computing the dot product the user embeddings and item embeddings. Popular choices of such models are **Matrix Factorization**, which learns low-rank user and item embeddings, and the **Two-Tower architecture**, which is a neural network with two MLP towers where both user and item features are fed to generate user and item embeddings in the output. Such models can be efficiently served by indexing the trained item embeddings into an **Approximate Nearest Neighbors (ANN)** engine and during inference scoring user embeddings over all indexed item embeddings within the engine.In this notebook we will build a Two-Tower architecture for item retrieval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e0b03",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n",
    "\n",
    "In this notebook, we are building a Two-Tower model for Item Retrieval task using the Ali-CCP: Alibaba Click and Conversion Prediction dataset. To download the training and test datasets visit Ali-CCP: Alibaba Click and Conversion Prediction at [tianchi.aliyun.com](https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1). We have curated the raw dataset via using this [script]() and generated the parquet files that we will use for this example.\n",
    "\n",
    "### Learning objectives\n",
    "- Preparing the data with NVTabular\n",
    "- Training and evaluating Two-Tower model with Merlin Models\n",
    "- Perform prediction for a given user query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb6ef0",
   "metadata": {},
   "source": [
    "### Feature Engineering with NVTabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e8e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 19:32:04.557591: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-22 19:32:05.948990: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-03-22 19:32:05.949120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16254 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "import cudf\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "from example_utils import workflow_fit_transform\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.schema import Schema\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "import merlin.models.tf.dataset as tf_dataloader\n",
    "\n",
    "from merlin.io.dataset import Dataset\n",
    "from merlin.schema.io.tensorflow_metadata import TensorflowMetadata\n",
    "from merlin.models.tf.blocks.core.aggregation import CosineSimilarity\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184199c9",
   "metadata": {},
   "source": [
    "First, we define our input and output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af46dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/workspace/data/train/*.parquet'\n",
    "test_path = '/workspace/data/test/*.parquet'\n",
    "output_path = '/workspace/retrieval/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20955cbf",
   "metadata": {},
   "source": [
    "ETL Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d896d5",
   "metadata": {},
   "source": [
    "We select only positive interaction rows therefore we remove rows where `click==0` from the dataset with `Filter()` op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326d0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = [\"user_id\"] >> Categorify() >> AddMetadata(tags=[Tags.USER_ID, Tags.USER])\n",
    "item_id = [\"item_id\"] >> Categorify() >> AddMetadata(tags=[Tags.ITEM_ID, Tags.ITEM]) \n",
    "\n",
    "item_features = [\"item_category\", \"item_shop\", \"item_brand\"] \\\n",
    "     >> AddMetadata(tags=[Tags.ITEM]) >> nvt.ops.Categorify()\n",
    "\n",
    "user_features = ['user_shops', 'user_profile', 'user_group', \n",
    "       'user_gender', 'user_age', 'user_consumption_2', 'user_is_occupied',\n",
    "       'user_geography', 'user_intentions', 'user_brands', 'user_categories'] \\\n",
    "    >> AddMetadata(tags=[Tags.USER]) >> nvt.ops.Categorify()\n",
    "\n",
    "inputs = user_id + item_id + item_features + user_features + ['click'] \n",
    "\n",
    "outputs = inputs >> Filter(f=lambda df: df[\"click\"] == 1)\n",
    "\n",
    "workflow_fit_transform(outputs, train_path, test_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b09540",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building Two-Tower Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13afd72b",
   "metadata": {},
   "source": [
    "We will use Two-Tower Model for Item retrieval task. Real-world large scale recommender systems have hundreds of millions of items (products) and users. It is Thus, these systems are often composed of two stages: candidate generation (retrieval) and ranking (scoring the retrieved items). You can read more about two stage Recommender Systems [here](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf). In this example, we're going to focus on the retrieval stage.\n",
    "\n",
    "A Two-Tower Model consists of item (candidate) and user (query) encoder towers. With two towers, the model can learn representations (embeddings) for queries and candidates separately. \n",
    "\n",
    "<img src=\"./images/TwoTower.png\"  width=\"30%\">\n",
    "\n",
    "Image Adapted from: [Off-policy Learning in Two-stage Recommender Systems](https://dl.acm.org/doi/abs/10.1145/3366423.3380130)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144428ef",
   "metadata": {},
   "source": [
    "We use the `schema` object to define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3854450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = TensorflowMetadata.from_proto_text_file('/workspace/retrieval/processed/train/').to_merlin_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd5aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = schema.select_by_tag([Tags.ITEM_ID, Tags.USER_ID, Tags.ITEM, Tags.USER])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b1a399",
   "metadata": {},
   "source": [
    "We expect the label names to be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca874e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = schema.select_by_tag(Tags.TARGET).column_names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0aa68d",
   "metadata": {},
   "source": [
    "### Negative sampling\n",
    "Many datasets for recommender systems contains implicit feedback, with logs of user interactions like clicks, add-to-cart, purchases, music listening events, rather than explicit ratings that reflects user preferences over items. To be able to learn from implicit feedback, we use the general (and naive) assumption that the interacted items are more relevant for the user than the non-interacted ones.\n",
    "In Merlin Models we provide some scalable negative sampling algorithms for the Item Retrieval Task. In particular, we use in this example the in-batch sampling algorithm which uses the items interacted by other users as negatives within the same mini-batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6d61c",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ccfc9e",
   "metadata": {},
   "source": [
    "Now, let's build our Two-Tower model. In a nutshell, we aggregate all user features to feed in user tower and feed the item features to the item tower. Then we compute the positive score by multiplying the user embedding with the item embedding and sample negative items (read more about negative sampling [here](https://openreview.net/pdf?id=824xC-SgWgU) and [here](https://medium.com/mlearning-ai/overview-negative-sampling-on-recommendation-systems-230a051c6cd7)), whose item embeddings are also multiplied by the user embedding. Then we apply the loss function on top of the positive and negative scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294a979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mm.TwoTowerModel(\n",
    "    schema,\n",
    "    query_tower=mm.MLPBlock([128, 64], no_activation_last_layer=True),        \n",
    "    loss=\"categorical_crossentropy\",  \n",
    "    samplers=[mm.InBatchSampler()],\n",
    "    embedding_options = mm.EmbeddingOptions(infer_embedding_sizes=True),\n",
    "    metrics=[mm.RecallAt(10), mm.NDCGAt(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9106f11",
   "metadata": {},
   "source": [
    "Let's explain the parameters in the TwoTowerModel():\n",
    "- no_activation_last_layer: when set True, no activation is used for top hidden layer. Learn more [here](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/b9f4e78a8830fe5afcf2f0452862fb3c0d6584ea.pdf).\n",
    "- infer_embedding_sizes: when set True, automatically defines the embedding dimension from the feature cardinality in the schema\n",
    "\n",
    "**Metrics:**\n",
    "\n",
    "The following information retrieval metrics are used to compute the Top-10 accuracy of recommendation lists containing all items:\n",
    "\n",
    "- **Normalized Discounted Cumulative Gain (NDCG@10)**: NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the top-k items.\n",
    "\n",
    "- **Recall@10**: Also known as HitRate@n when there is only one relevant item in the recommendation list. Recall just verifies whether the relevant item is among the top-n items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e98fa",
   "metadata": {},
   "source": [
    "We need to initialize the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd28a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4096\n",
    "\n",
    "train = Dataset(os.path.join(output_path + '/train/*.parquet'), part_size=\"500MB\")\n",
    "valid = Dataset(os.path.join(output_path + '/test/*.parquet'), part_size=\"500MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80ba4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 19:32:07.059318: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f22e85c56a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f22e85c56a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - ETA: 0s - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3208 - regularization_loss: 0.0000e+00 - total_loss: 8.3208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_layer_call_fn, block_context_layer_call_and_return_conditional_losses, sequential_block_6_layer_call_fn, sequential_block_6_layer_call_and_return_conditional_losses, l2_norm_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz_ytut1y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz_ytut1y/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "2022-03-22 19:32:42.522707: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: cond/then/_0/cond/cond/branch_executed/_184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 41s 84ms/step - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3194 - regularization_loss: 0.0000e+00 - total_loss: 8.3194 - val_recall_at_10: 0.0025 - val_ndcg_10: 0.0011 - val_loss: 7.4185 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4185\n",
      "Epoch 2/5\n",
      "382/384 [============================>.] - ETA: 0s - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3216 - regularization_loss: 0.0000e+00 - total_loss: 8.3216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_layer_call_fn, block_context_layer_call_and_return_conditional_losses, sequential_block_6_layer_call_fn, sequential_block_6_layer_call_and_return_conditional_losses, l2_norm_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9u6rutdm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9u6rutdm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 30s 77ms/step - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3186 - regularization_loss: 0.0000e+00 - total_loss: 8.3186 - val_recall_at_10: 0.0025 - val_ndcg_10: 0.0011 - val_loss: 7.4180 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4180\n",
      "Epoch 3/5\n",
      "382/384 [============================>.] - ETA: 0s - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3211 - regularization_loss: 0.0000e+00 - total_loss: 8.3211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_layer_call_fn, block_context_layer_call_and_return_conditional_losses, sequential_block_6_layer_call_fn, sequential_block_6_layer_call_and_return_conditional_losses, l2_norm_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp40ru6ol3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp40ru6ol3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 30s 77ms/step - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3181 - regularization_loss: 0.0000e+00 - total_loss: 8.3181 - val_recall_at_10: 0.0025 - val_ndcg_10: 0.0011 - val_loss: 7.4176 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4176\n",
      "Epoch 4/5\n",
      "382/384 [============================>.] - ETA: 0s - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3206 - regularization_loss: 0.0000e+00 - total_loss: 8.3206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_layer_call_fn, block_context_layer_call_and_return_conditional_losses, sequential_block_6_layer_call_fn, sequential_block_6_layer_call_and_return_conditional_losses, l2_norm_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp87k6tcun/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp87k6tcun/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 29s 76ms/step - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3176 - regularization_loss: 0.0000e+00 - total_loss: 8.3176 - val_recall_at_10: 0.0025 - val_ndcg_10: 0.0011 - val_loss: 7.4173 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4173\n",
      "Epoch 5/5\n",
      "383/384 [============================>.] - ETA: 0s - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3201 - regularization_loss: 0.0000e+00 - total_loss: 8.3201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_layer_call_fn, block_context_layer_call_and_return_conditional_losses, sequential_block_6_layer_call_fn, sequential_block_6_layer_call_and_return_conditional_losses, l2_norm_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsqngcedk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsqngcedk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 30s 78ms/step - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3171 - regularization_loss: 0.0000e+00 - total_loss: 8.3171 - val_recall_at_10: 0.0025 - val_ndcg_10: 0.0011 - val_loss: 7.4170 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21644f7190>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_retrieval_candidates_for_evaluation(train)\n",
    "\n",
    "opt = tf.keras.optimizers.Adagrad(learning_rate=0.003)\n",
    "model.compile(optimizer=opt, run_eagerly=False)\n",
    "model.fit(train, validation_data=valid, batch_size=batch_size, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba9b51",
   "metadata": {},
   "source": [
    "In batch sampling is prone to popularity-bias. since different users might have interacted same items. # in the fit method we are only using the negative sampling in each batch and the final score is avg over all the batches. \n",
    "for each batch we aer comparing only the items in the given batch. in the `.evaluate()` we are considering entire item catalog for each positive item. generate the scores for all items and check the position of the positive item in the list of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8cd0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(valid, return_dict=True, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca034c",
   "metadata": {},
   "source": [
    "## Exporting Retrieval Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3c5fc3",
   "metadata": {},
   "source": [
    "#### Save user (query) tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b03c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_layer_call_fn, block_context_layer_call_and_return_conditional_losses, sequential_block_9_layer_call_fn, sequential_block_9_layer_call_and_return_conditional_losses, l2_norm_1_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: query_tower/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: query_tower/assets\n"
     ]
    }
   ],
   "source": [
    "query_tower = model.retrieval_block.query_block()\n",
    "query_tower.save('query_tower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1436618",
   "metadata": {},
   "source": [
    "#### Extract and save user features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "205b62af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from merlin.models.utils.dataset import unique_rows_by_features\n",
    "user_features = unique_rows_by_features(Dataset('/workspace/retrieval/processed/train/*.parquet'), Tags.USER, Tags.USER_ID).compute().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce2c898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_shops</th>\n",
       "      <th>user_profile</th>\n",
       "      <th>user_group</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_consumption_2</th>\n",
       "      <th>user_is_occupied</th>\n",
       "      <th>user_geography</th>\n",
       "      <th>user_intentions</th>\n",
       "      <th>user_brands</th>\n",
       "      <th>user_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315873</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>131</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203115</th>\n",
       "      <td>2</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>4709</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696854</th>\n",
       "      <td>3</td>\n",
       "      <td>1876</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213309</th>\n",
       "      <td>4</td>\n",
       "      <td>534</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  user_shops  user_profile  user_group  user_gender  user_age  \\\n",
       "1970          0           0             1           4            1         3   \n",
       "315873        1         109             0           0            0         0   \n",
       "203115        2         301             1           1            1         1   \n",
       "696854        3        1876            23           7            2         3   \n",
       "213309        4         534             1           2            1         2   \n",
       "\n",
       "        user_consumption_2  user_is_occupied  user_geography  user_intentions  \\\n",
       "1970                     2                 1               0                0   \n",
       "315873                   0                 0               0               69   \n",
       "203115                   1                 1               2               57   \n",
       "696854                   1                 1               1                5   \n",
       "213309                   1                 1               0               40   \n",
       "\n",
       "        user_brands  user_categories  \n",
       "1970              0                0  \n",
       "315873          131                9  \n",
       "203115         4709               57  \n",
       "696854           63                3  \n",
       "213309           22              108  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28438e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214994, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c5edb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features.to_parquet('user_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fd7fa",
   "metadata": {},
   "source": [
    "#### Extract and save item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "415e2b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train path should be the path for the processed parquet files.\n",
    "item_features = unique_rows_by_features(Dataset('/workspace/retrieval/processed/train/*.parquet'), Tags.ITEM, Tags.ITEM_ID).compute().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b43a438a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category</th>\n",
       "      <th>item_shop</th>\n",
       "      <th>item_brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>380</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  item_category  item_shop  item_brand\n",
       "0        0              0          0           0\n",
       "1        1            140        380           6\n",
       "2        2              1          4          33\n",
       "3        3             38         57           0\n",
       "4        4             11         65         138"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a86932ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_features.to_parquet('item_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9f9ed2",
   "metadata": {},
   "source": [
    "#### Extract and save item embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1fe8601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_layer_call_fn, block_context_layer_call_and_return_conditional_losses, sequential_block_6_layer_call_fn, sequential_block_6_layer_call_and_return_conditional_losses, l2_norm_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpuyckfegj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpuyckfegj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "item_embs = model.item_embeddings(Dataset(item_features, schema=schema), batch_size=1024)\n",
    "item_embs_df = item_embs.compute(scheduler=\"synchronous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73898a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category</th>\n",
       "      <th>item_shop</th>\n",
       "      <th>item_brand</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.119417</td>\n",
       "      <td>-0.027896</td>\n",
       "      <td>-0.264912</td>\n",
       "      <td>-0.050182</td>\n",
       "      <td>-0.138162</td>\n",
       "      <td>0.136211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158456</td>\n",
       "      <td>0.168403</td>\n",
       "      <td>-0.096095</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-0.123101</td>\n",
       "      <td>0.128763</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>-0.106285</td>\n",
       "      <td>-0.055848</td>\n",
       "      <td>0.061402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>380</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.294812</td>\n",
       "      <td>-0.008678</td>\n",
       "      <td>0.051245</td>\n",
       "      <td>0.017450</td>\n",
       "      <td>-0.060454</td>\n",
       "      <td>0.161752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306396</td>\n",
       "      <td>-0.135012</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>-0.145180</td>\n",
       "      <td>0.078878</td>\n",
       "      <td>0.081469</td>\n",
       "      <td>-0.087589</td>\n",
       "      <td>-0.113694</td>\n",
       "      <td>-0.059155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.245789</td>\n",
       "      <td>0.050664</td>\n",
       "      <td>0.149792</td>\n",
       "      <td>0.196821</td>\n",
       "      <td>-0.051188</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161846</td>\n",
       "      <td>-0.091704</td>\n",
       "      <td>-0.039100</td>\n",
       "      <td>-0.145625</td>\n",
       "      <td>-0.172513</td>\n",
       "      <td>-0.071293</td>\n",
       "      <td>-0.054982</td>\n",
       "      <td>0.037903</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>-0.066160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.084216</td>\n",
       "      <td>0.141419</td>\n",
       "      <td>0.067517</td>\n",
       "      <td>-0.060590</td>\n",
       "      <td>0.170737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276075</td>\n",
       "      <td>-0.128361</td>\n",
       "      <td>-0.251821</td>\n",
       "      <td>-0.107160</td>\n",
       "      <td>-0.190219</td>\n",
       "      <td>-0.062546</td>\n",
       "      <td>-0.087450</td>\n",
       "      <td>-0.105357</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>-0.012447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>138</td>\n",
       "      <td>-0.192909</td>\n",
       "      <td>0.012221</td>\n",
       "      <td>-0.054791</td>\n",
       "      <td>0.124527</td>\n",
       "      <td>-0.043193</td>\n",
       "      <td>0.071654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122809</td>\n",
       "      <td>-0.177446</td>\n",
       "      <td>-0.115998</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>-0.078979</td>\n",
       "      <td>-0.144547</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>-0.113254</td>\n",
       "      <td>-0.025953</td>\n",
       "      <td>0.129219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568842</th>\n",
       "      <td>568842</td>\n",
       "      <td>390</td>\n",
       "      <td>213734</td>\n",
       "      <td>77789</td>\n",
       "      <td>-0.255753</td>\n",
       "      <td>-0.087150</td>\n",
       "      <td>-0.060789</td>\n",
       "      <td>0.058536</td>\n",
       "      <td>0.070155</td>\n",
       "      <td>0.158219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142069</td>\n",
       "      <td>-0.109075</td>\n",
       "      <td>-0.136190</td>\n",
       "      <td>-0.186605</td>\n",
       "      <td>-0.085247</td>\n",
       "      <td>-0.076334</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>-0.066224</td>\n",
       "      <td>0.081726</td>\n",
       "      <td>0.011914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568843</th>\n",
       "      <td>568843</td>\n",
       "      <td>137</td>\n",
       "      <td>111</td>\n",
       "      <td>161</td>\n",
       "      <td>-0.314179</td>\n",
       "      <td>-0.042740</td>\n",
       "      <td>-0.048638</td>\n",
       "      <td>0.096127</td>\n",
       "      <td>-0.092761</td>\n",
       "      <td>0.216961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137687</td>\n",
       "      <td>-0.045866</td>\n",
       "      <td>-0.066166</td>\n",
       "      <td>0.099646</td>\n",
       "      <td>-0.128875</td>\n",
       "      <td>0.024852</td>\n",
       "      <td>-0.050241</td>\n",
       "      <td>-0.081949</td>\n",
       "      <td>-0.098082</td>\n",
       "      <td>0.123643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568844</th>\n",
       "      <td>568844</td>\n",
       "      <td>543</td>\n",
       "      <td>140774</td>\n",
       "      <td>56005</td>\n",
       "      <td>-0.097131</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>-0.084501</td>\n",
       "      <td>0.101683</td>\n",
       "      <td>-0.216845</td>\n",
       "      <td>-0.027871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108308</td>\n",
       "      <td>-0.185961</td>\n",
       "      <td>-0.104254</td>\n",
       "      <td>-0.100263</td>\n",
       "      <td>-0.199770</td>\n",
       "      <td>0.112065</td>\n",
       "      <td>0.056785</td>\n",
       "      <td>-0.242739</td>\n",
       "      <td>-0.034991</td>\n",
       "      <td>-0.240517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568845</th>\n",
       "      <td>568845</td>\n",
       "      <td>803</td>\n",
       "      <td>142760</td>\n",
       "      <td>17371</td>\n",
       "      <td>-0.268720</td>\n",
       "      <td>-0.156125</td>\n",
       "      <td>-0.052229</td>\n",
       "      <td>0.026334</td>\n",
       "      <td>-0.115524</td>\n",
       "      <td>-0.216717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000883</td>\n",
       "      <td>-0.166568</td>\n",
       "      <td>0.038430</td>\n",
       "      <td>-0.166113</td>\n",
       "      <td>-0.057967</td>\n",
       "      <td>-0.178316</td>\n",
       "      <td>-0.238665</td>\n",
       "      <td>-0.053779</td>\n",
       "      <td>-0.163326</td>\n",
       "      <td>-0.017178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568846</th>\n",
       "      <td>568846</td>\n",
       "      <td>501</td>\n",
       "      <td>139037</td>\n",
       "      <td>422</td>\n",
       "      <td>0.056853</td>\n",
       "      <td>-0.150607</td>\n",
       "      <td>-0.087644</td>\n",
       "      <td>0.063829</td>\n",
       "      <td>-0.224097</td>\n",
       "      <td>0.036432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227783</td>\n",
       "      <td>-0.011818</td>\n",
       "      <td>-0.007256</td>\n",
       "      <td>-0.080987</td>\n",
       "      <td>-0.186516</td>\n",
       "      <td>-0.003505</td>\n",
       "      <td>0.392570</td>\n",
       "      <td>-0.029026</td>\n",
       "      <td>0.033836</td>\n",
       "      <td>0.038271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568847 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  item_category  item_shop  item_brand         0         1  \\\n",
       "0             0              0          0           0 -0.119417 -0.027896   \n",
       "1             1            140        380           6 -0.294812 -0.008678   \n",
       "2             2              1          4          33 -0.245789  0.050664   \n",
       "3             3             38         57           0 -0.049673 -0.084216   \n",
       "4             4             11         65         138 -0.192909  0.012221   \n",
       "...         ...            ...        ...         ...       ...       ...   \n",
       "568842   568842            390     213734       77789 -0.255753 -0.087150   \n",
       "568843   568843            137        111         161 -0.314179 -0.042740   \n",
       "568844   568844            543     140774       56005 -0.097131 -0.001878   \n",
       "568845   568845            803     142760       17371 -0.268720 -0.156125   \n",
       "568846   568846            501     139037         422  0.056853 -0.150607   \n",
       "\n",
       "               2         3         4         5  ...        54        55  \\\n",
       "0      -0.264912 -0.050182 -0.138162  0.136211  ...  0.158456  0.168403   \n",
       "1       0.051245  0.017450 -0.060454  0.161752  ...  0.306396 -0.135012   \n",
       "2       0.149792  0.196821 -0.051188  0.003327  ...  0.161846 -0.091704   \n",
       "3       0.141419  0.067517 -0.060590  0.170737  ...  0.276075 -0.128361   \n",
       "4      -0.054791  0.124527 -0.043193  0.071654  ...  0.122809 -0.177446   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "568842 -0.060789  0.058536  0.070155  0.158219  ...  0.142069 -0.109075   \n",
       "568843 -0.048638  0.096127 -0.092761  0.216961  ...  0.137687 -0.045866   \n",
       "568844 -0.084501  0.101683 -0.216845 -0.027871  ...  0.108308 -0.185961   \n",
       "568845 -0.052229  0.026334 -0.115524 -0.216717  ... -0.000883 -0.166568   \n",
       "568846 -0.087644  0.063829 -0.224097  0.036432  ...  0.227783 -0.011818   \n",
       "\n",
       "              56        57        58        59        60        61        62  \\\n",
       "0      -0.096095 -0.021504 -0.123101  0.128763  0.225422 -0.106285 -0.055848   \n",
       "1       0.022356  0.004448 -0.145180  0.078878  0.081469 -0.087589 -0.113694   \n",
       "2      -0.039100 -0.145625 -0.172513 -0.071293 -0.054982  0.037903  0.058987   \n",
       "3      -0.251821 -0.107160 -0.190219 -0.062546 -0.087450 -0.105357 -0.001375   \n",
       "4      -0.115998  0.020514 -0.078979 -0.144547 -0.003251 -0.113254 -0.025953   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "568842 -0.136190 -0.186605 -0.085247 -0.076334  0.005534 -0.066224  0.081726   \n",
       "568843 -0.066166  0.099646 -0.128875  0.024852 -0.050241 -0.081949 -0.098082   \n",
       "568844 -0.104254 -0.100263 -0.199770  0.112065  0.056785 -0.242739 -0.034991   \n",
       "568845  0.038430 -0.166113 -0.057967 -0.178316 -0.238665 -0.053779 -0.163326   \n",
       "568846 -0.007256 -0.080987 -0.186516 -0.003505  0.392570 -0.029026  0.033836   \n",
       "\n",
       "              63  \n",
       "0       0.061402  \n",
       "1      -0.059155  \n",
       "2      -0.066160  \n",
       "3      -0.012447  \n",
       "4       0.129219  \n",
       "...          ...  \n",
       "568842  0.011914  \n",
       "568843  0.123643  \n",
       "568844 -0.240517  \n",
       "568845 -0.017178  \n",
       "568846  0.038271  \n",
       "\n",
       "[568847 rows x 68 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dabdf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings = item_embs_df.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11716d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.119417</td>\n",
       "      <td>-0.027896</td>\n",
       "      <td>-0.264912</td>\n",
       "      <td>-0.050182</td>\n",
       "      <td>-0.138162</td>\n",
       "      <td>0.136211</td>\n",
       "      <td>-0.169776</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.154044</td>\n",
       "      <td>-0.307413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158456</td>\n",
       "      <td>0.168403</td>\n",
       "      <td>-0.096095</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-0.123101</td>\n",
       "      <td>0.128763</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>-0.106285</td>\n",
       "      <td>-0.055848</td>\n",
       "      <td>0.061402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.294812</td>\n",
       "      <td>-0.008678</td>\n",
       "      <td>0.051245</td>\n",
       "      <td>0.017450</td>\n",
       "      <td>-0.060454</td>\n",
       "      <td>0.161752</td>\n",
       "      <td>-0.037283</td>\n",
       "      <td>0.018863</td>\n",
       "      <td>-0.275601</td>\n",
       "      <td>-0.062120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306396</td>\n",
       "      <td>-0.135012</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>-0.145180</td>\n",
       "      <td>0.078878</td>\n",
       "      <td>0.081469</td>\n",
       "      <td>-0.087589</td>\n",
       "      <td>-0.113694</td>\n",
       "      <td>-0.059155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.245789</td>\n",
       "      <td>0.050664</td>\n",
       "      <td>0.149792</td>\n",
       "      <td>0.196821</td>\n",
       "      <td>-0.051188</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>-0.058045</td>\n",
       "      <td>-0.021776</td>\n",
       "      <td>-0.006233</td>\n",
       "      <td>-0.129631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161846</td>\n",
       "      <td>-0.091704</td>\n",
       "      <td>-0.039100</td>\n",
       "      <td>-0.145625</td>\n",
       "      <td>-0.172513</td>\n",
       "      <td>-0.071293</td>\n",
       "      <td>-0.054982</td>\n",
       "      <td>0.037903</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>-0.066160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.084216</td>\n",
       "      <td>0.141419</td>\n",
       "      <td>0.067517</td>\n",
       "      <td>-0.060590</td>\n",
       "      <td>0.170737</td>\n",
       "      <td>-0.031970</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>-0.148692</td>\n",
       "      <td>-0.155614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276075</td>\n",
       "      <td>-0.128361</td>\n",
       "      <td>-0.251821</td>\n",
       "      <td>-0.107160</td>\n",
       "      <td>-0.190219</td>\n",
       "      <td>-0.062546</td>\n",
       "      <td>-0.087450</td>\n",
       "      <td>-0.105357</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>-0.012447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.192909</td>\n",
       "      <td>0.012221</td>\n",
       "      <td>-0.054791</td>\n",
       "      <td>0.124527</td>\n",
       "      <td>-0.043193</td>\n",
       "      <td>0.071654</td>\n",
       "      <td>-0.098000</td>\n",
       "      <td>-0.130967</td>\n",
       "      <td>-0.186607</td>\n",
       "      <td>0.031632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122809</td>\n",
       "      <td>-0.177446</td>\n",
       "      <td>-0.115998</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>-0.078979</td>\n",
       "      <td>-0.144547</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>-0.113254</td>\n",
       "      <td>-0.025953</td>\n",
       "      <td>0.129219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.119417 -0.027896 -0.264912 -0.050182 -0.138162  0.136211 -0.169776   \n",
       "1 -0.294812 -0.008678  0.051245  0.017450 -0.060454  0.161752 -0.037283   \n",
       "2 -0.245789  0.050664  0.149792  0.196821 -0.051188  0.003327 -0.058045   \n",
       "3 -0.049673 -0.084216  0.141419  0.067517 -0.060590  0.170737 -0.031970   \n",
       "4 -0.192909  0.012221 -0.054791  0.124527 -0.043193  0.071654 -0.098000   \n",
       "\n",
       "          7         8         9  ...        54        55        56        57  \\\n",
       "0 -0.254903 -0.154044 -0.307413  ...  0.158456  0.168403 -0.096095 -0.021504   \n",
       "1  0.018863 -0.275601 -0.062120  ...  0.306396 -0.135012  0.022356  0.004448   \n",
       "2 -0.021776 -0.006233 -0.129631  ...  0.161846 -0.091704 -0.039100 -0.145625   \n",
       "3  0.087300 -0.148692 -0.155614  ...  0.276075 -0.128361 -0.251821 -0.107160   \n",
       "4 -0.130967 -0.186607  0.031632  ...  0.122809 -0.177446 -0.115998  0.020514   \n",
       "\n",
       "         58        59        60        61        62        63  \n",
       "0 -0.123101  0.128763  0.225422 -0.106285 -0.055848  0.061402  \n",
       "1 -0.145180  0.078878  0.081469 -0.087589 -0.113694 -0.059155  \n",
       "2 -0.172513 -0.071293 -0.054982  0.037903  0.058987 -0.066160  \n",
       "3 -0.190219 -0.062546 -0.087450 -0.105357 -0.001375 -0.012447  \n",
       "4 -0.078979 -0.144547 -0.003251 -0.113254 -0.025953  0.129219  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ec0a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings.to_parquet('item_embeddings')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
