{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce524ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea37e72",
   "metadata": {},
   "source": [
    "In this notebook we will use NVIDIA Merlin Models library to build and train two state-of-the-art Deep Learning-based Recommendation models with couple of lines of code:\n",
    "\n",
    "- Deep Learning Recommendation Model (DLRM)\n",
    "- Deep & Cross Network (DCN)-V2\n",
    "\n",
    "For detailed instructions on each building block, and see how you can build the same DLRM model via low-level api you can visit `DLRM_low_level_api_with_prediction.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9fe531",
   "metadata": {},
   "source": [
    "## Training a DLRM model with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c2dbcb",
   "metadata": {},
   "source": [
    "Deep Learning Recommendation Model [(DLRM)](https://arxiv.org/abs/1906.00091) architecture originally proposed by Facebook in 2019. Figure 1 illustrates DLRM architecture. The model was introduced as a personalization deep learning model that uses embeddings to process sparse features that represent categorical data and a multilayer perceptron (MLP) to process dense features, then interacts these features explicitly using the statistical techniques proposed in [here](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5694074)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd01f5c",
   "metadata": {},
   "source": [
    "![DLRM](../images/DLRM.png)\n",
    "\n",
    "<p>Figure 1. DLRM architecture. Image source: <a href=\"https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Recommendation/DLRM\">Nvidia DL Examples</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f905882",
   "metadata": {},
   "source": [
    "DLRM accepts two types of features: categorical and numerical. For details of the DLRM architecture and how to build it using Merlin Models low-level API please visit `Binary_classificaion_DLRM` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73092aab",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3bfee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 16:39:28.078720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16254 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nvtabular as nvt\n",
    "\n",
    "from merlin.schema import Schema\n",
    "from merlin.schema.io.tensorflow_metadata import TensorflowMetadata\n",
    "from merlin.schema.tags import Tags\n",
    "\n",
    "import merlin_models.tf as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f53a9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable INFO and DEBUG logging everywhere\n",
    "logging.disable(logging.WARNING) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e6faf",
   "metadata": {},
   "source": [
    "### Data Download and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c29a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\n",
    "    \"INPUT_DATA_DIR\", os.path.expanduser(\"/workspace/data/movielens/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847efa98",
   "metadata": {},
   "source": [
    "With help of a utility function first we download and unzip the data. Second, we convert data via basic preprocessing, and split data into train and validation files and save them as parquet files. Afterwards, we preprocess the train and validation parquet files and generate features for model training using NVTabular.\n",
    "\n",
    "Let's download Movielens 25M dataset and then process it, and save files to disk in parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b89eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from merlin_standard_lib.utils.data_etl_utils import movielens_download_etl\n",
    "# movielens_download_etl(INPUT_DATA_DIR, 'ml-25m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96fd8f1",
   "metadata": {},
   "source": [
    "Merlin Models library relies on a `schema` object to automatically build all necessary layers to represent, normalize and aggregate input features. As you can see below, schema.pb is a protobuf file that contains metadata including statistics about features such as cardinality, min and max values and also tags features based on their characteristics and dtypes (e.g., categorical, continuous, list, integer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec0e450",
   "metadata": {},
   "source": [
    "We also generated our `schema.pbtxt` file in using NVTabular. Now we read this schema file to create a `schema` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50bbfd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_PATH = os.path.join(INPUT_DATA_DIR, 'ml-25m/train/')\n",
    "schema = TensorflowMetadata.from_proto_text_file(SCHEMA_PATH).to_merlin_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dcd7bb",
   "metadata": {},
   "source": [
    "We can print out the feature names including the binary target column, `rating_binary`, in the schema easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9abbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = schema.without(['rating', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a7ee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movieId',\n",
       " 'userId',\n",
       " 'genres',\n",
       " 'TE_movieId_rating',\n",
       " 'userId_count',\n",
       " 'rating_binary']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c53d3a4",
   "metadata": {},
   "source": [
    "Select continuous and categorical columns from schema using feature tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fdc38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_schema = schema.select_by_tag(Tags.CONTINUOUS)\n",
    "cat_schema = schema.select_by_tag(Tags.CATEGORICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "050ecf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['TE_movieId_rating', 'userId_count'], ['movieId', 'userId', 'genres'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_schema.column_names, cat_schema.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc0b1fb",
   "metadata": {},
   "source": [
    "### Define Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bb34d4",
   "metadata": {},
   "source": [
    "Below we define our input block using the `mm.ContinuousEmbedding` function. The from_schema() method processes the schema and creates the necessary layers to represent features and aggregate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a52ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import merlin_models.tf.dataset as tf_dataloader\n",
    "def get_dataloader(paths_or_dataset, batch_size=4096, shuffle=True):\n",
    "    dataloader = tf_dataloader.Dataset(\n",
    "        paths_or_dataset,\n",
    "        batch_size=batch_size,\n",
    "        label_names=['rating_binary'],\n",
    "        shuffle=shuffle,\n",
    "        schema = schema,\n",
    "    )\n",
    "    return dataloader.map(lambda X, y: (X, tf.reshape(y, (-1,))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a24a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"/workspace/data/movielens/ml-25m/\")\n",
    "train_paths = glob.glob(os.path.join(OUTPUT_DIR, \"train/*.parquet\"))\n",
    "eval_paths = glob.glob(os.path.join(OUTPUT_DIR, \"valid/*.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ba836",
   "metadata": {},
   "source": [
    "In the DLRM architecture, categorical features are processed using embeddings. Below, for each categorical feature, we create an embedding table used to provide dense representation to each unique value of this feature. The dense vector values in the embedding tables are learned during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013325ef",
   "metadata": {},
   "source": [
    "### Building a DLRM model with Merlin Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1759a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlrm_body = mm.DLRMBlock(schema,\n",
    "        embedding_dim=16,\n",
    "        bottom_block=mm.MLPBlock([64, 16]),\n",
    "        top_block=mm.MLPBlock([64, 32]),\n",
    "    )\n",
    "model = dlrm_body.connect(mm.BinaryClassificationTask(\"rating_binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc6c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "optimizer = tf.keras.optimizers.Adam(0.005)\n",
    "model.compile(optimizer=optimizer, run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14e171e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "2022-02-21 16:39:34.833290: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Block.parse of <class 'merlin_models.tf.core.Block'>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: annotated name 'output' can't be nonlocal (__autograph_generated_filefizz6obd.py, line 36)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4883/4883 [==============================] - 94s 17ms/step - rating_binary/binary_classification_task/precision: 0.7625 - rating_binary/binary_classification_task/recall: 0.8606 - rating_binary/binary_classification_task/binary_accuracy: 0.7453 - rating_binary/binary_classification_task/auc: 0.8020 - loss: 0.5143 - regularization_loss: 0.0000e+00 - total_loss: 0.5143 - val_rating_binary/binary_classification_task/precision: 0.7707 - val_rating_binary/binary_classification_task/recall: 0.8651 - val_rating_binary/binary_classification_task/binary_accuracy: 0.7547 - val_rating_binary/binary_classification_task/auc: 0.8163 - val_loss: 0.4835 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.4835\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_dataloader(nvt.Dataset(train_paths), shuffle=True) \n",
    "eval_loader = get_dataloader(nvt.Dataset(eval_paths), shuffle=False) \n",
    "\n",
    "losses = model.fit(train_loader, validation_data=eval_loader, epochs=1)\n",
    "model.reset_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd7bce",
   "metadata": {},
   "source": [
    "## Training a Deep & Cross Network (DCN)-V2 model with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c1b2c",
   "metadata": {},
   "source": [
    "[Deep & Cross Network (DCN)-V2](https://arxiv.org/pdf/2008.13535.pdf) architecture was proposed by Google in 2020 as an improve upon the original [DCN model](https://arxiv.org/pdf/1708.05123.pdf). The overall model architecture is depicted in Figure 2, with two ways to combine the cross network with the deep network: (1) stacked and (2) parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19706f4a",
   "metadata": {},
   "source": [
    "![DCN](../images/DCN.png)\n",
    "\n",
    "<p>Figure 2. DCN-v2 architecture. Image source: <a href=\"https://arxiv.org/pdf/2008.13535.pdf\">DCN V2</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8e9b3",
   "metadata": {},
   "source": [
    "The output of the embbedding layer is the concatenation of all the embedded vectors and the normalized dense features: x<sub>0</sub> = [x<sub>embed,1</sub>; . . . ; x<sub>embed,ùëõ</sub>; x<sub>dense</sub>]. Below, we build a stacked structure shown in Figure 2(a). Basically, it starts with an input layer (typically an embedding layer), and then the input x<sub>0</sub> is fed to the cross network, containing multiple cross layers that models explicit feature interactions, and then followed by the deep network. At the last step, we connect the final layer to the `BinaryClassificationTask` head for doing binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fae1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn_body = (\n",
    "    mm.InputBlock(schema,\n",
    "        embedding_options=mm.EmbeddingOptions(embedding_dim_default=16),\n",
    "        aggregation=\"concat\",\n",
    "    )\n",
    "    .connect(mm.CrossBlock(3))\n",
    "    .connect(mm.MLPBlock([512, 256]))\n",
    ")\n",
    "model = dcn_body.connect(mm.BinaryClassificationTask(\"rating_binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90054ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4883/4883 [==============================] - 96s 18ms/step - rating_binary/binary_classification_task/precision: 0.7655 - rating_binary/binary_classification_task/recall: 0.8620 - rating_binary/binary_classification_task/binary_accuracy: 0.7487 - rating_binary/binary_classification_task/auc: 0.8068 - loss: 0.5088 - regularization_loss: 0.0000e+00 - total_loss: 0.5088 - val_rating_binary/binary_classification_task/precision: 0.7881 - val_rating_binary/binary_classification_task/recall: 0.8430 - val_rating_binary/binary_classification_task/binary_accuracy: 0.7600 - val_rating_binary/binary_classification_task/auc: 0.8245 - val_loss: 0.4740 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.4740\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.005)\n",
    "model.compile(optimizer=optimizer, run_eagerly=False)\n",
    "\n",
    "train_loader = get_dataloader(nvt.Dataset(train_paths), shuffle=True) \n",
    "eval_loader = get_dataloader(nvt.Dataset(eval_paths), shuffle=False) \n",
    "\n",
    "losses = model.fit(train_loader, validation_data=eval_loader, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906f30f",
   "metadata": {},
   "source": [
    "Just like that, with couple lines of codes we are able to build state-of-the-art Deep Learning-based Recommender Systems models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
