{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a556f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions anda\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697d1452",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_models_07-train-traditional-ml-models-using-the-merlin-models-api/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Train traditional ML models using the Merlin Models API\n",
    "\n",
    "## Overview\n",
    "\n",
    "Merlin Models exposes a high-level API that can be used with models from other libraries. For the Merlin Models v0.6.0 release, some `XGBoost`, `implicit` and `lightFM` models are supported.\n",
    "\n",
    "Relying on this high level API enables you to iterate more effectively. You do not have to switch between various APIs as you evaluate additional models on your data.\n",
    "\n",
    "Furthermore, you can use your data represented as a `Dataset` across all your models.\n",
    "\n",
    "We begin by training and `XGBoost` model. In this section we go into more details on some of the best practices around training `XGBoost` models and the technical aspects of training (using `DaskDeviceQuantileDMatrix` and the  `Distributed` context manager for efficient resource usage).\n",
    "\n",
    "Subsequently, we provide brief examples of using the Merlin Models high level API to train `lightFM` and `implicit` models on Merlin Datasets.\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Training an `XGBoost` model with `DaskDeviceQuantileDMatrix` and early stopping evaluated on the validation set\n",
    "- Starting a local dask cluster with the `Distributed` context manager\n",
    "- Training `implicit` and `lightFM` models\n",
    "- Understanding the interplay between column tagging and setting the objective for a model for target selection\n",
    "- Using the Merlin Models high level API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cccd005",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d93b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.core.utils import Distributed\n",
    "from merlin.models.xgb import XGBoost\n",
    "\n",
    "from merlin.datasets.entertainment import get_movielens\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec216e2",
   "metadata": {},
   "source": [
    "We will use the `movielens-100k` dataset. The dataset consists of `userId` and `movieId` pairings. For each record, a user rates a movie and the record includes additional information such as genre of the movie, age of the user, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24586409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2022-12-02 04:28:33.569062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 04:28:33.569676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 04:28:33.569819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "downloading ml-100k.zip: 4.94MB [00:02, 1.67MB/s]                                                                                                                                                                                                                                                                                                                                         \n",
      "unzipping files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 262.77files/s]\n",
      "INFO:merlin.datasets.entertainment.movielens.dataset:starting ETL..\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train, valid = get_movielens(variant='ml-100k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26cedb",
   "metadata": {},
   "source": [
    "The `get_movielens` function downloads the `movielens-100k` data for us and returns it materialized as a Merlin `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2237f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<merlin.io.dataset.Dataset at 0x7f5ad9429400>,\n",
       " <merlin.io.dataset.Dataset at 0x7f5ad802d220>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed670fc",
   "metadata": {},
   "source": [
    "One of the features that the Merlin Models API supports is tagging. You can tag your data once, during preprocessing, and this information is picked up during later steps such as additional preprocessing steps, training your model, serving the model, and so on.\n",
    "\n",
    "Here, we will make use of the `Tags.TARGET` to identify the objective for our `XGBoost` model.\n",
    "\n",
    "During preprocessing that is performed by the `get_movielens` function, two columns in the dataset are assigned the `Tags.TARGET` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69274522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rating</td>\n",
       "      <td>(Tags.TARGET, Tags.REGRESSION)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rating_binary</td>\n",
       "      <td>(Tags.BINARY_CLASSIFICATION, Tags.TARGET)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'rating', 'tags': {<Tags.TARGET: 'target'>, <Tags.REGRESSION: 'regression'>}, 'properties': {}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'rating_binary', 'tags': {<Tags.BINARY_CLASSIFICATION: 'binary_classification'>, <Tags.TARGET: 'target'>}, 'properties': {}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.schema.select_by_tag(Tags.TARGET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e607b7",
   "metadata": {},
   "source": [
    "You can specify the target to train by passing `target_columns` when you construct the model. We would like to use `rating_binary` as our target, so we could do the following:\n",
    "\n",
    "`model = XGBoost(target_columns='rating_binary', ...`\n",
    "\n",
    "However, we can also do something better. Instead of providing this argument to the constructor of our model, we can instead specify the `objective` for our `XGBoost` model and have the Merlin Models API do the rest of the work for us.\n",
    "\n",
    "Later in this example, we will set our booster's objective to `'binary:logistic'`. Given this piece of information, the Merlin Model code can infer that we want to train with a target that has the `Tags.BINARY_CLASSIFICATION` tag assigned to it and there will be nothing else we will need to do.\n",
    "\n",
    "Before we begin to train, let us remove the `title` column from our schema. In the dataset, the title is a string, and unless we preprocess it further, it is not useful in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a28f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_without_title = train.schema.remove_col('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb65d5",
   "metadata": {},
   "source": [
    "To summarize, we will train an `XGBoost` model that predicts the rating of a movie.\n",
    "\n",
    "For the `rating_binary` column, a value of `1` indicates that the user has given the movie a high rating, and a target of `0` indicates that the user has given the movie a low rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f575b14b",
   "metadata": {},
   "source": [
    "## Training an XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1d262",
   "metadata": {},
   "source": [
    "Before we begin training, let's define a couple of custom parameters.\n",
    "\n",
    "Specifying `gpu_hist` as our `tree_method` will run the training on the GPU. Also, it will trigger representing our datasets as `DaskDeviceQuantileDMatrix` instead of the standard `DaskDMatrix`. This class is introduced in the XGBoost 1.1 release and this data format provides more efficient training with lower memory footprint. You can read more about it in this [article](https://medium.com/rapids-ai/new-features-and-optimizations-for-gpus-in-xgboost-1-1-fc153dc029ce) from the RAPIDS AI channel.\n",
    "\n",
    "Additionally, we will train with early stopping and evaluate the stopping criteria on a validation set. If we were to train without early stopping, `XGboost` would continue to improve results on the train set until it would reach a perfect score. That would result in a low training loss but we would lose any ability to generalize to unseen data. Instead, by training with early stopping, the training ceases as soon as the model starts overfitting to the train set and the results on the validation set will start to deteriorate.\n",
    "\n",
    "The `verbose_eval` parameter specifies how often metrics are reported during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1804697",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_booster_params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'tree_method':'gpu_hist',\n",
    "}\n",
    "\n",
    "xgb_train_params = {\n",
    "    'num_boost_round': 100,\n",
    "    'verbose_eval': 20,\n",
    "    'early_stopping_rounds': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b755e80",
   "metadata": {},
   "source": [
    "We are now ready to train.\n",
    "\n",
    "In order to facilitate training on data larger than the available GPU memory, the training will leverage Dask. All the complexity of starting a local dask cluster is hidden in the `Distributed` context manager.\n",
    "\n",
    "Without further ado, let's train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c511fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 04:28:44,265 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "[04:28:45] task [xgboost.dask-0]:tcp://127.0.0.1:44089 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_set-logloss:0.65874\n",
      "[20]\tvalidation_set-logloss:0.61276\n",
      "[40]\tvalidation_set-logloss:0.60799\n",
      "[60]\tvalidation_set-logloss:0.60687\n",
      "[80]\tvalidation_set-logloss:0.60615\n",
      "[85]\tvalidation_set-logloss:0.60607\n"
     ]
    }
   ],
   "source": [
    "with Distributed():\n",
    "    model = XGBoost(schema=schema_without_title, **xgb_booster_params)\n",
    "    model.fit(\n",
    "        train,\n",
    "        evals=[(valid, 'validation_set'),],\n",
    "        **xgb_train_params\n",
    "    )\n",
    "    metrics = model.evaluate(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535396bc",
   "metadata": {},
   "source": [
    "## Training an implicit model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0dad36",
   "metadata": {},
   "source": [
    "`Implicit` provides fast Python implementations of several different popular recommendation algorithms for implicit feedback datasets.\n",
    "\n",
    "These models are designed to work with implicit datasets, that is datasets that don't have explicit labels! What this translates to is that we will not be able to use these algorithms for training on data with labels such as `ratings` or `number of likes received`, etc. These models are geared toward predicting a binary target of the form of how likely a user is to interact with an item of given id.\n",
    "\n",
    "There are two ways we can train and `implicit` model. We can pass only user-item id pairs. In this case the model will treat the pairs we pass as positive examples and will generate negative examples by itself. Alternatively, we can pass in a column of zeros and ones where ones indicate a positive example. We need to tag that column with `Tags.TARGET` (as outlined in the \"Preparing the data\" section above). From there on, all that remains is to pass the data to the `fit` method of our model to train it.\n",
    "\n",
    "There are two `implicit` models you can train with `Merli Models`:\n",
    "\n",
    "* `AlternatingLeastSquares` from [Collaborative Filtering for Implicit Feedback Datasets](http://yifanhu.net/PUB/cf.pdf))\n",
    "* `BayesianPersonalizedRanking` from [BPR: Bayesian Personalized Ranking from Implicit Feedback](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf)\n",
    "\n",
    "In this example, we will train a `BayesianPersonalizedRanking` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3e69a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.implicit import BayesianPersonalizedRanking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a8435",
   "metadata": {},
   "source": [
    "`merlin.models.implicit` doesn't have the same facility as `merlin.models.xgb.XGBoost` for identifying which target column it should use.\n",
    "\n",
    "Let's remove the `rating` column from the schema so that only `rating_binary` is left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ed10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.schema = schema_without_title.remove_col('rating')\n",
    "valid.schema = schema_without_title.remove_col('rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e9ab2d",
   "metadata": {},
   "source": [
    "This is a shape of data that will go into our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc22e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>genres</th>\n",
       "      <th>TE_movieId_rating</th>\n",
       "      <th>userId_count</th>\n",
       "      <th>gender</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_binary</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>43</td>\n",
       "      <td>0.779876</td>\n",
       "      <td>5.572154</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>231</td>\n",
       "      <td>77</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.896619</td>\n",
       "      <td>5.572154</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>366</td>\n",
       "      <td>77</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.954632</td>\n",
       "      <td>5.572154</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "      <td>-0.093809</td>\n",
       "      <td>5.572154</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>383</td>\n",
       "      <td>77</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.539376</td>\n",
       "      <td>5.572154</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  userId  genres  TE_movieId_rating  userId_count  gender  zip_code  \\\n",
       "0        7      77      43           0.779876      5.572154       1        77   \n",
       "1      231      77      13          -0.896619      5.572154       1        77   \n",
       "2      366      77      17          -0.954632      5.572154       1        77   \n",
       "3       96      77      89          -0.093809      5.572154       1        77   \n",
       "4      383      77      25          -0.539376      5.572154       1        77   \n",
       "\n",
       "   rating  rating_binary  age              title  \n",
       "0       5              1    1   Toy Story (1995)  \n",
       "1       3              0    1   GoldenEye (1995)  \n",
       "2       4              1    1  Four Rooms (1995)  \n",
       "3       3              0    1  Get Shorty (1995)  \n",
       "4       3              0    1     Copycat (1995)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22416c57",
   "metadata": {},
   "source": [
    "However, only the columns tagged with `Tags.USER_ID`, `Tags.ITEM_ID` or `Tags.TARGET` will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fb2b01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movieId</td>\n",
       "      <td>(Tags.ITEM_ID, Tags.ITEM, Tags.ID, Tags.CATEGO...</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.movieId.parquet</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>userId</td>\n",
       "      <td>(Tags.USER, Tags.USER_ID, Tags.ID, Tags.CATEGO...</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.userId.parquet</td>\n",
       "      <td>944.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rating_binary</td>\n",
       "      <td>(Tags.BINARY_CLASSIFICATION, Tags.TARGET)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'movieId', 'tags': {<Tags.ITEM_ID: 'item_id'>, <Tags.ITEM: 'item'>, <Tags.ID: 'id'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.movieId.parquet', 'embedding_sizes': {'cardinality': 1681.0, 'dimension': 102.0}, 'domain': {'min': 0, 'max': 1680}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'userId', 'tags': {<Tags.USER: 'user'>, <Tags.USER_ID: 'user_id'>, <Tags.ID: 'id'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.userId.parquet', 'embedding_sizes': {'cardinality': 944.0, 'dimension': 74.0}, 'domain': {'min': 0, 'max': 943}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'rating_binary', 'tags': {<Tags.BINARY_CLASSIFICATION: 'binary_classification'>, <Tags.TARGET: 'target'>}, 'properties': {}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.schema.select_by_tag([Tags.USER_ID, Tags.ITEM_ID, Tags.TARGET])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26459da",
   "metadata": {},
   "source": [
    "Let's train our model.\n",
    "\n",
    "There are several options we can specify. Here are the 3 most important ones:\n",
    "\n",
    "* factors - the number of latent factors to compute\n",
    "* learning_rate – the learning rate to apply for SGD updates during training\n",
    "* regularization – the regularization factor to use\n",
    "\n",
    "Further information on the arguments that `BayesianPersonalizedRanking` accepts can be found in [implicit's documentation](https://implicit.readthedocs.io/en/latest/bpr.html).\n",
    "\n",
    "We can also train without passing in any of the above values in which case `BayesianPersonalizedRanking` will use the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72edc5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7e472c443d4e11921932eb9ba338eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "implicit = BayesianPersonalizedRanking()\n",
    "implicit.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7151634",
   "metadata": {},
   "source": [
    "Having trained the model, we can now evaluate it.\n",
    "\n",
    "Implicit models can be best thought of as retrieval models and so we have the usual set of retrieval metrics at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76326a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72518d805e7474bb1cc30071858f6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'precision@10': 0.19480381760339344,\n",
       " 'map@10': 0.10750185157131092,\n",
       " 'ndcg@10': 0.22416874523237307,\n",
       " 'auc@10': 0.5950644703322262}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_metrics = implicit.evaluate(valid)\n",
    "implicit_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066d29fd",
   "metadata": {},
   "source": [
    "And last but not least, lets use our trained implicit model to output predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a327c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[373, 469, 518, ..., 187, 218, 312],\n",
       "        [238, 191,  49, ...,  64, 143,   5],\n",
       "        [176, 348, 180, ..., 318, 239, 741],\n",
       "        ...,\n",
       "        [  1,   2,  16, ...,   3,  12,  21],\n",
       "        [  7,   6,   1, ...,   8,   9, 102],\n",
       "        [  5,  14,   4, ..., 121,  90,  99]], dtype=int32),\n",
       " array([[4.086568 , 3.9380424, 3.8917089, ..., 3.5415509, 3.5352802,\n",
       "         3.4903793],\n",
       "        [3.1168025, 3.0303137, 2.8660183, ..., 2.5883107, 2.5812874,\n",
       "         2.5387335],\n",
       "        [2.2507575, 1.9358999, 1.8727003, ..., 1.6805655, 1.6348444,\n",
       "         1.606662 ],\n",
       "        ...,\n",
       "        [2.3514626, 2.2953627, 2.2321575, ..., 1.9194883, 1.8870326,\n",
       "         1.8788759],\n",
       "        [2.5334208, 2.5131962, 2.4948564, ..., 2.187589 , 2.1635065,\n",
       "         2.108275 ],\n",
       "        [2.9087033, 2.877173 , 2.6436164, ..., 2.4158123, 2.3826144,\n",
       "         2.3803732]], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_preds = implicit.predict(valid)\n",
    "implicit_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc48df",
   "metadata": {},
   "source": [
    "The predictions are item ids for each of the user id that we passed in as our data. They are ordered from the most likely to be interacted with by the user to the least likely as predicted by our `implicit` model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b19290",
   "metadata": {},
   "source": [
    "## Training a LightFM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb64446",
   "metadata": {},
   "source": [
    "[LightFM](https://github.com/lyst/lightfm) implements of a number of popular recommendation algorithms for both implicit and explicit feedback, including efficient implementation of BPR and WARP ranking losses.\n",
    "\n",
    "You can specify what type of model to train on through the use of the `loss` argument. Here we will train with a `warp` loss (Weighted Approximate-Rank Pairwise loss). You can read more about available losses as well as the parameters that can be used for training [here](https://making.lyst.com/lightfm/docs/lightfm.html).\n",
    "\n",
    "Let us train a model that will again predict a score of how likely a user is to interact with a given item, following the same approach as we did above with the `implicit` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ed97cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.lightfm import LightFM\n",
    "\n",
    "lightfm = LightFM(loss='warp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07cb401",
   "metadata": {},
   "source": [
    "We can now train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "471b78c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightfm.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a327de",
   "metadata": {},
   "source": [
    "Now that the model is trained let's validate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c8a8038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precisions@10': 0.19862142, 'auc': 0.90727156}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightfm_metrics = lightfm.evaluate(valid)\n",
    "lightfm_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce8d1f",
   "metadata": {},
   "source": [
    "We can now use the model to predict on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53f11e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.2559712, -2.3324568, -2.5932639, ..., -2.4952314, -2.311529 ,\n",
       "       -3.134278 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightfm_preds = lightfm.predict(valid)\n",
    "lightfm_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb3b5d1",
   "metadata": {},
   "source": [
    "Here, the model takes in user-item pairs and predicts the likelihood of interaction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
