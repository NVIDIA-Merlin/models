program: ranking_train_eval.py
method: bayes
metric:
  name: auc_improv_avg-final
  goal: maximize
parameters:
  activation:
    distribution: categorical
    values:
      - relu
  model:
    distribution: categorical
    values:
      - mlp
  dropout:
    distribution: categorical
    values:
      - 0.05458727478160215
  embeddings_l2_reg:
    distribution: categorical
    values:
      - 2.920004248774391e-09
  embedding_sizes_multiplier:
    distribution: categorical
    values:
      - 5
  l2_reg:
    distribution: categorical
    values:
      - 8.553048162662613e-05
  lr:
    distribution: categorical
    values:
      - 0.0031792007637684934
  lr_decay_rate:
    distribution: categorical
    values:
      - 0.9927757536617268
  lr_decay_steps:
    distribution: categorical
    values:
      - 141
  use_task_towers:
    distribution: categorical
    values:
      - True
  tower_layers:
    distribution: categorical
    values:
      - 64
  tasks:
    distribution: categorical
    values:
      - all
  train_batch_size:
    distribution: categorical
    values:
      - 16384
  eval_batch_size:
    distribution: categorical
    values:
      - 65536
  epochs:
    distribution: categorical
    values:
      - 1
  mlp_layers:
    distribution: categorical
    values:
      - 256


  mtl_loss_weight_click:
    distribution: categorical
    values:
      - 5
  mtl_loss_weight_like:
    distribution: int_uniform
    min: 1
    max: 10
  mtl_loss_weight_share:
    distribution: int_uniform
    min: 1
    max: 10
  mtl_loss_weight_follow:
    distribution: int_uniform
    min: 1
    max: 10
  mtl_loss_weight_watching_times:
    distribution: int_uniform
    min: 1
    max: 10  

  mtl_pos_class_weight_click:
    distribution: int_uniform
    min: 1
    max: 10
  mtl_pos_class_weight_like:
    distribution: int_uniform
    min: 1
    max: 100
  mtl_pos_class_weight_share:
    distribution: int_uniform
    min: 1
    max: 100
  mtl_pos_class_weight_follow:
    distribution: int_uniform
    min: 1
    max: 100