{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb3ae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:26:22.114565: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2023-03-13 20:26:24.538242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 20:26:24.538645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 20:26:24.538803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-03-13 20:26:24.965689: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 20:26:24.966631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 20:26:24.966839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 20:26:24.966994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 20:26:25.703328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 20:26:25.703539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 20:26:25.703699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 20:26:25.703813: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-03-13 20:26:25.703876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24576 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.io.dataset import Dataset\n",
    "import merlin.models.tf as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11647dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset(\"ecom_dataset/0001/train.parquet\")\n",
    "valid = Dataset(\"ecom_dataset/0002/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab4e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'sess_pid_seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d9903e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 192\n",
    "n_layer = 3\n",
    "n_head = 16\n",
    "batch_size = 128\n",
    "learning_rate = 0.0006667377132554976\n",
    "n_epoch = 5\n",
    "item_embedding_dim = 448 \n",
    "item_id_embeddings_init_std = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ade14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    mlp_block = mm.MLPBlock(\n",
    "                    [d_model],\n",
    "                    activation='relu',\n",
    "                    no_activation_last_layer=True,\n",
    "                )\n",
    "\n",
    "    from merlin.schema.io.tensorflow_metadata import TensorflowMetadata\n",
    "\n",
    "    schema = TensorflowMetadata.from_proto_text_file(\n",
    "        '../',\n",
    "        file_name='rees46_schema_modified.pbtxt'\n",
    "    ).to_merlin_schema()\n",
    "\n",
    "    train.schema = schema\n",
    "\n",
    "    schema_model = schema.select_by_tag(Tags.ITEM_ID)\n",
    "    input_block = mm.InputBlockV2(\n",
    "        schema_model,\n",
    "        categorical=mm.Embeddings(\n",
    "                schema_model.select_by_tag(Tags.CATEGORICAL),\n",
    "                dim=item_embedding_dim,\n",
    "                sequence_combiner=None,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    train.schema = train.schema.select_by_name('sess_pid_seq')\n",
    "\n",
    "    xlnet_block = mm.XLNetBlock(d_model=d_model, n_head=n_head, n_layer=n_layer)\n",
    "\n",
    "    dense_block = mm.SequentialBlock(\n",
    "        input_block,\n",
    "        mlp_block,\n",
    "        xlnet_block\n",
    "    )\n",
    "\n",
    "    mlp_block2 = mm.MLPBlock(\n",
    "                    [item_embedding_dim],\n",
    "                    activation='relu',\n",
    "                    no_activation_last_layer=True,\n",
    "                )\n",
    "\n",
    "    prediction_task = mm.CategoricalOutput(\n",
    "        to_call=input_block[\"categorical\"][target],\n",
    "    )\n",
    "\n",
    "    model_transformer = mm.Model(dense_block, mlp_block2, prediction_task)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=learning_rate,\n",
    "    )\n",
    "\n",
    "    model_transformer.compile(run_eagerly=False, optimizer=optimizer, loss=\"categorical_crossentropy\",\n",
    "                  metrics=mm.TopKMetricsAggregator.default_metrics(top_ks=[20])\n",
    "                 )\n",
    "    return model_transformer, xlnet_block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78302207",
   "metadata": {},
   "source": [
    "# Run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7474131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['model_5/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0', 'transformer/layer_._2/rel_attn/r_s_bias:0', 'transformer/layer_._2/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_5/sequential_block_29/xl_net_block_5/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_5/sequential_block_29/xl_net_block_5/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask/GatherV2:0\", shape=(None, 192), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_5/sequential_block_29/xl_net_block_5/prepare_transformer_inputs_4/RaggedToTensor_1/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_5/sequential_block_29/xl_net_block_5/sequential_block_32/replace_masked_embeddings_5/RaggedWhere/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_5/sequential_block_29/xl_net_block_5/sequential_block_32/replace_masked_embeddings_5/RaggedWhere/Reshape_2:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_5/sequential_block_29/xl_net_block_5/sequential_block_32/replace_masked_embeddings_5/RaggedWhere/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_5/sequential_block_29/xl_net_block_5/sequential_block_32/replace_masked_embeddings_5/RaggedWhere/RaggedTile_2/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_5/sequential_block_29/xl_net_block_5/sequential_block_32/replace_masked_embeddings_5/RaggedWhere/RaggedTile_2/Reshape_2:0\", shape=(None, 192), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_5/sequential_block_29/xl_net_block_5/sequential_block_32/replace_masked_embeddings_5/RaggedWhere/RaggedTile_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['model_5/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0', 'transformer/layer_._2/rel_attn/r_s_bias:0', 'transformer/layer_._2/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 06:41:41.374760: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_5/sequential_block_29/xl_net_block_5/sequential_block_32/replace_masked_embeddings_5/RaggedWhere/Assert/AssertGuard/branch_executed/_31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 164s 230ms/step - loss: 9.4924 - recall_at_20: 0.0704 - mrr_at_20: 0.0174 - ndcg_at_20: 0.0288 - map_at_20: 0.0174 - precision_at_20: 0.0035 - regularization_loss: 0.0000e+00 - loss_batch: 9.4899\n",
      "Epoch 2/5\n",
      "677/677 [==============================] - 159s 234ms/step - loss: 8.0755 - recall_at_20: 0.1759 - mrr_at_20: 0.0480 - ndcg_at_20: 0.0758 - map_at_20: 0.0480 - precision_at_20: 0.0088 - regularization_loss: 0.0000e+00 - loss_batch: 8.0726\n",
      "Epoch 3/5\n",
      "677/677 [==============================] - 159s 235ms/step - loss: 7.3926 - recall_at_20: 0.2427 - mrr_at_20: 0.0671 - ndcg_at_20: 0.1053 - map_at_20: 0.0671 - precision_at_20: 0.0121 - regularization_loss: 0.0000e+00 - loss_batch: 7.3887\n",
      "Epoch 4/5\n",
      "677/677 [==============================] - 159s 235ms/step - loss: 6.9299 - recall_at_20: 0.2932 - mrr_at_20: 0.0821 - ndcg_at_20: 0.1281 - map_at_20: 0.0821 - precision_at_20: 0.0147 - regularization_loss: 0.0000e+00 - loss_batch: 6.9255\n",
      "Epoch 5/5\n",
      "677/677 [==============================] - 143s 211ms/step - loss: 6.5825 - recall_at_20: 0.3350 - mrr_at_20: 0.0951 - ndcg_at_20: 0.1476 - map_at_20: 0.0951 - precision_at_20: 0.0167 - regularization_loss: 0.0000e+00 - loss_batch: 6.5791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 06:54:43.265476: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_5/sequential_block_29/xl_net_block_5/sequential_block_32/replace_masked_embeddings_5/RaggedWhere/Assert/AssertGuard/branch_executed/_529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 9s 49ms/step - loss: 8.3507 - recall_at_20: 0.2332 - mrr_at_20: 0.0720 - ndcg_at_20: 0.1070 - map_at_20: 0.0720 - precision_at_20: 0.0117 - regularization_loss: 0.0000e+00 - loss_batch: 8.3848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 8.350717544555664,\n",
       " 'recall_at_20': 0.23180365562438965,\n",
       " 'mrr_at_20': 0.06943727284669876,\n",
       " 'ndcg_at_20': 0.10483581572771072,\n",
       " 'map_at_20': 0.06943727284669876,\n",
       " 'precision_at_20': 0.011590182781219482,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 9.85844612121582}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformer, xlnet_block = get_model()\n",
    "model_transformer.fit(\n",
    "    train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epoch,\n",
    "    pre=mm.SequenceMaskRandom(schema=train.schema, target=target, transformer=xlnet_block)\n",
    ")\n",
    "\n",
    "predict_last = mm.SequencePredictLast(schema=valid.schema, target=target, transformer=xlnet_block)\n",
    "model_transformer.evaluate(\n",
    "    valid,\n",
    "    batch_size=batch_size,\n",
    "    pre=predict_last,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02b2e706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_block_29 (Sequen  multiple                 176252800 \n",
      " tialBlock)                                                      \n",
      "                                                                 \n",
      " sequential_block_30 (Sequen  multiple                 86464     \n",
      " tialBlock)                                                      \n",
      "                                                                 \n",
      " sess_pid_seq/categorical_ou  multiple                 175110449 \n",
      " tput (CategoricalOutput)                                        \n",
      "                                                                 \n",
      " model_context_5 (ModelConte  multiple                 0         \n",
      " xt)                                                             \n",
      "                                                                 \n",
      " prepare_features_11 (Prepar  multiple                 0         \n",
      " eFeatures)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 176,729,266\n",
      "Trainable params: 176,729,265\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513d28a",
   "metadata": {},
   "source": [
    "# Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e624551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['model_1/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0', 'transformer/layer_._2/rel_attn/r_s_bias:0', 'transformer/layer_._2/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_1/sequential_block_9/xl_net_block_1/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_1/sequential_block_9/xl_net_block_1/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask/GatherV2:0\", shape=(None, 192), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_1/sequential_block_9/xl_net_block_1/prepare_transformer_inputs_4/RaggedToTensor_1/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_1/sequential_block_9/xl_net_block_1/sequential_block_12/replace_masked_embeddings_1/RaggedWhere/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_1/sequential_block_9/xl_net_block_1/sequential_block_12/replace_masked_embeddings_1/RaggedWhere/Reshape_2:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_1/sequential_block_9/xl_net_block_1/sequential_block_12/replace_masked_embeddings_1/RaggedWhere/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_1/sequential_block_9/xl_net_block_1/sequential_block_12/replace_masked_embeddings_1/RaggedWhere/RaggedTile_2/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_1/sequential_block_9/xl_net_block_1/sequential_block_12/replace_masked_embeddings_1/RaggedWhere/RaggedTile_2/Reshape_2:0\", shape=(None, 192), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_1/sequential_block_9/xl_net_block_1/sequential_block_12/replace_masked_embeddings_1/RaggedWhere/RaggedTile_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['model_1/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0', 'transformer/layer_._2/rel_attn/r_s_bias:0', 'transformer/layer_._2/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:31:46.363004: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_1/sequential_block_9/xl_net_block_1/sequential_block_12/replace_masked_embeddings_1/RaggedWhere/Assert/AssertGuard/branch_executed/_31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 65s 84ms/step - loss: 9.4953 - recall_at_20: 0.0663 - mrr_at_20: 0.0167 - ndcg_at_20: 0.0274 - map_at_20: 0.0167 - precision_at_20: 0.0033 - regularization_loss: 0.0000e+00 - loss_batch: 9.4908\n",
      "Epoch 2/5\n",
      "677/677 [==============================] - 57s 84ms/step - loss: 8.1077 - recall_at_20: 0.1712 - mrr_at_20: 0.0474 - ndcg_at_20: 0.0744 - map_at_20: 0.0474 - precision_at_20: 0.0086 - regularization_loss: 0.0000e+00 - loss_batch: 8.1021\n",
      "Epoch 3/5\n",
      "677/677 [==============================] - 57s 84ms/step - loss: 7.3969 - recall_at_20: 0.2444 - mrr_at_20: 0.0671 - ndcg_at_20: 0.1057 - map_at_20: 0.0671 - precision_at_20: 0.0122 - regularization_loss: 0.0000e+00 - loss_batch: 7.3975\n",
      "Epoch 4/5\n",
      "677/677 [==============================] - 57s 84ms/step - loss: 6.9683 - recall_at_20: 0.2853 - mrr_at_20: 0.0794 - ndcg_at_20: 0.1243 - map_at_20: 0.0794 - precision_at_20: 0.0143 - regularization_loss: 0.0000e+00 - loss_batch: 6.9657\n",
      "Epoch 5/5\n",
      "677/677 [==============================] - 57s 85ms/step - loss: 6.6522 - recall_at_20: 0.3234 - mrr_at_20: 0.0917 - ndcg_at_20: 0.1423 - map_at_20: 0.0917 - precision_at_20: 0.0162 - regularization_loss: 0.0000e+00 - loss_batch: 6.6482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:36:37.576034: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_1/sequential_block_9/xl_net_block_1/sequential_block_12/replace_masked_embeddings_1/RaggedWhere/Assert/AssertGuard/branch_executed/_529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 9s 48ms/step - loss: 8.3509 - recall_at_20: 0.2300 - mrr_at_20: 0.0691 - ndcg_at_20: 0.1041 - map_at_20: 0.0691 - precision_at_20: 0.0115 - regularization_loss: 0.0000e+00 - loss_batch: 8.3545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 8.350946426391602,\n",
       " 'recall_at_20': 0.22926461696624756,\n",
       " 'mrr_at_20': 0.06758848577737808,\n",
       " 'ndcg_at_20': 0.10286629945039749,\n",
       " 'map_at_20': 0.06758848577737808,\n",
       " 'precision_at_20': 0.011463231407105923,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 8.509391784667969}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformer, xlnet_block = get_model()\n",
    "model_transformer.fit(\n",
    "    train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epoch,\n",
    "    pre=mm.SequenceMaskRandom(schema=train.schema, target=target, transformer=xlnet_block)\n",
    ")\n",
    "\n",
    "predict_last = mm.SequencePredictLast(schema=valid.schema, target=target, transformer=xlnet_block)\n",
    "model_transformer.evaluate(\n",
    "    valid,\n",
    "    batch_size=batch_size,\n",
    "    pre=predict_last,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42dea65",
   "metadata": {},
   "source": [
    "# Run 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e7322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['model_2/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0', 'transformer/layer_._2/rel_attn/r_s_bias:0', 'transformer/layer_._2/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_2/sequential_block_14/xl_net_block_2/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_2/sequential_block_14/xl_net_block_2/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask/GatherV2:0\", shape=(None, 192), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_2/sequential_block_14/xl_net_block_2/prepare_transformer_inputs_4/RaggedToTensor_1/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_2/sequential_block_14/xl_net_block_2/sequential_block_17/replace_masked_embeddings_2/RaggedWhere/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_2/sequential_block_14/xl_net_block_2/sequential_block_17/replace_masked_embeddings_2/RaggedWhere/Reshape_2:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_2/sequential_block_14/xl_net_block_2/sequential_block_17/replace_masked_embeddings_2/RaggedWhere/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_2/sequential_block_14/xl_net_block_2/sequential_block_17/replace_masked_embeddings_2/RaggedWhere/RaggedTile_2/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_2/sequential_block_14/xl_net_block_2/sequential_block_17/replace_masked_embeddings_2/RaggedWhere/RaggedTile_2/Reshape_2:0\", shape=(None, 192), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_2/sequential_block_14/xl_net_block_2/sequential_block_17/replace_masked_embeddings_2/RaggedWhere/RaggedTile_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['model_2/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0', 'transformer/layer_._2/rel_attn/r_s_bias:0', 'transformer/layer_._2/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:36:51.268625: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_2/sequential_block_14/xl_net_block_2/sequential_block_17/replace_masked_embeddings_2/RaggedWhere/Assert/AssertGuard/branch_executed/_31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 65s 84ms/step - loss: 9.4386 - recall_at_20: 0.0722 - mrr_at_20: 0.0190 - ndcg_at_20: 0.0305 - map_at_20: 0.0190 - precision_at_20: 0.0036 - regularization_loss: 0.0000e+00 - loss_batch: 9.4342\n",
      "Epoch 2/5\n",
      "677/677 [==============================] - 57s 84ms/step - loss: 8.0171 - recall_at_20: 0.1837 - mrr_at_20: 0.0502 - ndcg_at_20: 0.0792 - map_at_20: 0.0502 - precision_at_20: 0.0092 - regularization_loss: 0.0000e+00 - loss_batch: 8.0103\n",
      "Epoch 3/5\n",
      "677/677 [==============================] - 58s 85ms/step - loss: 7.3722 - recall_at_20: 0.2467 - mrr_at_20: 0.0691 - ndcg_at_20: 0.1078 - map_at_20: 0.0691 - precision_at_20: 0.0123 - regularization_loss: 0.0000e+00 - loss_batch: 7.3658\n",
      "Epoch 4/5\n",
      "677/677 [==============================] - 57s 85ms/step - loss: 6.9592 - recall_at_20: 0.2892 - mrr_at_20: 0.0807 - ndcg_at_20: 0.1262 - map_at_20: 0.0807 - precision_at_20: 0.0145 - regularization_loss: 0.0000e+00 - loss_batch: 6.9549\n",
      "Epoch 5/5\n",
      "677/677 [==============================] - 57s 85ms/step - loss: 6.6706 - recall_at_20: 0.3194 - mrr_at_20: 0.0899 - ndcg_at_20: 0.1401 - map_at_20: 0.0899 - precision_at_20: 0.0160 - regularization_loss: 0.0000e+00 - loss_batch: 6.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:41:42.865959: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_2/sequential_block_14/xl_net_block_2/sequential_block_17/replace_masked_embeddings_2/RaggedWhere/Assert/AssertGuard/branch_executed/_529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 9s 49ms/step - loss: 8.3114 - recall_at_20: 0.2264 - mrr_at_20: 0.0687 - ndcg_at_20: 0.1030 - map_at_20: 0.0687 - precision_at_20: 0.0113 - regularization_loss: 0.0000e+00 - loss_batch: 8.3190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 8.311356544494629,\n",
       " 'recall_at_20': 0.22738386690616608,\n",
       " 'mrr_at_20': 0.0663006603717804,\n",
       " 'ndcg_at_20': 0.10139463096857071,\n",
       " 'map_at_20': 0.0663006603717804,\n",
       " 'precision_at_20': 0.011369192972779274,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 8.649133682250977}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformer, xlnet_block = get_model()\n",
    "model_transformer.fit(\n",
    "    train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epoch,\n",
    "    pre=mm.SequenceMaskRandom(schema=train.schema, target=target, transformer=xlnet_block)\n",
    ")\n",
    "\n",
    "predict_last = mm.SequencePredictLast(schema=valid.schema, target=target, transformer=xlnet_block)\n",
    "model_transformer.evaluate(\n",
    "    valid,\n",
    "    batch_size=batch_size,\n",
    "    pre=predict_last,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610da911",
   "metadata": {},
   "source": [
    "# Run 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0f0891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['model_3/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0', 'transformer/layer_._2/rel_attn/r_s_bias:0', 'transformer/layer_._2/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_3/sequential_block_19/xl_net_block_3/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_3/sequential_block_19/xl_net_block_3/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask/GatherV2:0\", shape=(None, 192), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_3/sequential_block_19/xl_net_block_3/prepare_transformer_inputs_4/RaggedToTensor_1/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_3/sequential_block_19/xl_net_block_3/sequential_block_22/replace_masked_embeddings_3/RaggedWhere/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_3/sequential_block_19/xl_net_block_3/sequential_block_22/replace_masked_embeddings_3/RaggedWhere/Reshape_2:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_3/sequential_block_19/xl_net_block_3/sequential_block_22/replace_masked_embeddings_3/RaggedWhere/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_3/sequential_block_19/xl_net_block_3/sequential_block_22/replace_masked_embeddings_3/RaggedWhere/RaggedTile_2/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_3/sequential_block_19/xl_net_block_3/sequential_block_22/replace_masked_embeddings_3/RaggedWhere/RaggedTile_2/Reshape_2:0\", shape=(None, 192), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_3/sequential_block_19/xl_net_block_3/sequential_block_22/replace_masked_embeddings_3/RaggedWhere/RaggedTile_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['model_3/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0', 'transformer/layer_._2/rel_attn/r_s_bias:0', 'transformer/layer_._2/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:41:56.776497: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_3/sequential_block_19/xl_net_block_3/sequential_block_22/replace_masked_embeddings_3/RaggedWhere/Assert/AssertGuard/branch_executed/_31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 65s 84ms/step - loss: 9.4786 - recall_at_20: 0.0673 - mrr_at_20: 0.0176 - ndcg_at_20: 0.0283 - map_at_20: 0.0176 - precision_at_20: 0.0034 - regularization_loss: 0.0000e+00 - loss_batch: 9.4794\n",
      "Epoch 2/5\n",
      "677/677 [==============================] - 57s 84ms/step - loss: 8.1173 - recall_at_20: 0.1692 - mrr_at_20: 0.0454 - ndcg_at_20: 0.0723 - map_at_20: 0.0454 - precision_at_20: 0.0085 - regularization_loss: 0.0000e+00 - loss_batch: 8.1128\n",
      "Epoch 3/5\n",
      "677/677 [==============================] - 57s 85ms/step - loss: 7.4296 - recall_at_20: 0.2409 - mrr_at_20: 0.0664 - ndcg_at_20: 0.1044 - map_at_20: 0.0664 - precision_at_20: 0.0120 - regularization_loss: 0.0000e+00 - loss_batch: 7.4268\n",
      "Epoch 4/5\n",
      "677/677 [==============================] - 58s 85ms/step - loss: 6.9533 - recall_at_20: 0.2861 - mrr_at_20: 0.0778 - ndcg_at_20: 0.1232 - map_at_20: 0.0778 - precision_at_20: 0.0143 - regularization_loss: 0.0000e+00 - loss_batch: 6.9502\n",
      "Epoch 5/5\n",
      "677/677 [==============================] - 57s 85ms/step - loss: 6.6322 - recall_at_20: 0.3285 - mrr_at_20: 0.0931 - ndcg_at_20: 0.1445 - map_at_20: 0.0931 - precision_at_20: 0.0164 - regularization_loss: 0.0000e+00 - loss_batch: 6.6306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:46:48.752036: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_3/sequential_block_19/xl_net_block_3/sequential_block_22/replace_masked_embeddings_3/RaggedWhere/Assert/AssertGuard/branch_executed/_529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 9s 49ms/step - loss: 8.3535 - recall_at_20: 0.2280 - mrr_at_20: 0.0700 - ndcg_at_20: 0.1046 - map_at_20: 0.0700 - precision_at_20: 0.0114 - regularization_loss: 0.0000e+00 - loss_batch: 8.3763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 8.353541374206543,\n",
       " 'recall_at_20': 0.23067519068717957,\n",
       " 'mrr_at_20': 0.06726308912038803,\n",
       " 'ndcg_at_20': 0.10282379388809204,\n",
       " 'map_at_20': 0.06726308912038803,\n",
       " 'precision_at_20': 0.011533760465681553,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 9.360955238342285}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformer, xlnet_block = get_model()\n",
    "model_transformer.fit(\n",
    "    train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epoch,\n",
    "    pre=mm.SequenceMaskRandom(schema=train.schema, target=target, transformer=xlnet_block)\n",
    ")\n",
    "\n",
    "predict_last = mm.SequencePredictLast(schema=valid.schema, target=target, transformer=xlnet_block)\n",
    "model_transformer.evaluate(\n",
    "    valid,\n",
    "    batch_size=batch_size,\n",
    "    pre=predict_last,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cffc60d",
   "metadata": {},
   "source": [
    "# Run 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6981ff6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['model_4/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0', 'transformer/layer_._2/rel_attn/r_s_bias:0', 'transformer/layer_._2/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_4/sequential_block_24/xl_net_block_4/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_4/sequential_block_24/xl_net_block_4/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask/GatherV2:0\", shape=(None, 192), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_4/sequential_block_24/xl_net_block_4/prepare_transformer_inputs_4/RaggedToTensor_1/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_4/sequential_block_24/xl_net_block_4/sequential_block_27/replace_masked_embeddings_4/RaggedWhere/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model_4/sequential_block_24/xl_net_block_4/sequential_block_27/replace_masked_embeddings_4/RaggedWhere/Reshape_2:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_4/sequential_block_24/xl_net_block_4/sequential_block_27/replace_masked_embeddings_4/RaggedWhere/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_4/sequential_block_24/xl_net_block_4/sequential_block_27/replace_masked_embeddings_4/RaggedWhere/RaggedTile_2/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_4/sequential_block_24/xl_net_block_4/sequential_block_27/replace_masked_embeddings_4/RaggedWhere/RaggedTile_2/Reshape_2:0\", shape=(None, 192), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_4/sequential_block_24/xl_net_block_4/sequential_block_27/replace_masked_embeddings_4/RaggedWhere/RaggedTile_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['model_4/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0', 'transformer/layer_._2/rel_attn/r_s_bias:0', 'transformer/layer_._2/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:47:02.588234: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_4/sequential_block_24/xl_net_block_4/sequential_block_27/replace_masked_embeddings_4/RaggedWhere/Assert/AssertGuard/branch_executed/_31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 65s 84ms/step - loss: 9.4909 - recall_at_20: 0.0707 - mrr_at_20: 0.0184 - ndcg_at_20: 0.0297 - map_at_20: 0.0184 - precision_at_20: 0.0035 - regularization_loss: 0.0000e+00 - loss_batch: 9.4882\n",
      "Epoch 2/5\n",
      "677/677 [==============================] - 57s 84ms/step - loss: 8.1387 - recall_at_20: 0.1653 - mrr_at_20: 0.0453 - ndcg_at_20: 0.0713 - map_at_20: 0.0453 - precision_at_20: 0.0083 - regularization_loss: 0.0000e+00 - loss_batch: 8.1347\n",
      "Epoch 3/5\n",
      "677/677 [==============================] - 57s 84ms/step - loss: 7.4398 - recall_at_20: 0.2387 - mrr_at_20: 0.0662 - ndcg_at_20: 0.1038 - map_at_20: 0.0662 - precision_at_20: 0.0119 - regularization_loss: 0.0000e+00 - loss_batch: 7.4371\n",
      "Epoch 4/5\n",
      "677/677 [==============================] - 57s 85ms/step - loss: 6.9831 - recall_at_20: 0.2878 - mrr_at_20: 0.0810 - ndcg_at_20: 0.1261 - map_at_20: 0.0810 - precision_at_20: 0.0144 - regularization_loss: 0.0000e+00 - loss_batch: 6.9787\n",
      "Epoch 5/5\n",
      "677/677 [==============================] - 57s 85ms/step - loss: 6.6535 - recall_at_20: 0.3246 - mrr_at_20: 0.0905 - ndcg_at_20: 0.1416 - map_at_20: 0.0905 - precision_at_20: 0.0162 - regularization_loss: 0.0000e+00 - loss_batch: 6.6479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:51:54.265885: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model_4/sequential_block_24/xl_net_block_4/sequential_block_27/replace_masked_embeddings_4/RaggedWhere/Assert/AssertGuard/branch_executed/_529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 9s 49ms/step - loss: 8.3766 - recall_at_20: 0.2347 - mrr_at_20: 0.0690 - ndcg_at_20: 0.1050 - map_at_20: 0.0690 - precision_at_20: 0.0117 - regularization_loss: 0.0000e+00 - loss_batch: 8.3785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 8.376553535461426,\n",
       " 'recall_at_20': 0.23227383196353912,\n",
       " 'mrr_at_20': 0.0675581842660904,\n",
       " 'ndcg_at_20': 0.10343420505523682,\n",
       " 'map_at_20': 0.0675581842660904,\n",
       " 'precision_at_20': 0.011613693088293076,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 8.46284294128418}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformer, xlnet_block = get_model()\n",
    "model_transformer.fit(\n",
    "    train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epoch,\n",
    "    pre=mm.SequenceMaskRandom(schema=train.schema, target=target, transformer=xlnet_block)\n",
    ")\n",
    "\n",
    "predict_last = mm.SequencePredictLast(schema=valid.schema, target=target, transformer=xlnet_block)\n",
    "model_transformer.evaluate(\n",
    "    valid,\n",
    "    batch_size=batch_size,\n",
    "    pre=predict_last,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195f16d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
