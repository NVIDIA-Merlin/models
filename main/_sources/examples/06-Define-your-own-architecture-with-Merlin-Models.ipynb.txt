{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9be6e1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399da61",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_models_06-define-your-own-architecture-with-merlin-models/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Taking the Next Step with Merlin Models: Define Your Own Architecture\n",
    "\n",
    "This notebook is created using the latest stable [merlin-tensorflow](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags) container. \n",
    "\n",
    "In [Iterating over Deep Learning Models using Merlin Models](https://nvidia-merlin.github.io/models/main/examples/03-Exploring-different-models.html), we conducted a benchmark of standard and deep learning-based ranking models provided by the high-level Merlin Models API. The library also includes the standard components of deep learning that let recsys practitioners and researchers to define custom models, train and export them for inference.\n",
    "\n",
    "\n",
    "In this example, we combine pre-existing blocks and demonstrate how to create the [DLRM](https://arxiv.org/abs/1906.00091) architecture.\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "- Understand the building blocks of Merlin Models\n",
    "- Define a model architecture from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33d04c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Introduction to Merlin-models core building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75302fa1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The [Block](https://nvidia-merlin.github.io/models/review/pr-294/generated/merlin.models.tf.Block.html#merlin.models.tf.Block) is the core abstraction in Merlin Models and is the class from which all blocks inherit.\n",
    "The class extends the [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) base class and implements a number of properties that simplify the creation of custom blocks and models. These properties include the `Schema` object for determining the embedding dimensions, input shapes, and output shapes. Additionally, the `Block` has a `ModelContext` instance to store and retrieve public variables and share them with other blocks in the same model as additional meta-data. \n",
    "\n",
    "Before deep-diving into the definition of the DLRM architecture, let's start by listing the core components you need to know to define a model from scratch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd2a3f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Features Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3e494",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "They include input blocks to process various inputs based on their types and shapes. Merlin Models supports three main blocks: \n",
    "- `EmbeddingFeatures`: Input block for embedding-lookups for categorical features.\n",
    "- `SequenceEmbeddingFeatures`: Input block for embedding-lookups for sequential categorical features (3D tensors).\n",
    "- `ContinuousFeatures`: Input block for continuous features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9e7bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Transformations Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee72b1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "They include various operators commonly used to transform tensors in various parts of the model, such as: \n",
    "\n",
    "- `ToDense`: It takes a dictionary of raw input tensors and transforms the sparse tensors into dense tensors.\n",
    "- `L2Norm`: It takes a single or a dictionary of hidden tensors and applies an L2-normalization along a given axis. \n",
    "- `LogitsTemperatureScaler`: It scales the output tensor of predicted logits to lower the model's confidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d24c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Aggregations Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4519b6b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "They include common aggregation operations to combine multiple tensors, such as:\n",
    "- `ConcatFeatures`: Concatenate dictionary of tensors along a given dimension.\n",
    "- `StackFeatures`: Stack dictionary of tensors along a given dimension.\n",
    "- `CosineSimilarity`: Calculate the cosine similarity between two tensors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc30b6d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Connects Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266112b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The base class `Block` implements different connects methods that control how to link a given block to other blocks: \n",
    "\n",
    "- `connect`: Connect the block to other blocks sequentially. The output is a tensor returned by the last block. \n",
    "- `connect_branch`: Link the block to other blocks in parallel. The output is a dictionary containing the output tensor of each block.\n",
    "- `connect_with_shortcut`: Connect the block to other blocks sequentially and apply a skip connection with the block's output. \n",
    "- `connect_with_residual`: Connect the block to other blocks sequentially and apply a residual sum with the block's output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60fe383",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Prediction Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673a0a5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merlin Models introduces the `PredictionTask` layer that defines the necessary blocks and transformation operations to compute the final prediction scores. It also provides the default loss and metrics related to the given prediction task.\\\n",
    "Merlin Models supports the core tasks:  `BinaryClassificationTask`, `MultiClassClassificationTask`, and`RegressionTask`. In addition to the preceding tasks, Merlin Models provides tasks that are specific to recommender systems: `NextItemPredictionTask`, and `ItemRetrievalTask`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd80356",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Implement the DLRM model with MovieLens-1M data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eaae67",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we have introduced the core blocks of Merlin Models, let's take a look at how we can combine them to define the DLRM architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863eb0c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 20:45:41.774416: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-19 20:45:44.478032: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-19 20:45:44.478054: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-19 20:45:44.509373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import merlin.models.tf as mm\n",
    "\n",
    "from merlin.datasets.entertainment import get_movielens\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9457f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use the `get_movielens` function to download, extract, and preprocess the MovieLens 1M  dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c342cb6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alaiacano/.pyenv/versions/3.8.10/envs/merlin38/lib/python3.8/site-packages/merlin/io/dataset.py:251: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/home/alaiacano/.pyenv/versions/3.8.10/envs/merlin38/lib/python3.8/site-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/home/alaiacano/.pyenv/versions/3.8.10/envs/merlin38/lib/python3.8/site-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = os.getenv(\"DATA_FOLDER\", \"workspace/data\")\n",
    "train, valid = get_movielens(variant=\"ml-1m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ccab6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We display the first five rows of the validation data and use them to check the outputs of each building block: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3da2e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>TE_age_rating</th>\n",
       "      <th>TE_gender_rating</th>\n",
       "      <th>TE_occupation_rating</th>\n",
       "      <th>TE_zipcode_rating</th>\n",
       "      <th>TE_movieId_rating</th>\n",
       "      <th>TE_userId_rating</th>\n",
       "      <th>rating_binary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>624</td>\n",
       "      <td>773</td>\n",
       "      <td>772</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.568176</td>\n",
       "      <td>-0.570641</td>\n",
       "      <td>-0.087290</td>\n",
       "      <td>1.003093</td>\n",
       "      <td>0.057056</td>\n",
       "      <td>2.006259</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>449</td>\n",
       "      <td>0.782921</td>\n",
       "      <td>-0.549865</td>\n",
       "      <td>0.623558</td>\n",
       "      <td>0.068490</td>\n",
       "      <td>1.102673</td>\n",
       "      <td>0.660300</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1163</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>[3, 5]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>659</td>\n",
       "      <td>-0.544132</td>\n",
       "      <td>-0.555616</td>\n",
       "      <td>-0.111193</td>\n",
       "      <td>-0.621290</td>\n",
       "      <td>0.414818</td>\n",
       "      <td>0.905115</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2569</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>[1, 6]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>388</td>\n",
       "      <td>-0.505204</td>\n",
       "      <td>-0.549865</td>\n",
       "      <td>1.310142</td>\n",
       "      <td>-1.092174</td>\n",
       "      <td>0.122365</td>\n",
       "      <td>-0.706886</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>649</td>\n",
       "      <td>1137</td>\n",
       "      <td>1139</td>\n",
       "      <td>[9, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>509</td>\n",
       "      <td>-0.505204</td>\n",
       "      <td>-0.549865</td>\n",
       "      <td>1.438719</td>\n",
       "      <td>-0.622696</td>\n",
       "      <td>-1.186149</td>\n",
       "      <td>-0.500930</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  title  genres  gender  age  occupation  zipcode  \\\n",
       "0     624      773    772     [2]       1    2           8       32   \n",
       "1    1957       22     22     [1]       1    4           9      449   \n",
       "2    1163       71     71  [3, 5]       1    1           4      659   \n",
       "3    2569      327    327  [1, 6]       1    1          12      388   \n",
       "4     649     1137   1139  [9, 4]       1    1          11      509   \n",
       "\n",
       "   TE_age_rating  TE_gender_rating  TE_occupation_rating  TE_zipcode_rating  \\\n",
       "0       0.568176         -0.570641             -0.087290           1.003093   \n",
       "1       0.782921         -0.549865              0.623558           0.068490   \n",
       "2      -0.544132         -0.555616             -0.111193          -0.621290   \n",
       "3      -0.505204         -0.549865              1.310142          -1.092174   \n",
       "4      -0.505204         -0.549865              1.438719          -0.622696   \n",
       "\n",
       "   TE_movieId_rating  TE_userId_rating  rating_binary  rating  \n",
       "0           0.057056          2.006259              1     4.0  \n",
       "1           1.102673          0.660300              1     5.0  \n",
       "2           0.414818          0.905115              0     2.0  \n",
       "3           0.122365         -0.706886              0     3.0  \n",
       "4          -1.186149         -0.500930              0     3.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2044225b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We convert the first five rows of the `valid` dataset to a batch of input tensors:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932d878e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int32, numpy=\n",
       "array([[ 624],\n",
       "       [1957],\n",
       "       [1163],\n",
       "       [2569],\n",
       "       [ 649]], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = mm.sample_batch(valid, batch_size=5, shuffle=False, include_targets=False)\n",
    "batch[\"userId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ea3e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define the inputs block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66aa30",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For the sake of simplicity, let's create a schema with a subset of the following continuous and categorical features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0534f548",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sub_schema = train.schema.select_by_name(\n",
    "    [\n",
    "        \"userId\",\n",
    "        \"movieId\",\n",
    "        \"title\",\n",
    "        \"gender\",\n",
    "        \"TE_zipcode_rating\",\n",
    "        \"TE_movieId_rating\",\n",
    "        \"rating_binary\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bc018",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define the continuous layer based on the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a9dede5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "continuous_block = mm.ContinuousFeatures.from_schema(sub_schema, tags=Tags.CONTINUOUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16320ff1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We display the output tensor of the continuous block by using the data from the first batch. We can see the raw tensors of the continuous features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed672405",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TE_zipcode_rating': <tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       " array([[ 1.0030926 ],\n",
       "        [ 0.06849001],\n",
       "        [-0.6212898 ],\n",
       "        [-1.092174  ],\n",
       "        [-0.6226964 ]], dtype=float32)>,\n",
       " 'TE_movieId_rating': <tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       " array([[ 0.05705612],\n",
       "        [ 1.1026733 ],\n",
       "        [ 0.41481796],\n",
       "        [ 0.12236513],\n",
       "        [-1.1861489 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_block(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc168c68",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We connect the continuous block to a `MLPBlock` instance to project them into the same dimensionality as the embedding width of categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98d68924",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_continuous_block = continuous_block.connect(mm.MLPBlock([64]))\n",
    "deep_continuous_block(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbe7006",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define the categorical embedding block based on the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c291ab58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embedding_block = mm.EmbeddingFeatures.from_schema(sub_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453628f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We display the output tensor of the categorical embedding block using the data from the first batch. We can see the embeddings tensors of categorical features with a default dimension of 64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc0e02da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['userId', 'movieId', 'title', 'gender']), TensorShape([5, 64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embedding_block(batch)\n",
    "embeddings.keys(), embeddings[\"userId\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a6d1b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's store the continuous and categorical representations in a single dictionary using a `ParallelBlock` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f2b0a00",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shapes of DLRM input block:\n",
      "\tuserId : (5, 64)\n",
      "\tmovieId : (5, 64)\n",
      "\ttitle : (5, 64)\n",
      "\tgender : (5, 64)\n",
      "\tdeep_continuous : (5, 64)\n"
     ]
    }
   ],
   "source": [
    "dlrm_input_block = mm.ParallelBlock(\n",
    "    {\"embeddings\": embedding_block, \"deep_continuous\": deep_continuous_block}\n",
    ")\n",
    "print(\"Output shapes of DLRM input block:\")\n",
    "for key, val in dlrm_input_block(batch).items():\n",
    "    print(\"\\t%s : %s\" % (key, val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33287714",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By looking at the output, we can see that the `ParallelBlock` class applies embedding and continuous blocks, in parallel, to the same input batch.  Additionally, it merges the resulting tensors into one dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fd103",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define the interaction block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a34684",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we have a vector representation of each input feature, we will create the DLRM interaction block. It consists of three operations: \n",
    "- Apply a dot product between all continuous and categorical features to learn pairwise interactions. \n",
    "- Concat the resulting pairwise interaction with the deep representation of conitnuous features (skip-connection). \n",
    "- Apply an `MLPBlock` with a series of dense layers to the concatenated tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f895068",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, we use the `connect_with_shortcut` method to create first two operations of the DLRM interaction block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8218fc1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from merlin.models.tf.blocks.dlrm import DotProductInteractionBlock\n",
    "\n",
    "dlrm_interaction = dlrm_input_block.connect_with_shortcut(\n",
    "    DotProductInteractionBlock(), shortcut_filter=mm.Filter(\"deep_continuous\"), aggregation=\"concat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522dce49",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `Filter` operation allows us to select the `deep_continuous` tensor from the `dlrm_input_block` outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a613b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following diagram provides a visualization of the operations that we constructed in the `dlrm_interaction` object.\n",
    "\n",
    "<img src=\"./images/residual_interaction.png\"  width=\"30%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2671a01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 74), dtype=float32, numpy=\n",
       "array([[ 0.00000000e+00,  6.82826638e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.80383995e-01,  5.98768219e-02,\n",
       "         2.09976867e-01,  1.44710079e-01,  1.28024677e-02,\n",
       "         8.87025297e-02,  9.24035460e-02,  1.57566026e-01,\n",
       "         1.41247764e-01,  7.41617829e-02,  1.01561561e-01,\n",
       "         0.00000000e+00,  5.23385704e-02,  0.00000000e+00,\n",
       "         2.92576909e-01,  0.00000000e+00,  1.73170507e-01,\n",
       "         2.37197266e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.43107140e-01,  1.05558299e-01,  0.00000000e+00,\n",
       "         1.96579084e-01,  0.00000000e+00,  1.02332458e-01,\n",
       "         0.00000000e+00,  2.33163089e-01,  1.00891396e-01,\n",
       "         0.00000000e+00,  1.51944682e-01,  9.00887847e-02,\n",
       "         0.00000000e+00,  1.43880740e-01,  2.64524519e-01,\n",
       "         2.50956304e-02,  1.80838302e-01,  0.00000000e+00,\n",
       "         2.35574916e-01,  0.00000000e+00,  1.50875002e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.94353068e-01,  9.61890519e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  3.77075449e-02,  9.26294252e-02,\n",
       "         2.31126264e-01,  0.00000000e+00,  1.36887029e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.97133660e-01,\n",
       "         8.71547014e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         8.77225325e-02,  5.43038687e-03,  5.40966317e-02,\n",
       "         2.10780278e-02,  6.36962652e-02, -4.73170634e-03,\n",
       "         4.31833440e-04, -2.61518750e-02,  5.78600273e-04,\n",
       "         3.22858384e-03, -1.12014860e-02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  6.47013634e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.34879330e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.98461556e-01,\n",
       "         1.75109744e-01,  3.08581203e-01,  2.01059490e-01,\n",
       "         0.00000000e+00,  2.86171734e-01,  1.20401457e-01,\n",
       "         3.16995412e-01,  8.87140930e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  7.17573091e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.40364641e-01,\n",
       "         0.00000000e+00,  2.17864458e-02,  2.50810742e-01,\n",
       "         1.97104260e-01,  0.00000000e+00,  1.60598055e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  8.58442709e-02,\n",
       "         2.45450616e-01,  2.51366884e-01,  0.00000000e+00,\n",
       "         2.41251349e-01,  5.72509654e-02,  1.84434533e-01,\n",
       "         1.03250876e-01,  7.17810914e-02,  1.37276351e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.95059383e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.27920657e-01,\n",
       "         2.05035344e-01,  0.00000000e+00,  2.36066252e-01,\n",
       "         4.05495577e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -2.38138139e-02,  1.08807432e-02,\n",
       "         7.77303847e-03, -8.50100294e-02,  4.98681329e-03,\n",
       "         1.11919511e-02,  2.63783004e-04, -1.12807564e-02,\n",
       "        -1.01519739e-02,  1.61713101e-02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.57255560e-01,\n",
       "         8.98111165e-02,  0.00000000e+00,  5.74663691e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.13988757e-01,\n",
       "         1.43191861e-02,  6.66051209e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  6.92329630e-02,  0.00000000e+00,\n",
       "         2.41790712e-01,  2.46394938e-03,  7.98416510e-02,\n",
       "         0.00000000e+00,  7.82607049e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.71624459e-02,  1.06490739e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.72846913e-01,\n",
       "         0.00000000e+00,  1.03909791e-01,  3.22300903e-02,\n",
       "         5.67845404e-02,  0.00000000e+00,  3.74426208e-02,\n",
       "         2.37422630e-01,  0.00000000e+00,  7.47651095e-03,\n",
       "         1.13228727e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  4.96021621e-02,\n",
       "         0.00000000e+00,  2.84084052e-01,  0.00000000e+00,\n",
       "         1.15308307e-01,  1.02194354e-01,  2.14390516e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.53718740e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  6.09191619e-02,\n",
       "         0.00000000e+00,  2.89969984e-03,  0.00000000e+00,\n",
       "         2.68034309e-01,  8.19996595e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  6.74452633e-02,  6.79842429e-03,\n",
       "         0.00000000e+00, -4.81778830e-02, -1.77667178e-02,\n",
       "         1.82975288e-02, -2.25220341e-02, -2.50900462e-02,\n",
       "        -2.93726847e-02, -1.54160634e-02, -1.31359138e-02,\n",
       "        -4.18730685e-03,  7.02439900e-03],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  2.33091041e-01,\n",
       "         2.16639012e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.60264517e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.43452594e-01,  0.00000000e+00,  1.48931175e-01,\n",
       "         0.00000000e+00,  1.69527099e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  2.11448371e-01,  2.79685080e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.19585860e-01,\n",
       "         0.00000000e+00,  2.02429682e-01,  0.00000000e+00,\n",
       "         1.34652272e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.99382299e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.69278979e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.89442369e-02,\n",
       "         0.00000000e+00,  3.50016952e-01,  0.00000000e+00,\n",
       "         6.85007647e-02,  1.43442661e-01,  2.66930610e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.88728899e-01,\n",
       "         6.13208488e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.49810567e-01,  0.00000000e+00,\n",
       "         3.47220749e-01,  1.57068416e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.88575819e-01,  9.15735289e-02,\n",
       "         0.00000000e+00, -6.22908436e-02, -3.38319782e-03,\n",
       "         1.23800792e-01,  5.01863398e-02, -4.81331954e-03,\n",
       "        -2.04637516e-02, -4.44554165e-03, -1.80508029e-02,\n",
       "        -1.20663578e-02,  2.83019822e-02],\n",
       "       [ 1.51300639e-01,  2.16012716e-01,  4.31782342e-02,\n",
       "         2.45120600e-01,  1.40066464e-02,  0.00000000e+00,\n",
       "         1.38437048e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.02661684e-01,\n",
       "         0.00000000e+00,  1.62780583e-01,  5.45618273e-02,\n",
       "         3.03599149e-01,  4.95723397e-01,  3.50861490e-01,\n",
       "         1.02114871e-01,  0.00000000e+00,  2.14776307e-01,\n",
       "         2.14072213e-01,  1.56319469e-01,  0.00000000e+00,\n",
       "         1.48854032e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.58857539e-01,  0.00000000e+00,\n",
       "         4.05653536e-01,  1.22675776e-01,  4.25197184e-02,\n",
       "         1.12757748e-02,  2.18971923e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.00662389e-01,\n",
       "         0.00000000e+00,  6.85178116e-03,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.33341128e-01,  3.21402609e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  3.84907007e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.16290517e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  2.52411574e-01,  2.16994107e-01,\n",
       "         5.22157736e-02,  2.45120507e-02,  4.00505736e-02,\n",
       "        -4.24136184e-02, -2.03966000e-03,  1.33487843e-02,\n",
       "        -2.18517566e-03, -1.06863603e-02, -2.89479154e-03,\n",
       "        -2.85907798e-02, -3.10467603e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlrm_interaction(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0fe1ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, we project the learned interaction using a series of dense layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adc0c81b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 512), dtype=float32, numpy=\n",
       "array([[0.055957  , 0.0198308 , 0.        , ..., 0.01130124, 0.        ,\n",
       "        0.        ],\n",
       "       [0.0727547 , 0.04420617, 0.03328843, ..., 0.03163406, 0.        ,\n",
       "        0.        ],\n",
       "       [0.03016799, 0.05012683, 0.01152872, ..., 0.03033926, 0.        ,\n",
       "        0.        ],\n",
       "       [0.00409173, 0.0635931 , 0.        , ..., 0.0143235 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.01937133, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_dlrm_interaction = dlrm_interaction.connect(mm.MLPBlock([64, 128, 512]))\n",
    "deep_dlrm_interaction(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51615b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define the Prediction block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd62b7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At this stage, we have created the DLRM block that accepts a dictionary of categorical and continuous tensors as input. The output of this block is the interaction representation vector of shape `512`. The next step is to use this hidden representation to conduct a given prediction task. In our case, we use the label `rating_binary` and the objective is: to predict if a user `A` will give a high rating to a movie `B` or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88115591",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use the `BinaryClassificationTask` class and evaluate the performances using the `AUC` metric. We also use the `LogitsTemperatureScaler` block as a pre-transformation operation that scales the logits returned by the task before computing the loss and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42ad7eb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from merlin.models.tf.transforms.bias import LogitsTemperatureScaler\n",
    "\n",
    "binary_task = mm.BinaryClassificationTask(\n",
    "    sub_schema,\n",
    "    pre=LogitsTemperatureScaler(temperature=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4912355",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define, train, and evaluate the final DLRM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44495a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We connect the deep DLRM interaction to the binary task and the method automatically generates the `Model` class for us.\n",
    "We note that the `Model` class inherits from [tf.keras.Model](https://keras.io/api/models/model/) class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87df4596",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merlin.models.tf.models.base.Model"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mm.Model(deep_dlrm_interaction, binary_task)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e280dc4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We train the model using the built-in tf.keras `fit` method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1de1489c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 20s 16ms/step - loss: 0.6475 - auc: 0.7244 - regularization_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faa133ecd00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", metrics=[tf.keras.metrics.AUC()])\n",
    "model.fit(train, batch_size=1024, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c3dacb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's check out the model evaluation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07c8ba33",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 3s 9ms/step - loss: 0.6390 - auc: 0.7241 - regularization_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.6389783620834351,\n",
       " 'auc': 0.7241206169128418,\n",
       " 'regularization_loss': 0.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = model.evaluate(valid, batch_size=1024, return_dict=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7e334",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that the `evaluate()` progress bar shows the loss score for every batch, whereas the final loss stored in the dictionary represents the total loss across all batches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d793d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Save the model so we can use it for serving predictions in production or for resuming training with new observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb89d842",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((PredictionOutput(predictions=TensorSpec(shape=(None, 1), dtype=tf.float32, name='outputs/predictions'), targets=TensorSpec(shape=(None, 1), dtype=tf.float32, name='outputs/targets'), positive_item_ids=None, label_relevant_counts=None, valid_negatives_mask=None, negative_item_ids=None, sample_weight=None), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7faa33dea910>), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((PredictionOutput(predictions=TensorSpec(shape=(None, 1), dtype=tf.float32, name='outputs/predictions'), targets=TensorSpec(shape=(None, 1), dtype=tf.float32, name='outputs/targets'), positive_item_ids=None, label_relevant_counts=None, valid_negatives_mask=None, negative_item_ids=None, sample_weight=None), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7faa33dea910>), {}).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) TE_age_rating, TE_gender_rating, TE_movieId_rating, TE_occupation_rating, TE_userId_rating, TE_zipcode_rating, movieId, userId with unsupported characters which will be renamed to te_age_rating, te_gender_rating, te_movieid_rating, te_occupation_rating, te_userid_rating, te_zipcode_rating, movieid, userid in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((PredictionOutput(predictions=TensorSpec(shape=(None, 1), dtype=tf.float32, name='outputs/predictions'), targets=TensorSpec(shape=(None, 1), dtype=tf.float32, name='outputs/targets'), positive_item_ids=None, label_relevant_counts=None, valid_negatives_mask=None, negative_item_ids=None, sample_weight=None), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7faa33dea910>), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((PredictionOutput(predictions=TensorSpec(shape=(None, 1), dtype=tf.float32, name='outputs/predictions'), targets=TensorSpec(shape=(None, 1), dtype=tf.float32, name='outputs/targets'), positive_item_ids=None, label_relevant_counts=None, valid_negatives_mask=None, negative_item_ids=None, sample_weight=None), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7faa33dea910>), {}).\n",
      "WARNING:absl:Found untraced functions such as train_compute_metrics, model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, logits_temperature_scaler_layer_call_fn, logits_temperature_scaler_layer_call_and_return_conditional_losses while saving (showing 5 of 67). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace/data/custom_dlrm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace/data/custom_dlrm/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(DATA_FOLDER, \"custom_dlrm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d4aaa3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion \n",
    "\n",
    "Merlin Models provides common and state-of-the-art RecSys architectures in a high-level API as well as all the required low-level building blocks for you to create your own architecture (input blocks, MLP layers, prediction tasks, loss functions, etc.). In this example, we explored a subset of these pre-existing blocks to create the DLRM model, but you can view our [documentation](https://nvidia-merlin.github.io/models/main/) to discover more. You can also [contribute](https://github.com/NVIDIA-Merlin/models/blob/main/CONTRIBUTING.md) to the library by submitting new RecSys architectures and custom building Blocks.  \n",
    "\n",
    "\n",
    "\n",
    "## Next steps\n",
    "To learn more about how to deploy the trained DLRM model, please visit [Merlin Systems](https://github.com/NVIDIA-Merlin/systems) library and execute the `Serving-Ranking-Models-With-Merlin-Systems.ipynb` notebook that deploys an ensemble of a [NVTabular](https://github.com/NVIDIA-Merlin/NVTabular) Workflow and a trained model from Merlin Models to [Triton Inference Server](https://github.com/triton-inference-server/server). \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('merlin38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "merlin": {
   "containers": [
    "nvcr.io/nvidia/merlin/merlin-tensorflow:latest"
   ]
  },
  "vscode": {
   "interpreter": {
    "hash": "a398807c5c2ed8e5ff9d9890488d007fa99cbabcec733962e21659a28c5da99b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
