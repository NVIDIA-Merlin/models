<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Taking the Next Step with Merlin Models: Define Your Own Architecture &mdash; Merlin Models  documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/mystnb.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="API Documentation" href="../api.html" />
    <link rel="prev" title="Two-Stage Recommender Systems" href="05-Retrieval-Model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Merlin Models
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models_overview.html">Standard Models: Overview</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Example Notebooks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#inventory">Inventory</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#running-the-example-notebooks">Running the Example Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="01-Getting-started.html">Getting Started with Merlin Models: Develop a Model for MovieLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="02-Merlin-Models-and-NVTabular-integration.html">From ETL to Training RecSys models - NVTabular and Merlin Models integrated example</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-Exploring-different-models.html">Iterating over Deep Learning Models using Merlin Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-Exporting-ranking-models.html">Exporting Ranking Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="05-Retrieval-Model.html">Two-Stage Recommender Systems</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Taking the Next Step with Merlin Models: Define Your Own Architecture</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../additional_resources.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Merlin Models</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Merlin Models Example Notebooks</a> &raquo;</li>
      <li>Taking the Next Step with Merlin Models: Define Your Own Architecture</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright 2021 NVIDIA Corporation. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ================================</span>
</pre></div>
</div>
</div>
</div>
<img alt="https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_models_06-define-your-own-architecture-with-merlin-models/nvidia_logo.png" src="https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_models_06-define-your-own-architecture-with-merlin-models/nvidia_logo.png" />
<div class="tex2jax_ignore mathjax_ignore section" id="taking-the-next-step-with-merlin-models-define-your-own-architecture">
<h1>Taking the Next Step with Merlin Models: Define Your Own Architecture<a class="headerlink" href="#taking-the-next-step-with-merlin-models-define-your-own-architecture" title="Permalink to this headline"></a></h1>
<p>This notebook is created using the latest stable <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> container.</p>
<p>In <a class="reference external" href="https://nvidia-merlin.github.io/models/main/examples/03-Exploring-different-models.html">Iterating over Deep Learning Models using Merlin Models</a>, we conducted a benchmark of standard and deep learning-based ranking models provided by the high-level Merlin Models API. The library also includes the standard components of deep learning that let recsys practitioners and researchers to define custom models, train and export them for inference.</p>
<p>In this example, we combine pre-existing blocks and demonstrate how to create the <a class="reference external" href="https://arxiv.org/abs/1906.00091">DLRM</a> architecture.</p>
<div class="section" id="learning-objectives">
<h2>Learning objectives<a class="headerlink" href="#learning-objectives" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>Understand the building blocks of Merlin Models</p></li>
<li><p>Define a model architecture from scratch</p></li>
</ul>
</div>
<div class="section" id="introduction-to-merlin-models-core-building-blocks">
<h2>Introduction to Merlin-models core building blocks<a class="headerlink" href="#introduction-to-merlin-models-core-building-blocks" title="Permalink to this headline"></a></h2>
<p>The <a class="reference external" href="https://nvidia-merlin.github.io/models/review/pr-294/generated/merlin.models.tf.Block.html#merlin.models.tf.Block">Block</a> is the core abstraction in Merlin Models and is the class from which all blocks inherit.
The class extends the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer">tf.keras.layers.Layer</a> base class and implements a number of properties that simplify the creation of custom blocks and models. These properties include the <code class="docutils literal notranslate"><span class="pre">Schema</span></code> object for determining the embedding dimensions, input shapes, and output shapes. Additionally, the <code class="docutils literal notranslate"><span class="pre">Block</span></code> has a <code class="docutils literal notranslate"><span class="pre">ModelContext</span></code> instance to store and retrieve public variables and share them with other blocks in the same model as additional meta-data.</p>
<p>Before deep-diving into the definition of the DLRM architecture, let’s start by listing the core components you need to know to define a model from scratch:</p>
<div class="section" id="features-blocks">
<h3>Features Blocks<a class="headerlink" href="#features-blocks" title="Permalink to this headline"></a></h3>
<p>They include input blocks to process various inputs based on their types and shapes. Merlin Models supports three main blocks:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code>: Input block for embedding-lookups for categorical features.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures</span></code>: Input block for embedding-lookups for sequential categorical features (3D tensors).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures</span></code>: Input block for continuous features.</p></li>
</ul>
</div>
<div class="section" id="transformations-blocks">
<h3>Transformations Blocks<a class="headerlink" href="#transformations-blocks" title="Permalink to this headline"></a></h3>
<p>They include various operators commonly used to transform tensors in various parts of the model, such as:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ToDense</span></code>: It takes a dictionary of raw input tensors and transforms the sparse tensors into dense tensors.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">L2Norm</span></code>: It takes a single or a dictionary of hidden tensors and applies an L2-normalization along a given axis.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LogitsTemperatureScaler</span></code>: It scales the output tensor of predicted logits to lower the model’s confidence.</p></li>
</ul>
</div>
<div class="section" id="aggregations-blocks">
<h3>Aggregations Blocks<a class="headerlink" href="#aggregations-blocks" title="Permalink to this headline"></a></h3>
<p>They include common aggregation operations to combine multiple tensors, such as:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ConcatFeatures</span></code>: Concatenate dictionary of tensors along a given dimension.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">StackFeatures</span></code>: Stack dictionary of tensors along a given dimension.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CosineSimilarity</span></code>: Calculate the cosine similarity between two tensors.</p></li>
</ul>
</div>
<div class="section" id="connects-methods">
<h3>Connects Methods<a class="headerlink" href="#connects-methods" title="Permalink to this headline"></a></h3>
<p>The base class <code class="docutils literal notranslate"><span class="pre">Block</span></code> implements different connects methods that control how to link a given block to other blocks:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">connect</span></code>: Connect the block to other blocks sequentially. The output is a tensor returned by the last block.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">connect_branch</span></code>: Link the block to other blocks in parallel. The output is a dictionary containing the output tensor of each block.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">connect_with_shortcut</span></code>: Connect the block to other blocks sequentially and apply a skip connection with the block’s output.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">connect_with_residual</span></code>: Connect the block to other blocks sequentially and apply a residual sum with the block’s output.</p></li>
</ul>
</div>
<div class="section" id="prediction-tasks">
<h3>Prediction Tasks<a class="headerlink" href="#prediction-tasks" title="Permalink to this headline"></a></h3>
<p>Merlin Models introduces the <code class="docutils literal notranslate"><span class="pre">PredictionTask</span></code> layer that defines the necessary blocks and transformation operations to compute the final prediction scores. It also provides the default loss and metrics related to the given prediction task.<br />
Merlin Models supports the core tasks:  <code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask</span></code>, <code class="docutils literal notranslate"><span class="pre">MultiClassClassificationTask</span></code>, and<code class="docutils literal notranslate"><span class="pre">RegressionTask</span></code>. In addition to the preceding tasks, Merlin Models provides tasks that are specific to recommender systems: <code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask</span></code>, and <code class="docutils literal notranslate"><span class="pre">ItemRetrievalTask</span></code>.</p>
</div>
</div>
<div class="section" id="implement-the-dlrm-model-with-movielens-1m-data">
<h2>Implement the DLRM model with MovieLens-1M data<a class="headerlink" href="#implement-the-dlrm-model-with-movielens-1m-data" title="Permalink to this headline"></a></h2>
<p>Now that we have introduced the core blocks of Merlin Models, let’s take a look at how we can combine them to define the DLRM architecture:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">merlin.models.tf</span> <span class="k">as</span> <span class="nn">mm</span>

<span class="kn">from</span> <span class="nn">merlin.datasets.entertainment</span> <span class="kn">import</span> <span class="n">get_movielens</span>
<span class="kn">from</span> <span class="nn">merlin.schema.tags</span> <span class="kn">import</span> <span class="n">Tags</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-10-19 20:45:41.774416: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-10-19 20:45:44.478032: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudnn.so.8&#39;; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2022-10-19 20:45:44.478054: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2022-10-19 20:45:44.509373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div>
</div>
</div>
</div>
<p>We use the <code class="docutils literal notranslate"><span class="pre">get_movielens</span></code> function to download, extract, and preprocess the MovieLens 1M  dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DATA_FOLDER</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;DATA_FOLDER&quot;</span><span class="p">,</span> <span class="s2">&quot;workspace/data&quot;</span><span class="p">)</span>
<span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">get_movielens</span><span class="p">(</span><span class="n">variant</span><span class="o">=</span><span class="s2">&quot;ml-1m&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/alaiacano/.pyenv/versions/3.8.10/envs/merlin38/lib/python3.8/site-packages/merlin/io/dataset.py:251: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!
  warnings.warn(
/home/alaiacano/.pyenv/versions/3.8.10/envs/merlin38/lib/python3.8/site-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.USER: &#39;user&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].
  warnings.warn(
/home/alaiacano/.pyenv/versions/3.8.10/envs/merlin38/lib/python3.8/site-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.ITEM: &#39;item&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<p>We display the first five rows of the validation data and use them to check the outputs of each building block:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">valid</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>title</th>
      <th>genres</th>
      <th>gender</th>
      <th>age</th>
      <th>occupation</th>
      <th>zipcode</th>
      <th>TE_age_rating</th>
      <th>TE_gender_rating</th>
      <th>TE_occupation_rating</th>
      <th>TE_zipcode_rating</th>
      <th>TE_movieId_rating</th>
      <th>TE_userId_rating</th>
      <th>rating_binary</th>
      <th>rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>624</td>
      <td>773</td>
      <td>772</td>
      <td>[2]</td>
      <td>1</td>
      <td>2</td>
      <td>8</td>
      <td>32</td>
      <td>0.568176</td>
      <td>-0.570641</td>
      <td>-0.087290</td>
      <td>1.003093</td>
      <td>0.057056</td>
      <td>2.006259</td>
      <td>1</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1957</td>
      <td>22</td>
      <td>22</td>
      <td>[1]</td>
      <td>1</td>
      <td>4</td>
      <td>9</td>
      <td>449</td>
      <td>0.782921</td>
      <td>-0.549865</td>
      <td>0.623558</td>
      <td>0.068490</td>
      <td>1.102673</td>
      <td>0.660300</td>
      <td>1</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1163</td>
      <td>71</td>
      <td>71</td>
      <td>[3, 5]</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
      <td>659</td>
      <td>-0.544132</td>
      <td>-0.555616</td>
      <td>-0.111193</td>
      <td>-0.621290</td>
      <td>0.414818</td>
      <td>0.905115</td>
      <td>0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2569</td>
      <td>327</td>
      <td>327</td>
      <td>[1, 6]</td>
      <td>1</td>
      <td>1</td>
      <td>12</td>
      <td>388</td>
      <td>-0.505204</td>
      <td>-0.549865</td>
      <td>1.310142</td>
      <td>-1.092174</td>
      <td>0.122365</td>
      <td>-0.706886</td>
      <td>0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>649</td>
      <td>1137</td>
      <td>1139</td>
      <td>[9, 4]</td>
      <td>1</td>
      <td>1</td>
      <td>11</td>
      <td>509</td>
      <td>-0.505204</td>
      <td>-0.549865</td>
      <td>1.438719</td>
      <td>-0.622696</td>
      <td>-1.186149</td>
      <td>-0.500930</td>
      <td>0</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We convert the first five rows of the <code class="docutils literal notranslate"><span class="pre">valid</span></code> dataset to a batch of input tensors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">sample_batch</span><span class="p">(</span><span class="n">valid</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">include_targets</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">batch</span><span class="p">[</span><span class="s2">&quot;userId&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(5, 1), dtype=int32, numpy=
array([[ 624],
       [1957],
       [1163],
       [2569],
       [ 649]], dtype=int32)&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="define-the-inputs-block">
<h3>Define the inputs block<a class="headerlink" href="#define-the-inputs-block" title="Permalink to this headline"></a></h3>
<p>For the sake of simplicity, let’s create a schema with a subset of the following continuous and categorical features:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sub_schema</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">select_by_name</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="s2">&quot;userId&quot;</span><span class="p">,</span>
        <span class="s2">&quot;movieId&quot;</span><span class="p">,</span>
        <span class="s2">&quot;title&quot;</span><span class="p">,</span>
        <span class="s2">&quot;gender&quot;</span><span class="p">,</span>
        <span class="s2">&quot;TE_zipcode_rating&quot;</span><span class="p">,</span>
        <span class="s2">&quot;TE_movieId_rating&quot;</span><span class="p">,</span>
        <span class="s2">&quot;rating_binary&quot;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We define the continuous layer based on the schema:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">continuous_block</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">ContinuousFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span><span class="n">sub_schema</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="n">Tags</span><span class="o">.</span><span class="n">CONTINUOUS</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We display the output tensor of the continuous block by using the data from the first batch. We can see the raw tensors of the continuous features:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">continuous_block</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;TE_zipcode_rating&#39;: &lt;tf.Tensor: shape=(5, 1), dtype=float32, numpy=
 array([[ 1.0030926 ],
        [ 0.06849001],
        [-0.6212898 ],
        [-1.092174  ],
        [-0.6226964 ]], dtype=float32)&gt;,
 &#39;TE_movieId_rating&#39;: &lt;tf.Tensor: shape=(5, 1), dtype=float32, numpy=
 array([[ 0.05705612],
        [ 1.1026733 ],
        [ 0.41481796],
        [ 0.12236513],
        [-1.1861489 ]], dtype=float32)&gt;}
</pre></div>
</div>
</div>
</div>
<p>We connect the continuous block to a <code class="docutils literal notranslate"><span class="pre">MLPBlock</span></code> instance to project them into the same dimensionality as the embedding width of categorical features:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deep_continuous_block</span> <span class="o">=</span> <span class="n">continuous_block</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">mm</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">64</span><span class="p">]))</span>
<span class="n">deep_continuous_block</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TensorShape([5, 64])
</pre></div>
</div>
</div>
</div>
<p>We define the categorical embedding block based on the schema:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding_block</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">EmbeddingFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span><span class="n">sub_schema</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We display the output tensor of the categorical embedding block using the data from the first batch. We can see the embeddings tensors of categorical features with a default dimension of 64:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">embedding_block</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="n">embeddings</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">embeddings</span><span class="p">[</span><span class="s2">&quot;userId&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(dict_keys([&#39;userId&#39;, &#39;movieId&#39;, &#39;title&#39;, &#39;gender&#39;]), TensorShape([5, 64]))
</pre></div>
</div>
</div>
</div>
<p>Let’s store the continuous and categorical representations in a single dictionary using a <code class="docutils literal notranslate"><span class="pre">ParallelBlock</span></code> instance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dlrm_input_block</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">ParallelBlock</span><span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;embeddings&quot;</span><span class="p">:</span> <span class="n">embedding_block</span><span class="p">,</span> <span class="s2">&quot;deep_continuous&quot;</span><span class="p">:</span> <span class="n">deep_continuous_block</span><span class="p">}</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output shapes of DLRM input block:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">dlrm_input_block</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">%s</span><span class="s2"> : </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Output shapes of DLRM input block:
	userId : (5, 64)
	movieId : (5, 64)
	title : (5, 64)
	gender : (5, 64)
	deep_continuous : (5, 64)
</pre></div>
</div>
</div>
</div>
<p>By looking at the output, we can see that the <code class="docutils literal notranslate"><span class="pre">ParallelBlock</span></code> class applies embedding and continuous blocks, in parallel, to the same input batch.  Additionally, it merges the resulting tensors into one dictionary.</p>
</div>
<div class="section" id="define-the-interaction-block">
<h3>Define the interaction block<a class="headerlink" href="#define-the-interaction-block" title="Permalink to this headline"></a></h3>
<p>Now that we have a vector representation of each input feature, we will create the DLRM interaction block. It consists of three operations:</p>
<ul class="simple">
<li><p>Apply a dot product between all continuous and categorical features to learn pairwise interactions.</p></li>
<li><p>Concat the resulting pairwise interaction with the deep representation of conitnuous features (skip-connection).</p></li>
<li><p>Apply an <code class="docutils literal notranslate"><span class="pre">MLPBlock</span></code> with a series of dense layers to the concatenated tensor.</p></li>
</ul>
<p>First, we use the <code class="docutils literal notranslate"><span class="pre">connect_with_shortcut</span></code> method to create first two operations of the DLRM interaction block:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.models.tf.blocks.dlrm</span> <span class="kn">import</span> <span class="n">DotProductInteractionBlock</span>

<span class="n">dlrm_interaction</span> <span class="o">=</span> <span class="n">dlrm_input_block</span><span class="o">.</span><span class="n">connect_with_shortcut</span><span class="p">(</span>
    <span class="n">DotProductInteractionBlock</span><span class="p">(),</span> <span class="n">shortcut_filter</span><span class="o">=</span><span class="n">mm</span><span class="o">.</span><span class="n">Filter</span><span class="p">(</span><span class="s2">&quot;deep_continuous&quot;</span><span class="p">),</span> <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">Filter</span></code> operation allows us to select the <code class="docutils literal notranslate"><span class="pre">deep_continuous</span></code> tensor from the <code class="docutils literal notranslate"><span class="pre">dlrm_input_block</span></code> outputs.</p>
<p>The following diagram provides a visualization of the operations that we constructed in the <code class="docutils literal notranslate"><span class="pre">dlrm_interaction</span></code> object.</p>
<a class="reference internal image-reference" href="../_images/residual_interaction.png"><img alt="../_images/residual_interaction.png" src="../_images/residual_interaction.png" style="width: 30%;" /></a>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dlrm_interaction</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(5, 74), dtype=float32, numpy=
array([[ 0.00000000e+00,  6.82826638e-02,  0.00000000e+00,
         0.00000000e+00,  1.80383995e-01,  5.98768219e-02,
         2.09976867e-01,  1.44710079e-01,  1.28024677e-02,
         8.87025297e-02,  9.24035460e-02,  1.57566026e-01,
         1.41247764e-01,  7.41617829e-02,  1.01561561e-01,
         0.00000000e+00,  5.23385704e-02,  0.00000000e+00,
         2.92576909e-01,  0.00000000e+00,  1.73170507e-01,
         2.37197266e-03,  0.00000000e+00,  0.00000000e+00,
         2.43107140e-01,  1.05558299e-01,  0.00000000e+00,
         1.96579084e-01,  0.00000000e+00,  1.02332458e-01,
         0.00000000e+00,  2.33163089e-01,  1.00891396e-01,
         0.00000000e+00,  1.51944682e-01,  9.00887847e-02,
         0.00000000e+00,  1.43880740e-01,  2.64524519e-01,
         2.50956304e-02,  1.80838302e-01,  0.00000000e+00,
         2.35574916e-01,  0.00000000e+00,  1.50875002e-01,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         2.94353068e-01,  9.61890519e-02,  0.00000000e+00,
         0.00000000e+00,  3.77075449e-02,  9.26294252e-02,
         2.31126264e-01,  0.00000000e+00,  1.36887029e-01,
         0.00000000e+00,  0.00000000e+00,  1.97133660e-01,
         8.71547014e-02,  0.00000000e+00,  0.00000000e+00,
         8.77225325e-02,  5.43038687e-03,  5.40966317e-02,
         2.10780278e-02,  6.36962652e-02, -4.73170634e-03,
         4.31833440e-04, -2.61518750e-02,  5.78600273e-04,
         3.22858384e-03, -1.12014860e-02],
       [ 0.00000000e+00,  0.00000000e+00,  6.47013634e-02,
         0.00000000e+00,  0.00000000e+00,  2.34879330e-01,
         0.00000000e+00,  0.00000000e+00,  2.98461556e-01,
         1.75109744e-01,  3.08581203e-01,  2.01059490e-01,
         0.00000000e+00,  2.86171734e-01,  1.20401457e-01,
         3.16995412e-01,  8.87140930e-02,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  7.17573091e-02,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  2.40364641e-01,
         0.00000000e+00,  2.17864458e-02,  2.50810742e-01,
         1.97104260e-01,  0.00000000e+00,  1.60598055e-01,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  8.58442709e-02,
         2.45450616e-01,  2.51366884e-01,  0.00000000e+00,
         2.41251349e-01,  5.72509654e-02,  1.84434533e-01,
         1.03250876e-01,  7.17810914e-02,  1.37276351e-01,
         0.00000000e+00,  0.00000000e+00,  2.95059383e-01,
         0.00000000e+00,  0.00000000e+00,  1.27920657e-01,
         2.05035344e-01,  0.00000000e+00,  2.36066252e-01,
         4.05495577e-02,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00, -2.38138139e-02,  1.08807432e-02,
         7.77303847e-03, -8.50100294e-02,  4.98681329e-03,
         1.11919511e-02,  2.63783004e-04, -1.12807564e-02,
        -1.01519739e-02,  1.61713101e-02],
       [ 0.00000000e+00,  0.00000000e+00,  1.57255560e-01,
         8.98111165e-02,  0.00000000e+00,  5.74663691e-02,
         0.00000000e+00,  0.00000000e+00,  1.13988757e-01,
         1.43191861e-02,  6.66051209e-02,  0.00000000e+00,
         0.00000000e+00,  6.92329630e-02,  0.00000000e+00,
         2.41790712e-01,  2.46394938e-03,  7.98416510e-02,
         0.00000000e+00,  7.82607049e-02,  0.00000000e+00,
         0.00000000e+00,  1.71624459e-02,  1.06490739e-01,
         0.00000000e+00,  0.00000000e+00,  1.72846913e-01,
         0.00000000e+00,  1.03909791e-01,  3.22300903e-02,
         5.67845404e-02,  0.00000000e+00,  3.74426208e-02,
         2.37422630e-01,  0.00000000e+00,  7.47651095e-03,
         1.13228727e-02,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  4.96021621e-02,
         0.00000000e+00,  2.84084052e-01,  0.00000000e+00,
         1.15308307e-01,  1.02194354e-01,  2.14390516e-01,
         0.00000000e+00,  0.00000000e+00,  1.53718740e-01,
         0.00000000e+00,  0.00000000e+00,  6.09191619e-02,
         0.00000000e+00,  2.89969984e-03,  0.00000000e+00,
         2.68034309e-01,  8.19996595e-02,  0.00000000e+00,
         0.00000000e+00,  6.74452633e-02,  6.79842429e-03,
         0.00000000e+00, -4.81778830e-02, -1.77667178e-02,
         1.82975288e-02, -2.25220341e-02, -2.50900462e-02,
        -2.93726847e-02, -1.54160634e-02, -1.31359138e-02,
        -4.18730685e-03,  7.02439900e-03],
       [ 0.00000000e+00,  0.00000000e+00,  2.33091041e-01,
         2.16639012e-01,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  3.60264517e-02,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         2.43452594e-01,  0.00000000e+00,  1.48931175e-01,
         0.00000000e+00,  1.69527099e-01,  0.00000000e+00,
         0.00000000e+00,  2.11448371e-01,  2.79685080e-01,
         0.00000000e+00,  0.00000000e+00,  3.19585860e-01,
         0.00000000e+00,  2.02429682e-01,  0.00000000e+00,
         1.34652272e-01,  0.00000000e+00,  0.00000000e+00,
         2.99382299e-01,  0.00000000e+00,  0.00000000e+00,
         1.69278979e-01,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  3.89442369e-02,
         0.00000000e+00,  3.50016952e-01,  0.00000000e+00,
         6.85007647e-02,  1.43442661e-01,  2.66930610e-01,
         0.00000000e+00,  0.00000000e+00,  1.88728899e-01,
         6.13208488e-03,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  1.49810567e-01,  0.00000000e+00,
         3.47220749e-01,  1.57068416e-01,  0.00000000e+00,
         0.00000000e+00,  1.88575819e-01,  9.15735289e-02,
         0.00000000e+00, -6.22908436e-02, -3.38319782e-03,
         1.23800792e-01,  5.01863398e-02, -4.81331954e-03,
        -2.04637516e-02, -4.44554165e-03, -1.80508029e-02,
        -1.20663578e-02,  2.83019822e-02],
       [ 1.51300639e-01,  2.16012716e-01,  4.31782342e-02,
         2.45120600e-01,  1.40066464e-02,  0.00000000e+00,
         1.38437048e-01,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  1.02661684e-01,
         0.00000000e+00,  1.62780583e-01,  5.45618273e-02,
         3.03599149e-01,  4.95723397e-01,  3.50861490e-01,
         1.02114871e-01,  0.00000000e+00,  2.14776307e-01,
         2.14072213e-01,  1.56319469e-01,  0.00000000e+00,
         1.48854032e-01,  0.00000000e+00,  0.00000000e+00,
         0.00000000e+00,  1.58857539e-01,  0.00000000e+00,
         4.05653536e-01,  1.22675776e-01,  4.25197184e-02,
         1.12757748e-02,  2.18971923e-01,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  2.00662389e-01,
         0.00000000e+00,  6.85178116e-03,  0.00000000e+00,
         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         2.33341128e-01,  3.21402609e-01,  0.00000000e+00,
         0.00000000e+00,  3.84907007e-01,  0.00000000e+00,
         0.00000000e+00,  1.16290517e-01,  0.00000000e+00,
         0.00000000e+00,  2.52411574e-01,  2.16994107e-01,
         5.22157736e-02,  2.45120507e-02,  4.00505736e-02,
        -4.24136184e-02, -2.03966000e-03,  1.33487843e-02,
        -2.18517566e-03, -1.06863603e-02, -2.89479154e-03,
        -2.85907798e-02, -3.10467603e-03]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p>Then, we project the learned interaction using a series of dense layers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deep_dlrm_interaction</span> <span class="o">=</span> <span class="n">dlrm_interaction</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">mm</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">]))</span>
<span class="n">deep_dlrm_interaction</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(5, 512), dtype=float32, numpy=
array([[0.055957  , 0.0198308 , 0.        , ..., 0.01130124, 0.        ,
        0.        ],
       [0.0727547 , 0.04420617, 0.03328843, ..., 0.03163406, 0.        ,
        0.        ],
       [0.03016799, 0.05012683, 0.01152872, ..., 0.03033926, 0.        ,
        0.        ],
       [0.00409173, 0.0635931 , 0.        , ..., 0.0143235 , 0.        ,
        0.        ],
       [0.        , 0.01937133, 0.        , ..., 0.        , 0.        ,
        0.        ]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="define-the-prediction-block">
<h3>Define the Prediction block<a class="headerlink" href="#define-the-prediction-block" title="Permalink to this headline"></a></h3>
<p>At this stage, we have created the DLRM block that accepts a dictionary of categorical and continuous tensors as input. The output of this block is the interaction representation vector of shape <code class="docutils literal notranslate"><span class="pre">512</span></code>. The next step is to use this hidden representation to conduct a given prediction task. In our case, we use the label <code class="docutils literal notranslate"><span class="pre">rating_binary</span></code> and the objective is: to predict if a user <code class="docutils literal notranslate"><span class="pre">A</span></code> will give a high rating to a movie <code class="docutils literal notranslate"><span class="pre">B</span></code> or not.</p>
<p>We use the <code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask</span></code> class and evaluate the performances using the <code class="docutils literal notranslate"><span class="pre">AUC</span></code> metric. We also use the <code class="docutils literal notranslate"><span class="pre">LogitsTemperatureScaler</span></code> block as a pre-transformation operation that scales the logits returned by the task before computing the loss and metrics:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.models.tf.transforms.bias</span> <span class="kn">import</span> <span class="n">LogitsTemperatureScaler</span>

<span class="n">binary_task</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">BinaryClassificationTask</span><span class="p">(</span>
    <span class="n">sub_schema</span><span class="p">,</span>
    <span class="n">pre</span><span class="o">=</span><span class="n">LogitsTemperatureScaler</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="define-train-and-evaluate-the-final-dlrm-model">
<h3>Define, train, and evaluate the final DLRM Model<a class="headerlink" href="#define-train-and-evaluate-the-final-dlrm-model" title="Permalink to this headline"></a></h3>
<p>We connect the deep DLRM interaction to the binary task and the method automatically generates the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class for us.
We note that the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class inherits from <a class="reference external" href="https://keras.io/api/models/model/">tf.keras.Model</a> class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">deep_dlrm_interaction</span><span class="p">,</span> <span class="n">binary_task</span><span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>merlin.models.tf.models.base.Model
</pre></div>
</div>
</div>
</div>
<p>We train the model using the built-in tf.keras <code class="docutils literal notranslate"><span class="pre">fit</span></code> method:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">AUC</span><span class="p">()])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>782/782 [==============================] - 20s 16ms/step - loss: 0.6475 - auc: 0.7244 - regularization_loss: 0.0000e+00
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;keras.callbacks.History at 0x7faa133ecd00&gt;
</pre></div>
</div>
</div>
</div>
<p>Let’s check out the model evaluation scores:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">metrics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">valid</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>196/196 [==============================] - 3s 9ms/step - loss: 0.6390 - auc: 0.7241 - regularization_loss: 0.0000e+00
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;loss&#39;: 0.6389783620834351,
 &#39;auc&#39;: 0.7241206169128418,
 &#39;regularization_loss&#39;: 0.0}
</pre></div>
</div>
</div>
</div>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">evaluate()</span></code> progress bar shows the loss score for every batch, whereas the final loss stored in the dictionary represents the total loss across all batches.</p>
<p>Save the model so we can use it for serving predictions in production or for resuming training with new observations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="s2">&quot;custom_dlrm&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:tensorflow:Unsupported signature for serialization: ((PredictionOutput(predictions=TensorSpec(shape=(None, 1), dtype=tf.float32, name=&#39;outputs/predictions&#39;), targets=TensorSpec(shape=(None, 1), dtype=tf.float32, name=&#39;outputs/targets&#39;), positive_item_ids=None, label_relevant_counts=None, valid_negatives_mask=None, negative_item_ids=None, sample_weight=None), &lt;tensorflow.python.framework.func_graph.UnknownArgument object at 0x7faa33dea910&gt;), {}).
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:tensorflow:Unsupported signature for serialization: ((PredictionOutput(predictions=TensorSpec(shape=(None, 1), dtype=tf.float32, name=&#39;outputs/predictions&#39;), targets=TensorSpec(shape=(None, 1), dtype=tf.float32, name=&#39;outputs/targets&#39;), positive_item_ids=None, label_relevant_counts=None, valid_negatives_mask=None, negative_item_ids=None, sample_weight=None), &lt;tensorflow.python.framework.func_graph.UnknownArgument object at 0x7faa33dea910&gt;), {}).
WARNING:absl:Function `_wrapped_model` contains input name(s) TE_age_rating, TE_gender_rating, TE_movieId_rating, TE_occupation_rating, TE_userId_rating, TE_zipcode_rating, movieId, userId with unsupported characters which will be renamed to te_age_rating, te_gender_rating, te_movieid_rating, te_occupation_rating, te_userid_rating, te_zipcode_rating, movieid, userid in the SavedModel.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:tensorflow:Unsupported signature for serialization: ((PredictionOutput(predictions=TensorSpec(shape=(None, 1), dtype=tf.float32, name=&#39;outputs/predictions&#39;), targets=TensorSpec(shape=(None, 1), dtype=tf.float32, name=&#39;outputs/targets&#39;), positive_item_ids=None, label_relevant_counts=None, valid_negatives_mask=None, negative_item_ids=None, sample_weight=None), &lt;tensorflow.python.framework.func_graph.UnknownArgument object at 0x7faa33dea910&gt;), {}).
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:tensorflow:Unsupported signature for serialization: ((PredictionOutput(predictions=TensorSpec(shape=(None, 1), dtype=tf.float32, name=&#39;outputs/predictions&#39;), targets=TensorSpec(shape=(None, 1), dtype=tf.float32, name=&#39;outputs/targets&#39;), positive_item_ids=None, label_relevant_counts=None, valid_negatives_mask=None, negative_item_ids=None, sample_weight=None), &lt;tensorflow.python.framework.func_graph.UnknownArgument object at 0x7faa33dea910&gt;), {}).
WARNING:absl:Found untraced functions such as train_compute_metrics, model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, logits_temperature_scaler_layer_call_fn, logits_temperature_scaler_layer_call_and_return_conditional_losses while saving (showing 5 of 67). These functions will not be directly callable after loading.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:tensorflow:Assets written to: workspace/data/custom_dlrm/assets
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:tensorflow:Assets written to: workspace/data/custom_dlrm/assets
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline"></a></h2>
<p>Merlin Models provides common and state-of-the-art RecSys architectures in a high-level API as well as all the required low-level building blocks for you to create your own architecture (input blocks, MLP layers, prediction tasks, loss functions, etc.). In this example, we explored a subset of these pre-existing blocks to create the DLRM model, but you can view our <a class="reference external" href="https://nvidia-merlin.github.io/models/main/">documentation</a> to discover more. You can also <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/blob/main/CONTRIBUTING.md">contribute</a> to the library by submitting new RecSys architectures and custom building Blocks.</p>
</div>
<div class="section" id="next-steps">
<h2>Next steps<a class="headerlink" href="#next-steps" title="Permalink to this headline"></a></h2>
<p>To learn more about how to deploy the trained DLRM model, please visit <a class="reference external" href="https://github.com/NVIDIA-Merlin/systems">Merlin Systems</a> library and execute the <code class="docutils literal notranslate"><span class="pre">Serving-Ranking-Models-With-Merlin-Systems.ipynb</span></code> notebook that deploys an ensemble of a <a class="reference external" href="https://github.com/NVIDIA-Merlin/NVTabular">NVTabular</a> Workflow and a trained model from Merlin Models to <a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server</a>.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="05-Retrieval-Model.html" class="btn btn-neutral float-left" title="Two-Stage Recommender Systems" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../api.html" class="btn btn-neutral float-right" title="API Documentation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: main
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../v0.4.0/index.html">v0.4.0</a></dd>
      <dd><a href="../../v0.5.0/index.html">v0.5.0</a></dd>
      <dd><a href="../../v0.6.0/index.html">v0.6.0</a></dd>
      <dd><a href="../../v0.7.0/index.html">v0.7.0</a></dd>
      <dd><a href="../../v0.8.0/index.html">v0.8.0</a></dd>
      <dd><a href="../../v0.9.0/index.html">v0.9.0</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="06-Define-your-own-architecture-with-Merlin-Models.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>