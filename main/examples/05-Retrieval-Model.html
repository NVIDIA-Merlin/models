<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Two-Stage Recommender Systems &mdash; Merlin Models  documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Merlin Models
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models_overview.html">Standard Models: Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="README.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Merlin Models</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Two-Stage Recommender Systems</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Copyright 2021 NVIDIA Corporation. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ================================
</pre></div>
</div>
</div>
<div class="section" id="Two-Stage-Recommender-Systems">
<h1>Two-Stage Recommender Systems<a class="headerlink" href="#Two-Stage-Recommender-Systems" title="Permalink to this headline"></a></h1>
<p>In large scale recommender systems pipelines, the size of the item catalog (number of unique items) might be in the order of millions. At such scale, a typical setup is having two-stage pipeline, where a faster candidate retrieval model quickly extracts thousands of relevant items and a then a more powerful ranking model (i.e. with more features and more powerful architecture) ranks the top-k items that are going to be displayed to the user. For ML-based candidate retrieval model, as it needs to
quickly score millions of items for a given user, a popular choices are models that can produce recommendation scores by just computing the dot product the user embeddings and item embeddings. Popular choices of such models are <strong>Matrix Factorization</strong>, which learns low-rank user and item embeddings, and the <strong>Two-Tower architecture</strong>, which is a neural network with two MLP towers where both user and item features are fed to generate user and item embeddings in the output.</p>
<div class="section" id="Dataset">
<h2>Dataset<a class="headerlink" href="#Dataset" title="Permalink to this headline"></a></h2>
<p>In this notebook, we are building a Two-Tower model for Item Retrieval task using the Ali-CCP: Alibaba Click and Conversion Prediction dataset. To download the Ali-CCP training and test datasets visit <a class="reference external" href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1">tianchi.aliyun.com</a> website. We have curated the raw dataset using this <a href="#id1"><span class="problematic" id="id2">`script &lt;&gt;`__</span></a> and generated the parquet files that we will use for this example.</p>
</div>
<div class="section" id="Learning-objectives">
<h2>Learning objectives<a class="headerlink" href="#Learning-objectives" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>Preparing the data with NVTabular</p></li>
<li><p>Training and evaluating Two-Tower model with Merlin Models</p></li>
<li><p>Exporting the model for deployment</p></li>
</ul>
</div>
<div class="section" id="Feature-Engineering-with-NVTabular">
<h2>Feature Engineering with NVTabular<a class="headerlink" href="#Feature-Engineering-with-NVTabular" title="Permalink to this headline"></a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
os.environ[&quot;TF_GPU_ALLOCATOR&quot;]=&quot;cuda_malloc_async&quot;
import cudf
import glob
import gc

import nvtabular as nvt
from nvtabular.ops import *
from merlin.models.utils.example_utils import workflow_fit_transform

from merlin.schema.tags import Tags
from merlin.schema import Schema

import merlin.models.tf as mm
import merlin.models.tf.dataset as tf_dataloader

from merlin.io.dataset import Dataset
from merlin.schema.io.tensorflow_metadata import TensorflowMetadata
from merlin.models.tf.blocks.core.aggregation import CosineSimilarity

import tensorflow as tf
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-03-25 18:21:09.740734: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-25 18:21:10.876420: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0
2022-03-25 18:21:10.876553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16254 MB memory:  -&gt; device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># disable INFO and DEBUG logging everywhere
import logging
logging.disable(logging.WARNING)
</pre></div>
</div>
</div>
<p>First, we define our input and output paths. We will use the parquet files in the test folder to validate our trained model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>DATA_FOLDER = os.environ.get(&quot;DATA_FOLDER&quot;, &quot;/workspace/data/&quot;)
train_path = os.path.join(DATA_FOLDER, &#39;train&#39;, &#39;*.parquet&#39;)
valid_path = os.path.join(DATA_FOLDER, &#39;test&#39;,&#39;*.parquet&#39;)
output_path = &#39;/workspace/data/processed/&#39;
</pre></div>
</div>
</div>
<p>ETL Workflow</p>
<p>We keep only positive interactions where clicks==1 in the dataset with <code class="docutils literal notranslate"><span class="pre">Filter()</span></code> op.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>user_id = [&quot;user_id&quot;] &gt;&gt; Categorify() &gt;&gt; TagAsUserID()
item_id = [&quot;item_id&quot;] &gt;&gt; Categorify() &gt;&gt; TagAsItemID()

item_features = [&quot;item_category&quot;, &quot;item_shop&quot;, &quot;item_brand&quot;] &gt;&gt; Categorify() &gt;&gt; TagAsItemFeatures()

user_features = [&#39;user_shops&#39;, &#39;user_profile&#39;, &#39;user_group&#39;,
       &#39;user_gender&#39;, &#39;user_age&#39;, &#39;user_consumption_2&#39;, &#39;user_is_occupied&#39;,
       &#39;user_geography&#39;, &#39;user_intentions&#39;, &#39;user_brands&#39;, &#39;user_categories&#39;] \
        &gt;&gt; Categorify() &gt;&gt; TagAsUserFeatures()

inputs = user_id + item_id + item_features + user_features + [&#39;click&#39;]

outputs = inputs &gt;&gt; Filter(f=lambda df: df[&quot;click&quot;] == 1)

workflow_fit_transform(outputs, train_path, valid_path, output_path)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.
  warnings.warn(
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Building-a-Two-Tower-Model-with-Merlin-Models">
<h1>Building a Two-Tower Model with Merlin Models<a class="headerlink" href="#Building-a-Two-Tower-Model-with-Merlin-Models" title="Permalink to this headline"></a></h1>
<p>We will use Two-Tower Model for item retrieval task. Real-world large scale recommender systems have hundreds of millions of items (products) and users. Thus, these systems often composed of two stages: candidate generation (retrieval) and ranking (scoring the retrieved items). At candidate generation step, a subset of relevant items from large item corpus is retrieved. You can read more about two stage Recommender Systems here. In this example, we’re going to focus on the retrieval stage.</p>
<p>A Two-Tower Model consists of item (candidate) and user (query) encoder towers. With two towers, the model can learn representations (embeddings) for queries and candidates separately.</p>
<p><img alt="3c6980bce8024762aaec7e6086e57964" class="no-scaled-link" src="../_images/TwoTower.png" style="width: 30%;" /></p>
<p>Image Adapted from: <a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/3366423.3380130">Off-policy Learning in Two-stage Recommender Systems</a></p>
<p>We use the <code class="docutils literal notranslate"><span class="pre">schema</span></code> object to define our model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train = Dataset(os.path.join(output_path, &#39;train&#39;, &#39;*.parquet&#39;), part_size=&quot;500MB&quot;)
valid = Dataset(os.path.join(output_path, &#39;valid&#39;, &#39;*.parquet&#39;), part_size=&quot;500MB&quot;)

schema = train.schema
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>schema = schema.select_by_tag([Tags.ITEM_ID, Tags.USER_ID, Tags.ITEM, Tags.USER])
</pre></div>
</div>
</div>
<p>We can print out the feature column names.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>schema.column_names
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;user_id&#39;,
 &#39;item_id&#39;,
 &#39;item_category&#39;,
 &#39;item_shop&#39;,
 &#39;item_brand&#39;,
 &#39;user_shops&#39;,
 &#39;user_profile&#39;,
 &#39;user_group&#39;,
 &#39;user_gender&#39;,
 &#39;user_age&#39;,
 &#39;user_consumption_2&#39;,
 &#39;user_is_occupied&#39;,
 &#39;user_geography&#39;,
 &#39;user_intentions&#39;,
 &#39;user_brands&#39;,
 &#39;user_categories&#39;]
</pre></div></div>
</div>
<p>We expect the label names to be empty.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>label_names = schema.select_by_tag(Tags.TARGET).column_names
label_names
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[]
</pre></div></div>
</div>
<div class="section" id="Negative-sampling">
<h2>Negative sampling<a class="headerlink" href="#Negative-sampling" title="Permalink to this headline"></a></h2>
<p>Many datasets for recommender systems contains implicit feedback, with logs of user interactions like clicks, add-to-cart, purchases, music listening events, rather than explicit ratings that reflects user preferences over items. To be able to learn from implicit feedback, we use the general (and naive) assumption that the interacted items are more relevant for the user than the non-interacted ones. In Merlin Models we provide some scalable negative sampling algorithms for the Item Retrieval
Task. In particular, we use in this example the in-batch sampling algorithm which uses the items interacted by other users as negatives within the same mini-batch.</p>
</div>
<div class="section" id="Building-the-Model">
<h2>Building the Model<a class="headerlink" href="#Building-the-Model" title="Permalink to this headline"></a></h2>
<p>Now, let’s build our Two-Tower model. In a nutshell, we aggregate all user features to feed in user tower and feed the item features to the item tower. Then we compute the positive score by multiplying the user embedding with the item embedding and sample negative items (read more about negative sampling <a class="reference external" href="https://openreview.net/pdf?id=824xC-SgWgU">here</a> and <a class="reference external" href="https://medium.com/mlearning-ai/overview-negative-sampling-on-recommendation-systems-230a051c6cd7">here</a>), whose item embeddings are
also multiplied by the user embedding. Then we apply the loss function on top of the positive and negative scores.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model = mm.TwoTowerModel(
    schema,
    query_tower=mm.MLPBlock([128, 64], no_activation_last_layer=True),
    loss=&quot;categorical_crossentropy&quot;,
    samplers=[mm.InBatchSampler()],
    embedding_options = mm.EmbeddingOptions(infer_embedding_sizes=True),
    metrics=[mm.RecallAt(10), mm.NDCGAt(10)]
)
</pre></div>
</div>
</div>
<p>Let’s explain the parameters in the TwoTowerModel(): - no_activation_last_layer: when set True, no activation is used for top hidden layer. Learn more <a class="reference external" href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/b9f4e78a8830fe5afcf2f0452862fb3c0d6584ea.pdf">here</a>. - infer_embedding_sizes: when set True, automatically defines the embedding dimension from the feature cardinality in the schema</p>
<p><strong>Metrics:</strong></p>
<p>The following information retrieval metrics are used to compute the Top-10 accuracy of recommendation lists containing all items:</p>
<ul class="simple">
<li><p><strong>Normalized Discounted Cumulative Gain (NDCG&#64;10)</strong>: NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the top-k items.</p></li>
<li><p><strong>Recall&#64;10</strong>: Also known as HitRate&#64;n when there is only one relevant item in the recommendation list. Recall just verifies whether the relevant item is among the top-n items.</p></li>
</ul>
<p>We need to initialize the dataloaders.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.set_retrieval_candidates_for_evaluation(train)

opt = tf.keras.optimizers.Adagrad(learning_rate=0.003)
model.compile(optimizer=opt, run_eagerly=False)
model.fit(train, validation_data=valid, batch_size=4096, epochs=5)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-03-25 18:21:49.247382: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/5
382/384 [============================&gt;.] - ETA: 0s - recall_at_10: 0.0024 - ndcg_10: 0.0011 - loss: 8.3225 - regularization_loss: 0.0000e+00 - total_loss: 8.3225
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-03-25 18:22:08.000481: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1034311152 exceeds 10% of free system memory.
2022-03-25 18:22:11.491670: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1034311152 exceeds 10% of free system memory.
2022-03-25 18:22:21.411679: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: cond/then/_0/cond/cond/branch_executed/_184
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
384/384 [==============================] - 37s 80ms/step - recall_at_10: 0.0024 - ndcg_10: 0.0011 - loss: 8.3196 - regularization_loss: 0.0000e+00 - total_loss: 8.3196 - val_recall_at_10: 0.0025 - val_ndcg_10: 0.0011 - val_loss: 7.4208 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4208
Epoch 2/5
382/384 [============================&gt;.] - ETA: 0s - recall_at_10: 0.0024 - ndcg_10: 0.0011 - loss: 8.3217 - regularization_loss: 0.0000e+00 - total_loss: 8.3217
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-03-25 18:22:38.212795: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1034311152 exceeds 10% of free system memory.
2022-03-25 18:22:41.619888: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1034311152 exceeds 10% of free system memory.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
384/384 [==============================] - 28s 71ms/step - recall_at_10: 0.0024 - ndcg_10: 0.0011 - loss: 8.3188 - regularization_loss: 0.0000e+00 - total_loss: 8.3188 - val_recall_at_10: 0.0025 - val_ndcg_10: 0.0012 - val_loss: 7.4200 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4200
Epoch 3/5
382/384 [============================&gt;.] - ETA: 0s - recall_at_10: 0.0024 - ndcg_10: 0.0011 - loss: 8.3210 - regularization_loss: 0.0000e+00 - total_loss: 8.3210
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-03-25 18:23:05.813015: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1034311152 exceeds 10% of free system memory.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
384/384 [==============================] - 28s 72ms/step - recall_at_10: 0.0024 - ndcg_10: 0.0011 - loss: 8.3181 - regularization_loss: 0.0000e+00 - total_loss: 8.3181 - val_recall_at_10: 0.0025 - val_ndcg_10: 0.0012 - val_loss: 7.4193 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4193
Epoch 4/5
384/384 [==============================] - 28s 72ms/step - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3175 - regularization_loss: 0.0000e+00 - total_loss: 8.3175 - val_recall_at_10: 0.0026 - val_ndcg_10: 0.0012 - val_loss: 7.4187 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4187
Epoch 5/5
384/384 [==============================] - 28s 72ms/step - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3169 - regularization_loss: 0.0000e+00 - total_loss: 8.3169 - val_recall_at_10: 0.0026 - val_ndcg_10: 0.0012 - val_loss: 7.4182 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4182
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;keras.callbacks.History at 0x7f743c3be640&gt;
</pre></div></div>
</div>
<p>In batch sampling is prone to popularity-bias. since different users might have interacted same items. # in the fit method we are only using the negative sampling in each batch and the final score is avg over all the batches. for each batch we aer comparing only the items in the given batch. in the <code class="docutils literal notranslate"><span class="pre">.evaluate()</span></code> we are considering entire item catalog for each positive item. generate the scores for all items and check the position of the positive item in the list of scores.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.evaluate(valid, return_dict=True, batch_size=1024)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1542/1542 [==============================] - 46s 29ms/step - recall_at_10: 2.2805e-05 - ndcg_10: 9.9212e-06 - loss: 5.2483e-05 - regularization_loss: 0.0000e+00 - total_loss: 5.2483e-05
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;recall_at_10&#39;: 2.280459739267826e-05,
 &#39;ndcg_10&#39;: 9.921227501763497e-06,
 &#39;loss&#39;: 0.0,
 &#39;regularization_loss&#39;: 0.0,
 &#39;total_loss&#39;: 0.0}
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Exporting-Retrieval-Models">
<h1>Exporting Retrieval Models<a class="headerlink" href="#Exporting-Retrieval-Models" title="Permalink to this headline"></a></h1>
<p>So far we have trained and evaluated our Retrieval model. Now, the next step is to deploy our model and generate top-K recommendations given a user (query). We can efficiently serve our model by indexing the trained item embeddings into an <strong>Approximate Nearest Neighbors (ANN)</strong> engine. Basically, for a given user query vector, that is generated passing the user features into user tower of retrieval model, we do an ANN search query to find the ids of nearby item vectors, and at serve time, we
score user embeddings over all indexed top-K item embeddings within the ANN engine.</p>
<p>In doing so, we need to export</p>
<ul class="simple">
<li><p>user (query) tower</p></li>
<li><p>item and user features</p></li>
<li><p>item embeddings</p></li>
</ul>
<p>We are able to save the user tower model as a TF model to disk. The user tower model is needed to generate a user embedding vector when a user feature vector x is fed into that model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>query_tower = model.retrieval_block.query_block()
query_tower.save(&#39;query_tower&#39;)
</pre></div>
</div>
</div>
<p>With <code class="docutils literal notranslate"><span class="pre">unique_rows_by_features</span></code> utility function we can easily extract both unique user and item features tables as cuDF dataframes. Note that for user features table, we use <code class="docutils literal notranslate"><span class="pre">USER</span></code> and <code class="docutils literal notranslate"><span class="pre">USER_ID</span></code> tags.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from merlin.models.utils.dataset import unique_rows_by_features
user_features = unique_rows_by_features(train, Tags.USER, Tags.USER_ID).compute().reset_index(drop=True)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>user_features.head()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>user_shops</th>
      <th>user_profile</th>
      <th>user_group</th>
      <th>user_gender</th>
      <th>user_age</th>
      <th>user_consumption_2</th>
      <th>user_is_occupied</th>
      <th>user_geography</th>
      <th>user_intentions</th>
      <th>user_brands</th>
      <th>user_categories</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>109</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>69</td>
      <td>131</td>
      <td>9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>301</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>57</td>
      <td>4709</td>
      <td>57</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>1876</td>
      <td>23</td>
      <td>7</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>63</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>534</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>40</td>
      <td>22</td>
      <td>108</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>user_features.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(214994, 12)
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># save to disk
user_features.to_parquet(&#39;user_features.parquet&#39;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>item_features = unique_rows_by_features(train, Tags.ITEM, Tags.ITEM_ID).compute().reset_index(drop=True)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>item_features.head()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>item_id</th>
      <th>item_category</th>
      <th>item_shop</th>
      <th>item_brand</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>441</td>
      <td>432</td>
      <td>474</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>193</td>
      <td>1159</td>
      <td>125</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>3</td>
      <td>1463</td>
      <td>872</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>282</td>
      <td>2479</td>
      <td>555</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># save to disk
item_features.to_parquet(&#39;item_features.parquet&#39;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>item_embs = model.item_embeddings(Dataset(item_features, schema=schema), batch_size=1024)
item_embs_df = item_embs.compute(scheduler=&quot;synchronous&quot;)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>item_embs_df
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>item_id</th>
      <th>item_category</th>
      <th>item_shop</th>
      <th>item_brand</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>...</th>
      <th>54</th>
      <th>55</th>
      <th>56</th>
      <th>57</th>
      <th>58</th>
      <th>59</th>
      <th>60</th>
      <th>61</th>
      <th>62</th>
      <th>63</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.100480</td>
      <td>-0.101183</td>
      <td>0.038712</td>
      <td>-0.069887</td>
      <td>0.055463</td>
      <td>0.187399</td>
      <td>...</td>
      <td>-0.136141</td>
      <td>0.092087</td>
      <td>0.000309</td>
      <td>0.012232</td>
      <td>0.004694</td>
      <td>0.185416</td>
      <td>-0.175290</td>
      <td>-0.113102</td>
      <td>0.046894</td>
      <td>-0.095183</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>441</td>
      <td>432</td>
      <td>474</td>
      <td>0.106592</td>
      <td>-0.140783</td>
      <td>0.187643</td>
      <td>0.116384</td>
      <td>-0.117863</td>
      <td>0.151208</td>
      <td>...</td>
      <td>-0.078249</td>
      <td>0.098082</td>
      <td>0.033912</td>
      <td>0.028970</td>
      <td>0.004288</td>
      <td>0.182896</td>
      <td>-0.049048</td>
      <td>0.088471</td>
      <td>0.095434</td>
      <td>-0.031751</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>193</td>
      <td>1159</td>
      <td>125</td>
      <td>-0.028713</td>
      <td>-0.173785</td>
      <td>-0.056876</td>
      <td>0.034120</td>
      <td>-0.056204</td>
      <td>0.311673</td>
      <td>...</td>
      <td>-0.129029</td>
      <td>0.144884</td>
      <td>-0.012147</td>
      <td>0.056141</td>
      <td>-0.024954</td>
      <td>0.147257</td>
      <td>-0.034835</td>
      <td>0.065109</td>
      <td>0.052829</td>
      <td>-0.073503</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>3</td>
      <td>1463</td>
      <td>872</td>
      <td>0.087634</td>
      <td>-0.136825</td>
      <td>0.128481</td>
      <td>0.016375</td>
      <td>0.066299</td>
      <td>-0.077430</td>
      <td>...</td>
      <td>-0.183097</td>
      <td>0.093180</td>
      <td>0.074107</td>
      <td>-0.220991</td>
      <td>0.077473</td>
      <td>0.183373</td>
      <td>-0.085114</td>
      <td>-0.160506</td>
      <td>-0.069322</td>
      <td>0.011579</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>282</td>
      <td>2479</td>
      <td>555</td>
      <td>0.044352</td>
      <td>-0.185963</td>
      <td>-0.060681</td>
      <td>-0.028867</td>
      <td>0.046313</td>
      <td>0.220343</td>
      <td>...</td>
      <td>-0.085646</td>
      <td>0.063820</td>
      <td>-0.137686</td>
      <td>-0.071112</td>
      <td>-0.161351</td>
      <td>0.150922</td>
      <td>-0.066201</td>
      <td>-0.178179</td>
      <td>0.023789</td>
      <td>-0.196832</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>568842</th>
      <td>3078159</td>
      <td>1764</td>
      <td>365864</td>
      <td>121053</td>
      <td>-0.181527</td>
      <td>0.013411</td>
      <td>0.059540</td>
      <td>0.030576</td>
      <td>0.007284</td>
      <td>0.240745</td>
      <td>...</td>
      <td>-0.156806</td>
      <td>0.170368</td>
      <td>0.061671</td>
      <td>-0.153007</td>
      <td>-0.216809</td>
      <td>0.114002</td>
      <td>0.040904</td>
      <td>-0.152487</td>
      <td>0.138781</td>
      <td>0.004465</td>
    </tr>
    <tr>
      <th>568843</th>
      <td>3078210</td>
      <td>377</td>
      <td>97495</td>
      <td>116656</td>
      <td>-0.000746</td>
      <td>-0.059242</td>
      <td>0.196628</td>
      <td>0.018706</td>
      <td>0.065176</td>
      <td>0.227332</td>
      <td>...</td>
      <td>-0.049041</td>
      <td>0.105531</td>
      <td>-0.003052</td>
      <td>0.104010</td>
      <td>-0.052346</td>
      <td>-0.033157</td>
      <td>-0.106754</td>
      <td>-0.065986</td>
      <td>0.317890</td>
      <td>-0.063438</td>
    </tr>
    <tr>
      <th>568844</th>
      <td>3078270</td>
      <td>3817</td>
      <td>577371</td>
      <td>80796</td>
      <td>-0.073659</td>
      <td>-0.020232</td>
      <td>-0.099983</td>
      <td>-0.005017</td>
      <td>-0.238924</td>
      <td>0.178821</td>
      <td>...</td>
      <td>-0.213560</td>
      <td>0.130538</td>
      <td>0.054929</td>
      <td>-0.038743</td>
      <td>-0.068914</td>
      <td>0.062025</td>
      <td>0.089917</td>
      <td>0.031116</td>
      <td>0.102875</td>
      <td>-0.180703</td>
    </tr>
    <tr>
      <th>568845</th>
      <td>3078283</td>
      <td>551</td>
      <td>201089</td>
      <td>85172</td>
      <td>-0.013963</td>
      <td>-0.047382</td>
      <td>0.124333</td>
      <td>0.055950</td>
      <td>0.104881</td>
      <td>0.094359</td>
      <td>...</td>
      <td>0.186676</td>
      <td>0.136704</td>
      <td>0.101370</td>
      <td>-0.016214</td>
      <td>-0.030931</td>
      <td>0.129269</td>
      <td>-0.069209</td>
      <td>-0.014182</td>
      <td>0.144155</td>
      <td>-0.062910</td>
    </tr>
    <tr>
      <th>568846</th>
      <td>3078304</td>
      <td>475</td>
      <td>255840</td>
      <td>335</td>
      <td>-0.191559</td>
      <td>-0.092710</td>
      <td>0.025378</td>
      <td>-0.024475</td>
      <td>0.079726</td>
      <td>0.079302</td>
      <td>...</td>
      <td>0.044710</td>
      <td>0.082819</td>
      <td>0.032549</td>
      <td>-0.024786</td>
      <td>-0.024001</td>
      <td>0.074184</td>
      <td>-0.074518</td>
      <td>-0.077085</td>
      <td>0.170670</td>
      <td>0.116576</td>
    </tr>
  </tbody>
</table>
<p>568847 rows × 68 columns</p>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># select only embedding columns
item_embeddings = item_embs_df.iloc[:, 4:]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>item_embeddings.head()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>54</th>
      <th>55</th>
      <th>56</th>
      <th>57</th>
      <th>58</th>
      <th>59</th>
      <th>60</th>
      <th>61</th>
      <th>62</th>
      <th>63</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.100480</td>
      <td>-0.101183</td>
      <td>0.038712</td>
      <td>-0.069887</td>
      <td>0.055463</td>
      <td>0.187399</td>
      <td>0.088853</td>
      <td>-0.251354</td>
      <td>0.069880</td>
      <td>-0.046955</td>
      <td>...</td>
      <td>-0.136141</td>
      <td>0.092087</td>
      <td>0.000309</td>
      <td>0.012232</td>
      <td>0.004694</td>
      <td>0.185416</td>
      <td>-0.175290</td>
      <td>-0.113102</td>
      <td>0.046894</td>
      <td>-0.095183</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.106592</td>
      <td>-0.140783</td>
      <td>0.187643</td>
      <td>0.116384</td>
      <td>-0.117863</td>
      <td>0.151208</td>
      <td>0.165833</td>
      <td>-0.152995</td>
      <td>-0.071885</td>
      <td>0.057338</td>
      <td>...</td>
      <td>-0.078249</td>
      <td>0.098082</td>
      <td>0.033912</td>
      <td>0.028970</td>
      <td>0.004288</td>
      <td>0.182896</td>
      <td>-0.049048</td>
      <td>0.088471</td>
      <td>0.095434</td>
      <td>-0.031751</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.028713</td>
      <td>-0.173785</td>
      <td>-0.056876</td>
      <td>0.034120</td>
      <td>-0.056204</td>
      <td>0.311673</td>
      <td>0.211417</td>
      <td>-0.058011</td>
      <td>0.129465</td>
      <td>-0.073758</td>
      <td>...</td>
      <td>-0.129029</td>
      <td>0.144884</td>
      <td>-0.012147</td>
      <td>0.056141</td>
      <td>-0.024954</td>
      <td>0.147257</td>
      <td>-0.034835</td>
      <td>0.065109</td>
      <td>0.052829</td>
      <td>-0.073503</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.087634</td>
      <td>-0.136825</td>
      <td>0.128481</td>
      <td>0.016375</td>
      <td>0.066299</td>
      <td>-0.077430</td>
      <td>0.176676</td>
      <td>-0.230770</td>
      <td>0.042750</td>
      <td>-0.019357</td>
      <td>...</td>
      <td>-0.183097</td>
      <td>0.093180</td>
      <td>0.074107</td>
      <td>-0.220991</td>
      <td>0.077473</td>
      <td>0.183373</td>
      <td>-0.085114</td>
      <td>-0.160506</td>
      <td>-0.069322</td>
      <td>0.011579</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.044352</td>
      <td>-0.185963</td>
      <td>-0.060681</td>
      <td>-0.028867</td>
      <td>0.046313</td>
      <td>0.220343</td>
      <td>0.015842</td>
      <td>-0.183577</td>
      <td>0.102639</td>
      <td>-0.070050</td>
      <td>...</td>
      <td>-0.085646</td>
      <td>0.063820</td>
      <td>-0.137686</td>
      <td>-0.071112</td>
      <td>-0.161351</td>
      <td>0.150922</td>
      <td>-0.066201</td>
      <td>-0.178179</td>
      <td>0.023789</td>
      <td>-0.196832</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 64 columns</p>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># save to disk
item_embeddings.to_parquet(&#39;item_embeddings.parquet&#39;)
</pre></div>
</div>
</div>
<p>That’s it. You have learned how to train and evaluate your Two-Tower retrieval model, and then how to export the required components to be able to deploy this model to generate recommendations. In order to learn more on serving a model to <a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server</a>, please explore the examples in the <a class="reference external" href="https://github.com/NVIDIA-Merlin/Merlin">Merlin</a> and <a class="reference external" href="https://github.com/NVIDIA-Merlin/systems">Merlin Systems</a> repos.</p>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: main
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../v0.2.0/index.html">v0.2.0</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="05-Retrieval-Model.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>