<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>merlin.models.tf.core.transformations &mdash; Merlin Models  documentation</title><link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/mystnb.css" type="text/css" />
    <link rel="canonical" href="https://nvidia-merlin.github.io/models/main/_modules/merlin/models/tf/core/transformations.html" />
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../../../../../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../index.html" class="icon icon-home"> Merlin Models
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../models_overview.html">Standard Models: Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../additional_resources.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">Merlin Models</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
      <li>merlin.models.tf.core.transformations</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for merlin.models.tf.core.transformations</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Copyright (c) 2021, NVIDIA CORPORATION.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">keras.layers.preprocessing</span> <span class="kn">import</span> <span class="n">preprocessing_utils</span>
<span class="kn">from</span> <span class="nn">keras.layers.preprocessing</span> <span class="kn">import</span> <span class="n">preprocessing_utils</span> <span class="k">as</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">layer_utils</span>

<span class="kn">from</span> <span class="nn">merlin.models.config.schema</span> <span class="kn">import</span> <span class="n">requires_schema</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.core.base</span> <span class="kn">import</span> <span class="n">Block</span><span class="p">,</span> <span class="n">PredictionOutput</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.core.combinators</span> <span class="kn">import</span> <span class="n">ParallelBlock</span><span class="p">,</span> <span class="n">TabularBlock</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.typing</span> <span class="kn">import</span> <span class="n">TabularData</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.utils.tf_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">df_to_tensor</span><span class="p">,</span>
    <span class="n">get_candidate_probs</span><span class="p">,</span>
    <span class="n">list_col_to_ragged</span><span class="p">,</span>
    <span class="n">transform_label_to_onehot</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">merlin.models.utils</span> <span class="kn">import</span> <span class="n">schema_utils</span>
<span class="kn">from</span> <span class="nn">merlin.schema</span> <span class="kn">import</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">Tags</span>

<span class="n">ONE_HOT</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">ONE_HOT</span>
<span class="n">MULTI_HOT</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">MULTI_HOT</span>
<span class="n">COUNT</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">COUNT</span>


<span class="nd">@Block</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;as-ragged&quot;</span><span class="p">)</span>
<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin.models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">AsRaggedFeatures</span><span class="p">(</span><span class="n">TabularBlock</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert all list (multi-hot/sequential) features to tf.RaggedTensor&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">TabularData</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TabularData</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">list_col_to_ragged</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shapes</span><span class="p">):</span>
        <span class="n">output_shapes</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">input_shapes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># If it is a list/sparse feature (in tuple representation), uses the offset as shape</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">):</span>
                <span class="n">output_shapes</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="kc">None</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_shapes</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="k">return</span> <span class="n">output_shapes</span>

    <span class="k">def</span> <span class="nf">compute_call_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shapes</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)</span>


<div class="viewcode-block" id="AsSparseFeatures"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.AsSparseFeatures.html#merlin.models.tf.AsSparseFeatures">[docs]</a><span class="nd">@Block</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;as-sparse&quot;</span><span class="p">)</span>
<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin.models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">AsSparseFeatures</span><span class="p">(</span><span class="n">TabularBlock</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert all list-inputs to sparse-tensors.</span>

<span class="sd">    By default, the dataloader will represent list-columns as a tuple of values &amp; row-lengths.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AsSparseFeatures.call"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.AsSparseFeatures.html#merlin.models.tf.AsSparseFeatures.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">TabularData</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TabularData</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">list_col_to_ragged</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">):</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>

        <span class="k">return</span> <span class="n">outputs</span></div>

<div class="viewcode-block" id="AsSparseFeatures.compute_output_shape"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.AsSparseFeatures.html#merlin.models.tf.AsSparseFeatures.compute_output_shape">[docs]</a>    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_shape</span></div></div>


<div class="viewcode-block" id="AsDenseFeatures"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.AsDenseFeatures.html#merlin.models.tf.AsDenseFeatures">[docs]</a><span class="nd">@Block</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;as-dense&quot;</span><span class="p">)</span>
<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin.models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">AsDenseFeatures</span><span class="p">(</span><span class="n">TabularBlock</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert all list-inputs to dense-tensors.</span>

<span class="sd">    By default, the dataloader will represent list-columns as a tuple of values &amp; row-lengths.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    max_seq_length : int</span>
<span class="sd">        The maximum length of multi-hot features.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AsDenseFeatures.__init__"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.AsDenseFeatures.html#merlin.models.tf.AsDenseFeatures.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">max_seq_length</span></div>

<div class="viewcode-block" id="AsDenseFeatures.call"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.AsDenseFeatures.html#merlin.models.tf.AsDenseFeatures.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">TabularData</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TabularData</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">list_col_to_ragged</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">:</span>
                    <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span></div>

<div class="viewcode-block" id="AsDenseFeatures.compute_output_shape"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.AsDenseFeatures.html#merlin.models.tf.AsDenseFeatures.compute_output_shape">[docs]</a>    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_batch_size_from_input_shapes</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">outputs</span></div>

<div class="viewcode-block" id="AsDenseFeatures.get_config"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.AsDenseFeatures.html#merlin.models.tf.AsDenseFeatures.get_config">[docs]</a>    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">config</span></div></div>


<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin.models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RenameFeatures</span><span class="p">(</span><span class="n">TabularBlock</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Rename input features</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    renames: dict</span>
<span class="sd">        Mapping with new features names.</span>
<span class="sd">    schema: Schema, optional</span>
<span class="sd">        The `Schema` with input features,</span>
<span class="sd">        by default None</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">renames</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tags</span><span class="p">],</span> <span class="nb">str</span><span class="p">],</span> <span class="n">schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Schema</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">renames</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">renames</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">Tags</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Schema must be provided to rename features with Tags&quot;</span><span class="p">)</span>
                <span class="n">cols</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tag: </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> does not uniquely identify a column&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">renames</span><span class="p">[</span><span class="n">cols</span><span class="o">.</span><span class="n">first</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">renames</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">TabularData</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TabularData</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">renames</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">renames</span><span class="p">[</span><span class="n">key</span><span class="p">]]</span> <span class="o">=</span> <span class="n">val</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">renames</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">renames</span><span class="p">[</span><span class="n">key</span><span class="p">]]</span> <span class="o">=</span> <span class="n">val</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;renames&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">renames</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">config</span>


<div class="viewcode-block" id="ExpandDims"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.ExpandDims.html#merlin.models.tf.ExpandDims">[docs]</a><span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin.models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ExpandDims</span><span class="p">(</span><span class="n">TabularBlock</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expand dims of selected input tensors.</span>
<span class="sd">    Example::</span>

<span class="sd">        inputs = {</span>
<span class="sd">            &quot;cont_feat1&quot;: tf.random.uniform((NUM_ROWS,)),</span>
<span class="sd">            &quot;cont_feat2&quot;: tf.random.uniform((NUM_ROWS,)),</span>
<span class="sd">            &quot;multi_hot_categ_feat&quot;: tf.random.uniform(</span>
<span class="sd">                (NUM_ROWS, 4), minval=1, maxval=100, dtype=tf.int32</span>
<span class="sd">            ),</span>
<span class="sd">        }</span>

<span class="sd">        expand_dims_op = tr.ExpandDims(expand_dims={&quot;cont_feat2&quot;: 0, &quot;multi_hot_categ_feat&quot;: 1})</span>
<span class="sd">        expanded_inputs = expand_dims_op(inputs)</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ExpandDims.__init__"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.ExpandDims.html#merlin.models.tf.ExpandDims.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expand_dims</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiates the `ExpandDims` transformation, which allows to expand dims</span>
<span class="sd">        of the input tensors</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        expand_dims : Union[int, Dict[str, int]], optional, by default -1</span>
<span class="sd">            Defines which dimensions should be expanded. If an `int` is provided, all input tensors</span>
<span class="sd">            will have the same dimension expanded. If a `dict` is passed, only features matching</span>
<span class="sd">            the dict keys will be expanded, in the dimension specified as the dict values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs_expand_dims</span> <span class="o">=</span> <span class="n">expand_dims</span></div>

<div class="viewcode-block" id="ExpandDims.call"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.ExpandDims.html#merlin.models.tf.ExpandDims.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">TabularData</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TabularData</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs_expand_dims</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs_expand_dims</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs_expand_dims</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs_expand_dims</span><span class="p">:</span>
                <span class="n">expand_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs_expand_dims</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">expand_dim</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs_expand_dims</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The expand_dims argument is not valid&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span></div>

<div class="viewcode-block" id="ExpandDims.compute_output_shape"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.ExpandDims.html#merlin.models.tf.ExpandDims.compute_output_shape">[docs]</a>    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_shape</span></div></div>


<span class="nd">@Block</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">register_with_multiple_names</span><span class="p">(</span><span class="s2">&quot;l2-norm&quot;</span><span class="p">)</span>
<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin.models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">L2Norm</span><span class="p">(</span><span class="n">TabularBlock</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply L2-normalization to input tensors along a given axis&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">L2Norm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">TabularData</span><span class="p">],</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">l2_normalize</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">inp</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">l2_normalize</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">inputs</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_shape</span>


<span class="nd">@Block</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">register_with_multiple_names</span><span class="p">(</span><span class="s2">&quot;remove_pad_3d&quot;</span><span class="p">)</span>
<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin_models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RemovePad3D</span><span class="p">(</span><span class="n">Block</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Flatten the sequence of labels and filter out non-targets positions</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        padding_idx: int</span>
<span class="sd">            The padding index value.</span>
<span class="sd">            Defaults to 0.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">        targets: tf.Tensor</span>
<span class="sd">            The flattened vector of true targets positions</span>
<span class="sd">        flatten_predictions: tf.Tensor</span>
<span class="sd">            If the predictions are 3-D vectors (sequential task),</span>
<span class="sd">            flatten the predictions vectors to keep only the ones related to target positions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_shape</span>

    <span class="k">def</span> <span class="nf">call_outputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">PredictionOutput</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;PredictionOutput&quot;</span><span class="p">:</span>
        <span class="n">targets</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">predictions</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
        <span class="n">non_pad_mask</span> <span class="o">=</span> <span class="n">targets</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">non_pad_mask</span><span class="p">)</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">),</span> <span class="s2">&quot;Predictions must be a tensor&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()))</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span>
                <span class="n">predictions</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">non_pad_mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">predictions</span><span class="p">))</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="o">.</span><span class="n">copy_with_updates</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>


<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin_models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LogitsTemperatureScaler</span><span class="p">(</span><span class="n">Block</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scale the logits higher or lower,</span>
<span class="sd">    this is often used to reduce the overconfidence of the model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    temperature : float</span>
<span class="sd">        Divide the logits by this scaler.</span>
<span class="sd">    apply_on_call_outputs: bool</span>
<span class="sd">        Whether to apply the transform (logits / temperature) on</span>
<span class="sd">        `call()` or `call_outputs()`. By default True</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">apply_on_call_outputs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogitsTemperatureScaler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply_on_call_outputs</span> <span class="o">=</span> <span class="n">apply_on_call_outputs</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_on_call_outputs</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_temperature</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">inputs</span>

    <span class="k">def</span> <span class="nf">call_outputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">PredictionOutput</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;PredictionOutput&quot;</span><span class="p">:</span>
        <span class="n">targets</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">predictions</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_temperature</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="o">.</span><span class="n">copy_with_updates</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_shape</span>

    <span class="k">def</span> <span class="nf">apply_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">),</span> <span class="s2">&quot;Predictions must be a tensor&quot;</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>
        <span class="k">return</span> <span class="n">predictions</span>


<span class="nd">@Block</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">register_with_multiple_names</span><span class="p">(</span><span class="s2">&quot;weight-tying&quot;</span><span class="p">)</span>
<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin_models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ItemsPredictionWeightTying</span><span class="p">(</span><span class="n">Block</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tying the item embedding weights with the output projection layer matrix [1]</span>
<span class="sd">    The output logits are obtained by multiplying the output vector by the item-ids embeddings.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        schema : Schema</span>
<span class="sd">            The `Schema` with the input features</span>
<span class="sd">        bias_initializer : str, optional</span>
<span class="sd">            Initializer to use on the bias vector, by default &quot;zeros&quot;</span>

<span class="sd">    References:</span>
<span class="sd">    -----------</span>
<span class="sd">    [1] Hakan, Inan et al.</span>
<span class="sd">        &quot;Tying word vectors and word classifiers: A loss framework for language modeling&quot;</span>
<span class="sd">        arXiv:1611.01462</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ItemsPredictionWeightTying</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_initializer</span> <span class="o">=</span> <span class="n">bias_initializer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_id_feature_name</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">ITEM_ID</span><span class="p">)</span><span class="o">.</span><span class="n">column_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">categorical_cardinalities</span><span class="p">(</span><span class="n">schema</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">item_id_feature_name</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_domain</span> <span class="o">=</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">categorical_domains</span><span class="p">(</span><span class="n">schema</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">item_id_feature_name</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output_layer_bias&quot;</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,),</span>
            <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_initializer</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">embedding_table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="o">.</span><span class="n">get_embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_domain</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">embedding_table</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">logits</span>


<span class="k">def</span> <span class="nf">reshape_categorical_input_tensor_for_encoding</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span> <span class="n">feat_name</span><span class="p">,</span> <span class="n">features_2d_last_dim</span><span class="p">,</span> <span class="n">output_mode</span><span class="p">,</span> <span class="n">ensure_1d_for_one_hot_mode</span><span class="o">=</span><span class="kc">True</span>
<span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="nb">input</span>
    <span class="n">reshape_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">reshape</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span>
    <span class="k">if</span> <span class="n">ensure_1d_for_one_hot_mode</span> <span class="ow">and</span> <span class="n">output_mode</span> <span class="o">==</span> <span class="n">ONE_HOT</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">features_2d_last_dim</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">feat_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">input</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">reshape_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">feat_name</span> <span class="ow">in</span> <span class="n">features_2d_last_dim</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">input</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;One-hot accepts input tensors that are squeezable to 1D, but received&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; a tensor with shape: </span><span class="si">{</span><span class="nb">input</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># if feat_name in features_2d_last_dim or len(input.get_shape()) == 2:</span>
        <span class="k">if</span> <span class="n">feat_name</span> <span class="ow">in</span> <span class="n">features_2d_last_dim</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">input</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="p">):</span>
            <span class="c1"># Ensures that the shape is known to avoid error on graph mode</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">features_2d_last_dim</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">feat_name</span><span class="p">,</span> <span class="nb">input</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">reshape_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">expand_dims_fn</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">expand_dims</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span>
            <span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">expand_dims_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">output</span>


<span class="nd">@Block</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">register_with_multiple_names</span><span class="p">(</span><span class="s2">&quot;category_encoding&quot;</span><span class="p">)</span>
<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin_models&quot;</span><span class="p">)</span>
<span class="nd">@requires_schema</span>
<span class="k">class</span> <span class="nc">CategoryEncoding</span><span class="p">(</span><span class="n">TabularBlock</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A preprocessing layer which encodes integer features.</span>

<span class="sd">    This layer provides options for condensing data into a categorical encoding. It accepts integer</span>
<span class="sd">    values as inputs, and it outputs a dense or sparse representation of those inputs. Only</span>
<span class="sd">    categorical features with &quot;CATEGORICAL&quot; as Tag can be transformed, and other features without</span>
<span class="sd">    this Tag would be discarded.</span>
<span class="sd">    It outputs a TabularData (Dict of features), where each feature is a 2D tensor computed</span>
<span class="sd">    based on the outputmode.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ----------</span>
<span class="sd">    schema : Optional[Schema]</span>
<span class="sd">        The `Schema` with the input features</span>
<span class="sd">    output_mode: Optional[str]</span>
<span class="sd">        Specification for the output of the layer. Defaults to `&quot;multi_hot&quot;`. Values can be</span>
<span class="sd">        &quot;one_hot&quot;, &quot;multi_hot&quot; or &quot;count&quot;, configuring the transformation layer as follows:</span>
<span class="sd">        - &quot;one_hot&quot;: Encodes each individual element in the input into a tensor with shape</span>
<span class="sd">            (batch_size, feature_cardinality), containing a 1 at the element index.</span>
<span class="sd">            It accepts both 1D tensor or 2D tensor if squeezable (i.e., if the last dimension is 1).</span>
<span class="sd">        - &quot;multi_hot&quot;: Encodes each categorical value from the 2D input features into a</span>
<span class="sd">            multi-hot representation with shape (batch_size, feature_cardinality), with 1 at</span>
<span class="sd">            the indices present in the sequence and 0 for the other position.</span>
<span class="sd">            If 1D feature is provided, it behaves the same as &quot;one_hot&quot;.</span>
<span class="sd">        - &quot;count&quot;: also expects 2D tensor like `&quot;multi_hot&quot;` and outputs the features</span>
<span class="sd">            with shape (batch_size, feature_cardinality). But instead of returning &quot;multi-hot&quot;</span>
<span class="sd">            values, it outputs the frequency (count) of the number of items each item occurs</span>
<span class="sd">            in each sample.</span>
<span class="sd">    sparse: Optional[Boolean]</span>
<span class="sd">        If true, returns a `SparseTensor` instead of a dense `Tensor`. Defaults to `False`.</span>
<span class="sd">        Setting sparse=True is recommended for high-cardinality features, in order to avoid</span>
<span class="sd">        out-of-memory errors.</span>
<span class="sd">    count_weights: Optional[Union(tf.Tensor, tf.RaggedTensor, tf.SparseTensor)]</span>
<span class="sd">        count_weights is used to calculate weighted sum of times a token at that index appeared when</span>
<span class="sd">        `output_mode` is &quot;count&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_mode</span><span class="o">=</span><span class="s2">&quot;one_hot&quot;</span><span class="p">,</span>
        <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">count_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">schema</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_schema</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">CATEGORICAL</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cardinalities</span> <span class="o">=</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">categorical_cardinalities</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">)</span>
        <span class="c1"># &#39;output_mode&#39; must be one of (COUNT, ONE_HOT, MULTI_HOT)</span>
        <span class="n">layer_utils</span><span class="o">.</span><span class="n">validate_string_arg</span><span class="p">(</span>
            <span class="n">output_mode</span><span class="p">,</span>
            <span class="n">allowable_strings</span><span class="o">=</span><span class="p">(</span><span class="n">COUNT</span><span class="p">,</span> <span class="n">ONE_HOT</span><span class="p">,</span> <span class="n">MULTI_HOT</span><span class="p">),</span>
            <span class="n">layer_name</span><span class="o">=</span><span class="s2">&quot;CategoryEncoding&quot;</span><span class="p">,</span>
            <span class="n">arg_name</span><span class="o">=</span><span class="s2">&quot;output_mode&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span> <span class="o">=</span> <span class="n">output_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>
        <span class="k">if</span> <span class="n">count_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span> <span class="o">!=</span> <span class="n">COUNT</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;`count_weights` is not used when `output_mode` is not &quot;</span>
                    <span class="s2">&quot;`&#39;count&#39;`. Received `count_weights=</span><span class="si">{count_weights}</span><span class="s2">`.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">count_weights</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">ensure_tensor</span><span class="p">(</span><span class="n">count_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">count_weights</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Used to reshape 1D&lt;-&gt;2Dtensors depending on the output_mode, when in graph mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_2d_last_dim</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">TabularData</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TabularData</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">depth</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cardinalities</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># Ensures the input is a Tensor, SparseTensor, then convert to Tensor</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;All `CategoryEncoding` inputs should not contain a RaggedTensor. Received &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> with type of </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">name</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="n">assertion_min_rank</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Assert</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">name</span><span class="p">]),</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">name</span><span class="p">]),</span> <span class="mi">2</span><span class="p">),</span>
                <span class="p">),</span>
                <span class="p">[</span>
                    <span class="s2">&quot;`CategoryEncoding` only accepts 1D or 2D-shaped inputs, but got &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;different rank for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">],</span>
            <span class="p">)</span>

            <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">ensure_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
                <span class="n">max_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
                <span class="n">min_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">max_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                <span class="n">min_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
            <span class="n">condition</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">max_value</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">max_value</span><span class="p">),</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">min_value</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">min_value</span><span class="o">.</span><span class="n">dtype</span><span class="p">)),</span>
            <span class="p">)</span>
            <span class="n">assertion_valid_values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Assert</span><span class="p">(</span>
                <span class="n">condition</span><span class="p">,</span>
                <span class="p">[</span>
                    <span class="s2">&quot;Input values must be in the range 0 &lt;= values &lt; num_tokens&quot;</span>
                    <span class="s2">&quot; with num_tokens=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">depth</span><span class="p">)</span>
                <span class="p">],</span>
            <span class="p">)</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">assertion_min_rank</span><span class="p">,</span> <span class="n">assertion_valid_values</span><span class="p">]):</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">reshape_categorical_input_tensor_for_encoding</span><span class="p">(</span>
                    <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span>
                    <span class="n">name</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">features_2d_last_dim</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span><span class="p">,</span>
                    <span class="n">ensure_1d_for_one_hot_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">encode_categorical_inputs</span><span class="p">(</span>
                    <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span>
                    <span class="n">output_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span><span class="p">,</span>
                    <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">,</span>
                    <span class="n">sparse</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">,</span>
                    <span class="n">count_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">count_weights</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
                    <span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shapes</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
            <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_shapes</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">input_shape</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">cardinalities</span><span class="p">[</span><span class="n">key</span><span class="p">]])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cardinalities</span><span class="p">[</span><span class="n">key</span><span class="p">]])</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">features_2d_last_dim</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">:</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;schema&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">schema_to_tensorflow_metadata_json</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">)</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;output_mode&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span><span class="p">,</span>
                <span class="s2">&quot;sparse&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">,</span>
                <span class="s2">&quot;count_weights&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_weights</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_weights</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>


<span class="nd">@Block</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">register_with_multiple_names</span><span class="p">(</span><span class="s2">&quot;label_to_onehot&quot;</span><span class="p">)</span>
<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin_models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LabelToOneHot</span><span class="p">(</span><span class="n">Block</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Transform the categorical encoded labels into a one-hot representation&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_shape</span>

    <span class="k">def</span> <span class="nf">call_outputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">PredictionOutput</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;PredictionOutput&quot;</span><span class="p">:</span>
        <span class="n">targets</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">predictions</span>

        <span class="n">num_classes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">predictions</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">transform_label_to_onehot</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="o">.</span><span class="n">copy_with_updates</span><span class="p">(</span><span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>


<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin_models&quot;</span><span class="p">)</span>
<span class="nd">@requires_schema</span>
<span class="k">class</span> <span class="nc">PopularityLogitsCorrection</span><span class="p">(</span><span class="n">Block</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Correct the predicted logit scores based on the item frequency,</span>
<span class="sd">    using the logQ correction proposed in sampled softmax [1]_ [2]_.</span>
<span class="sd">    The correction is done as `logits -= log(item_prob)`,</span>
<span class="sd">    where `item_prob = item_freq_count / sum(item_freq_count)` is</span>
<span class="sd">    a probability distribution of the item frequency. In a nutshell,</span>
<span class="sd">    the logQ correction aims to increase the prediction scores (logits)</span>
<span class="sd">    for infrequent items and decrease the ones for frequent items.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Yoshua Bengio and Jean-Sbastien Sncal. 2003. Quick Training of Probabilistic</span>
<span class="sd">       Neural Nets by Importance Sampling. In Proceedings of the conference on Artificial</span>
<span class="sd">       Intelligence and Statistics (AISTATS).</span>

<span class="sd">    .. [2] Y. Bengio and J. S. Senecal. 2008. Adaptive Importance Sampling to Accelerate</span>
<span class="sd">       Training of a Neural Probabilistic Language Model. Trans. Neur. Netw. 19, 4 (April</span>
<span class="sd">       2008), 713722. https://doi.org/10.1109/TNN.2007.912312</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ----------</span>
<span class="sd">    item_freq_probs : Union[tf.Tensor, Sequence]</span>
<span class="sd">        A Tensor or list with item frequencies (if is_prob_distribution=False)</span>
<span class="sd">        or with item probabilities (if is_prob_distribution=True)</span>
<span class="sd">    is_prob_distribution: bool, optional</span>
<span class="sd">        If True, the item_freq_probs should be a probability distribution of the items.</span>
<span class="sd">        If False, the item frequencies is converted to probabilities</span>
<span class="sd">    reg_factor: float</span>
<span class="sd">        Factor to scale the logq correction, by default 1.0</span>
<span class="sd">    schema: Schema, optional</span>
<span class="sd">        The `Schema` with input features,</span>
<span class="sd">        by default None</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">item_freq_probs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">is_prob_distribution</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">reg_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">schema</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reg_factor</span> <span class="o">=</span> <span class="n">reg_factor</span>

        <span class="k">if</span> <span class="n">item_freq_probs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_items_cardinality</span><span class="p">(</span><span class="n">item_freq_probs</span><span class="p">)</span>
            <span class="n">candidate_probs</span> <span class="o">=</span> <span class="n">get_candidate_probs</span><span class="p">(</span><span class="n">item_freq_probs</span><span class="p">,</span> <span class="n">is_prob_distribution</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">candidate_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
                <span class="n">candidate_probs</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;candidate_probs&quot;</span><span class="p">,</span>
                <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="n">validate_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">candidate_probs</span><span class="p">),</span>
            <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_parquet</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">parquet_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">frequencies_probs_col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">is_prob_distribution</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load the item frequency table from a parquet file</span>
<span class="sd">        (in the format automatically generated by NVTabular with workflow.fit()).</span>
<span class="sd">        It supposed the parquet file has a single column with the item frequencies</span>
<span class="sd">        and is indexed by item ids.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        parquet_path : str</span>
<span class="sd">            Path to the parquet file</span>
<span class="sd">        frequencies_probs_col : str</span>
<span class="sd">            Column name containing the items frequencies / probabilities</span>
<span class="sd">        is_prob_distribution: bool, optional</span>
<span class="sd">            If True, the frequencies_probs_col should contain the probability</span>
<span class="sd">            distribution of the items. If False, the frequencies_probs_col values</span>
<span class="sd">            are frequencies and will be converted to probabilities</span>
<span class="sd">        gpu : bool, optional</span>
<span class="sd">            Whether to load data using cudf, by default True</span>
<span class="sd">        schema: Schema, optional</span>
<span class="sd">            The `Schema` with input features,</span>
<span class="sd">            by default None</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            An instance of PopularityLogitsCorrection</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: Use the schema to infer the path to the item frequency parquet table</span>
        <span class="k">if</span> <span class="n">gpu</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">cudf</span>

            <span class="n">df</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">)</span>
            <span class="n">item_frequency</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">df_to_tensor</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">frequencies_probs_col</span><span class="p">]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">)</span>
            <span class="n">item_frequency</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">frequencies_probs_col</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">item_freq_probs</span><span class="o">=</span><span class="n">item_frequency</span><span class="p">,</span>
            <span class="n">is_prob_distribution</span><span class="o">=</span><span class="n">is_prob_distribution</span><span class="p">,</span>
            <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_candidate_probs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_probs</span><span class="o">.</span><span class="n">value</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">item_freq_probs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">],</span> <span class="n">is_prob_distribution</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Updates the item frequencies / probabilities</span>

<span class="sd">        Parameters:</span>
<span class="sd">        ----------</span>
<span class="sd">        item_freq_probs : Union[tf.Tensor, Sequence]</span>
<span class="sd">            A Tensor or list with item frequencies (if is_prob_distribution=False)</span>
<span class="sd">            or with item probabilities (if is_prob_distribution=True)</span>
<span class="sd">        is_prob_distribution: bool, optional</span>
<span class="sd">            If True, the item_freq_probs should be a probability distribution of the items.</span>
<span class="sd">            If False, the item frequencies is converted to probabilities</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_items_cardinality</span><span class="p">(</span><span class="n">item_freq_probs</span><span class="p">)</span>
        <span class="n">candidate_probs</span> <span class="o">=</span> <span class="n">get_candidate_probs</span><span class="p">(</span><span class="n">item_freq_probs</span><span class="p">,</span> <span class="n">is_prob_distribution</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">candidate_probs</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">candidate_probs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_shape</span>

    <span class="k">def</span> <span class="nf">call_outputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">PredictionOutput</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;PredictionOutput&quot;</span><span class="p">:</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">predictions</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">positive_item_ids</span><span class="p">,</span> <span class="n">negative_item_ids</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">outputs</span><span class="o">.</span><span class="n">positive_item_ids</span><span class="p">,</span>
                <span class="n">outputs</span><span class="o">.</span><span class="n">negative_item_ids</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">positive_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_probs</span><span class="p">,</span> <span class="n">positive_item_ids</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">negative_item_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">negative_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_probs</span><span class="p">,</span> <span class="n">negative_item_ids</span><span class="p">)</span>
                <span class="c1"># repeat negative scores for each positive item</span>
                <span class="n">negative_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">negative_probs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">positive_item_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]),</span>
                    <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">negative_item_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="p">)</span>
                <span class="n">positive_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">positive_probs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">negative_probs</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
                <span class="p">)</span>

            <span class="c1"># Applies the logQ correction</span>
            <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-16</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_factor</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">positive_probs</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="o">.</span><span class="n">copy_with_updates</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_items_cardinality</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_freq_probs</span><span class="p">):</span>
        <span class="n">cardinalities</span> <span class="o">=</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">categorical_cardinalities</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">)</span>
        <span class="n">item_id_feature_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">ITEM_ID</span><span class="p">)</span><span class="o">.</span><span class="n">column_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">item_freq_probs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">cardinalities</span><span class="p">[</span><span class="n">item_id_feature_name</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The item frequency table length does not match the item ids cardinality&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;(expected </span><span class="si">{</span><span class="n">cardinalities</span><span class="p">[</span><span class="n">item_id_feature_name</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;, got </span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">item_freq_probs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>


<span class="nd">@Block</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;hashed_cross&quot;</span><span class="p">)</span>
<span class="nd">@tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">(</span><span class="n">package</span><span class="o">=</span><span class="s2">&quot;merlin.models&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">HashedCross</span><span class="p">(</span><span class="n">TabularBlock</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A transformation block which crosses categorical features using the &quot;hashing trick&quot;.</span>
<span class="sd">    Conceptually, the transformation can be thought of as: hash(concatenation of features) %</span>
<span class="sd">    num_bins</span>
<span class="sd">    Example usage::</span>
<span class="sd">    model_body = ParallelBlock(</span>
<span class="sd">                TabularBlock.from_schema(schema=cross_schema, pre=ml.HashedCross(cross_schema,</span>
<span class="sd">                                        num_bins = 1000)),</span>
<span class="sd">                is_input=True).connect(ml.MLPBlock([64, 32]))</span>
<span class="sd">    model = ml.Model(model_body, ml.BinaryClassificationTask(&quot;click&quot;))</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        schema : Schema</span>
<span class="sd">            The `Schema` with the input features</span>
<span class="sd">        num_bins : int</span>
<span class="sd">            Number of hash bins.</span>
<span class="sd">        output_mode: string</span>
<span class="sd">            Specification for the output of the layer. Defaults to &quot;one_hot&quot;.  Values can be &quot;int&quot;,</span>
<span class="sd">            or &quot;one_hot&quot;, configuring the layer as follows:</span>
<span class="sd">            - `&quot;int&quot;`: Return the integer bin indices directly.</span>
<span class="sd">            - `&quot;one_hot&quot;`: Encodes each individual element in the input into an array with the same</span>
<span class="sd">                size as `num_bins`, containing a 1 at the input&#39;s bin index.</span>
<span class="sd">        sparse: bool</span>
<span class="sd">            Boolean. Only applicable to `&quot;one_hot&quot;` mode. If True, returns a `SparseTensor` instead</span>
<span class="sd">            of a dense `Tensor`. Defaults to False.</span>
<span class="sd">        output_name: string</span>
<span class="sd">            Name of output feature, if not specified, default would be</span>
<span class="sd">            cross_&lt;feature_name&gt;_&lt;feature_name&gt;_&lt;...&gt;</span>
<span class="sd">        infer_num_bins: bool</span>
<span class="sd">            If True, num_bins would be set as the multiplier of feature cadinalities, if the</span>
<span class="sd">            multiplier is bigger than max_num_bins, then it would be cliped by max_num_bins</span>
<span class="sd">        max_num_bins: int</span>
<span class="sd">            Upper bound of num_bins, by default 100000.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span><span class="p">,</span>
        <span class="n">num_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sparse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">output_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;one_hot&quot;</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">infer_num_bins</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">max_num_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">infer_num_bins</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num_bins</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;num_bins is not given, and infer_num_bins is False, either of them &quot;</span>
                <span class="s2">&quot;is required, if you want to set fixed num_bins, then set infer_num_bins to False,&quot;</span>
                <span class="s2">&quot; and set num_bins to an integer value, if you want to infer num_bins from the &quot;</span>
                <span class="s2">&quot;mulplier of feature cardinalities, at the same time you can set the max_num_bins.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">output_mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="s2">&quot;one_hot&quot;</span><span class="p">,</span> <span class="s2">&quot;multi_hot&quot;</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;output_mode must be &#39;int&#39;, &#39;one_hot&#39;, or &#39;multi_hot&#39;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span> <span class="o">=</span> <span class="n">output_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_name</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_name</span> <span class="o">=</span> <span class="s2">&quot;cross&quot;</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">column_names</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_name</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">name</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_name</span> <span class="o">=</span> <span class="n">output_name</span>

        <span class="c1"># Set num_bins</span>
        <span class="k">if</span> <span class="n">num_bins</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_bins</span> <span class="o">=</span> <span class="n">num_bins</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cardinalities</span> <span class="o">=</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">categorical_cardinalities</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
            <span class="n">inferred_num_bins_from_cardinalities_multiplier</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">for</span> <span class="n">cardinality</span> <span class="ow">in</span> <span class="n">cardinalities</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="n">inferred_num_bins_from_cardinalities_multiplier</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">inferred_num_bins_from_cardinalities_multiplier</span> <span class="o">*</span> <span class="n">cardinality</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_bins</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">max_num_bins</span><span class="p">,</span> <span class="n">inferred_num_bins_from_cardinalities_multiplier</span><span class="p">))</span>

        <span class="c1"># Used to enforce the shape of 2D tensors depending on the output_mode, when in graph mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_2d_last_dim</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_at_least_two_inputs</span><span class="p">()</span>

        <span class="n">_inputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>

            <span class="n">assertion_min_rank</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Assert</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">name</span><span class="p">]),</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">name</span><span class="p">]),</span> <span class="mi">2</span><span class="p">),</span>
                <span class="p">),</span>
                <span class="p">[</span>
                    <span class="s2">&quot;`HashedCross` only accepts 1D or 2D-shaped inputs, but got &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;different rank for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">],</span>
            <span class="p">)</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">assertion_min_rank</span><span class="p">]):</span>
                <span class="n">_inputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">reshape_categorical_input_tensor_for_encoding</span><span class="p">(</span>
                    <span class="n">inputs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span>
                    <span class="n">name</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">features_2d_last_dim</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span><span class="p">,</span>
                    <span class="n">ensure_1d_for_one_hot_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># Perform the cross and convert to dense</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">cross_hashed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">_inputs</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_bins</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span> <span class="o">==</span> <span class="n">ONE_HOT</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># Encode outputs.</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">preprocessing_utils</span><span class="o">.</span><span class="n">encode_categorical_inputs</span><span class="p">(</span>
            <span class="n">output</span><span class="p">,</span>
            <span class="n">output_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span><span class="p">,</span>
            <span class="n">depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_bins</span><span class="p">,</span>
            <span class="n">sparse</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_name</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
            <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_name</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shapes</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_at_least_two_inputs</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_input_shape_and_type</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)</span>

        <span class="c1"># Save the last dim for 2D features so that we can reshape them in graph mode in call()</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
            <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_shapes</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">features_2d_last_dim</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">output_shape</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_batch_size_from_input_shapes</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)</span>
        <span class="n">output_shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">preprocessing_utils</span><span class="o">.</span><span class="n">compute_shape_for_encode_categorical</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">output_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_bins</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">output_shape</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;num_bins&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_bins</span><span class="p">,</span>
                <span class="s2">&quot;output_mode&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_mode</span><span class="p">,</span>
                <span class="s2">&quot;sparse&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">,</span>
                <span class="s2">&quot;output_name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_name</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">:</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;schema&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">schema_to_tensorflow_metadata_json</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>

    <span class="k">def</span> <span class="nf">_check_at_least_two_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;`HashedCross` should be called on at least two features. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Received: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">)</span><span class="si">}</span><span class="s2"> schemas&quot;</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">column_schema</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">column_schemas</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">Tags</span><span class="o">.</span><span class="n">CATEGORICAL</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">column_schema</span><span class="o">.</span><span class="n">tags</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Please make sure input features to be categorical, detect </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="s2">&quot;has no categorical tag&quot;</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_input_shape_and_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs_shapes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TabularData</span><span class="p">:</span>
        <span class="n">_inputs_shapes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">inputs_shapes</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">shape</span><span class="o">.</span><span class="n">rank</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;All `HashedCross` inputs should have 1D or 2D shape. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Received: input </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> with shape=</span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="n">_inputs_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">_inputs_shapes</span><span class="p">]))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;All `HashedCross` inputs should have equal first dim (batch size). &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Received: inputs=</span><span class="si">{</span><span class="n">_inputs_shapes</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>


<span class="k">def</span> <span class="nf">HashedCrossAll</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">infer_num_bins</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">max_num_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span>
    <span class="n">max_level</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">sparse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">output_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;one_hot&quot;</span><span class="p">,</span>
    <span class="n">ignore_combinations</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Block</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Parallel block consists of HashedCross blocks for all combinations of schema with all levels</span>
<span class="sd">        through level 2 to max_level.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ----------</span>
<span class="sd">    schema: Schema</span>
<span class="sd">        Schema of the input data.</span>
<span class="sd">    max_level: int</span>
<span class="sd">        Max num of levels, this function would hash cross all combinations, the number of features</span>
<span class="sd">        included in these combinations is in the range from 2 to max_level, i.e. [2, max_level], by</span>
<span class="sd">        default 2, which means it would return hashed cross blocks of all level 2 combinations of</span>
<span class="sd">        features within schema</span>

<span class="sd">        For example, if schemas contain 3 features: feature_1, feature_2 and feature_3, if we call</span>
<span class="sd">            `level_3_cross = HashedCrossAll(schema = schemas, max_level = 3)`</span>
<span class="sd">        Then level_3_cross is a Parallel block, which contains 4 hashed crosses of</span>
<span class="sd">            1) feature_1 and feature_2</span>
<span class="sd">            2) feature_1 and feature_3</span>
<span class="sd">            3) feature_2 and feature_3</span>
<span class="sd">            4) feature_1, feature_2 and feature_3</span>
<span class="sd">    num_bins : int</span>
<span class="sd">        Number of hash bins, note that num_bins is for all hashed cross transformation block, no</span>
<span class="sd">        matter what level it is, if you want to set different num_bins for different hashed cross,</span>
<span class="sd">        please use HashedCross to define each one with different num_bins.</span>
<span class="sd">    output_mode: string</span>
<span class="sd">        Specification for the output of the layer. Defaults to</span>
<span class="sd">        `&quot;one_hot&quot;`.  Values can be `&quot;int&quot;`, or `&quot;one_hot&quot;` configuring the layer as</span>
<span class="sd">        follows:</span>
<span class="sd">        - `&quot;int&quot;`: Return the integer bin indices directly.</span>
<span class="sd">        - `&quot;one_hot&quot;`: Encodes each individual element in the input into an</span>
<span class="sd">            array the same size as `num_bins`, containing a 1 at the input&#39;s bin</span>
<span class="sd">            index.</span>
<span class="sd">    sparse : bool</span>
<span class="sd">        Boolean. Only applicable to `&quot;one_hot&quot;` mode. If True, returns a</span>
<span class="sd">        `SparseTensor` instead of a dense `Tensor`. Defaults to False.</span>
<span class="sd">    infer_num_bins: bool</span>
<span class="sd">        If True, all num_bins would be set as the multiplier of corresponding feature cadinalities,</span>
<span class="sd">        if the multiplier is bigger than max_num_bins, then it would be cliped by max_num_bins</span>
<span class="sd">    max_num_bins: int</span>
<span class="sd">        Upper bound of num_bins for all hashed cross transformation blocks, by default 100000.</span>

<span class="sd">    ignore_combinations :  Sequence[Sequence[str]]</span>
<span class="sd">        If provided, ignore feature combinations from this list.</span>
<span class="sd">        Useful to avoid interacting features whose combined value is always the same.</span>
<span class="sd">        For example, interacting these features is not useful and one of the features</span>
<span class="sd">        is dependent on the other :</span>
<span class="sd">        [[&quot;item_id&quot;, &quot;item_category&quot;], [&quot;user_id&quot;, &quot;user_birth_city&quot;, &quot;user_age&quot;]]</span>


<span class="sd">    Example usage::</span>

<span class="sd">        level_3_cross = HashedCrossAll(schema = schemas, max_level = 3, infer_num_bins = True)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">max_level</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">max_level</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Please make sure 1 &lt; max_level &lt; 4, because the cross transformation requires at &quot;</span>
            <span class="s2">&quot;least 2 features, and HashedCrossAll only support at most 3 level, if you want to &quot;</span>
            <span class="s2">&quot;cross more than 3 features, please use HashedCross. Received: max_level = </span><span class="si">{max_level}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;`HashedCrossing` should be called on at least two features. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Received: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span><span class="si">}</span><span class="s2"> schemas&quot;</span>
        <span class="p">)</span>

    <span class="n">all_combinations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">combination_tuple</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">all_combinations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">combination_tuple</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">max_level</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">combination_tuple</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
            <span class="n">all_combinations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">combination_tuple</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">ignore_combinations</span><span class="p">:</span>
        <span class="n">ignore_combinations_set</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span><span class="nb">set</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">ignore_combinations</span><span class="p">])</span>
        <span class="n">all_combinations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">combination</span>
                <span class="k">for</span> <span class="n">combination</span> <span class="ow">in</span> <span class="n">all_combinations</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">combination</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ignore_combinations_set</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>

    <span class="n">hashed_crosses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">schema_names</span> <span class="ow">in</span> <span class="n">all_combinations</span><span class="p">:</span>
        <span class="n">hashed_crosses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">HashedCross</span><span class="p">(</span>
                <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="o">.</span><span class="n">select_by_name</span><span class="p">(</span><span class="n">schema_names</span><span class="p">),</span>
                <span class="n">num_bins</span><span class="o">=</span><span class="n">num_bins</span><span class="p">,</span>
                <span class="n">sparse</span><span class="o">=</span><span class="n">sparse</span><span class="p">,</span>
                <span class="n">output_mode</span><span class="o">=</span><span class="n">output_mode</span><span class="p">,</span>
                <span class="n">infer_num_bins</span><span class="o">=</span><span class="n">infer_num_bins</span><span class="p">,</span>
                <span class="n">max_num_bins</span><span class="o">=</span><span class="n">max_num_bins</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">ParallelBlock</span><span class="p">(</span><span class="n">hashed_crosses</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v0.7.0
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../../../../../v0.4.0/index.html">v0.4.0</a></dd>
      <dd><a href="../../../../../../v0.5.0/index.html">v0.5.0</a></dd>
      <dd><a href="../../../../../../v0.6.0/index.html">v0.6.0</a></dd>
      <dd><a href="transformations.html">v0.7.0</a></dd>
      <dd><a href="../../../../../../v0.8.0/index.html">v0.8.0</a></dd>
      <dd><a href="../../../../../../v0.9.0/index.html">v0.9.0</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../../../../../main/index.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>