{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb28e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77464844",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Getting Started with Merlin Models: Develop a Model for MovieLens\n",
    "\n",
    "## Overview\n",
    "\n",
    "[Merlin Models](https://github.com/NVIDIA-Merlin/models/) is a library for training recommender models. Merlin Models let Data Scientists and ML Engineers easily train standard RecSys models on their own dataset, getting GPU-accelerated models with best practices baked into the library. This will also let researchers to build custom models by incorporating standard components of deep learning recommender models, and then benchmark their new models on example offline datasets. Merlin Models is part of the [Merlin open source framework](https://developer.nvidia.com/nvidia-merlin).\n",
    "\n",
    "Core features are:\n",
    "- Many different recommender system architectures (tabular, two-tower, sequential) or tasks (binary, multi-class classification, multi-task)\n",
    "- Flexible APIs targeted to both production and research\n",
    "- Deep integration with NVIDIA Merlin platform, including NVTabular for ETL and Merlin Systems model serving\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Training [Facebook's DLRM model](https://arxiv.org/pdf/1906.00091.pdf) very easily with our high-level API.\n",
    "- Understanding Merlin Models high-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5598ae",
   "metadata": {},
   "source": [
    "## Downloading and preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60653f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 16:24:05.620762: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:24:07.820943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16249 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n",
      "2022-03-30 16:24:07.822085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30611 MB memory:  -> device: 1, name: Quadro GV100, pci bus id: 0000:2d:00.0, compute capability: 7.0\n",
      "/home/gmoreira/projects/nvidia/nvidia_merlin/NVTabular/nvtabular/graph.py:23: FutureWarning: The `nvtabular.graph` module has moved to `merlin.dag`. Support for importing from `nvtabular.graph` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.dag`.\n",
      "  warnings.warn(\n",
      "/home/gmoreira/projects/nvidia/nvidia_merlin/NVTabular/nvtabular/io.py:23: FutureWarning: The `nvtabular.io` module has moved to `merlin.io`. Support for importing from `nvtabular.io` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.io`.\n",
      "  warnings.warn(\n",
      "/home/gmoreira/projects/nvidia/nvidia_merlin/NVTabular/nvtabular/utils.py:23: FutureWarning: The `nvtabular.utils` module has moved to `merlin.core.utils`. Support for importing from `nvtabular.utils` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.core.utils`.\n",
      "  warnings.warn(\n",
      "/home/gmoreira/projects/nvidia/nvidia_merlin/NVTabular/nvtabular/dispatch.py:23: FutureWarning: The `nvtabular.dispatch` module has moved to `merlin.core.dispatch`. Support for importing from `nvtabular.dispatch` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.core.dispatch`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import merlin.models.tf as mm\n",
    "\n",
    "from merlin.models.data.movielens import get_movielens\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327924b",
   "metadata": {},
   "source": [
    "We provide the `get_movielens()` function as a convenience to download the dataset, perform simple preprocessing, and split the data into training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba8b53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreira/miniconda3/envs/merlin_22.04_dev/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train, valid = get_movielens(variant=\"ml-1m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee5c7c2",
   "metadata": {},
   "source": [
    "## Training the DLRM Model with Merlin Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b89c7",
   "metadata": {},
   "source": [
    "We define the DLRM model, whose prediction task is a binary classification. From the `schema`, the categorical features are identified (and embedded) and the target column is also automatically inferred, because of the schema tags. We talk more about the schema in the example notebook [02-Merlin-Models-and-NVTabular-applying-to-your-own-dataset](02-Merlin-Models-and-NVTabular-applying-to-your-own-dataset),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b8942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mm.DLRMModel(\n",
    "    train.schema,\n",
    "    embedding_dim=64,\n",
    "    bottom_block=mm.MLPBlock([128, 64]),\n",
    "    top_block=mm.MLPBlock([128, 64, 32]),\n",
    "    prediction_tasks=mm.BinaryClassificationTask(\n",
    "        train.schema.select_by_tag(Tags.TARGET).column_names[0]\n",
    "    ),\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee4cef",
   "metadata": {},
   "source": [
    "Next, we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33343067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 16:24:08.840469: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 10ms/step - rating_binary/binary_classification_task/precision: 0.7113 - rating_binary/binary_classification_task/recall: 0.8239 - rating_binary/binary_classification_task/binary_accuracy: 0.7065 - rating_binary/binary_classification_task/auc: 0.7682 - loss: 0.5637 - regularization_loss: 0.0000e+00 - total_loss: 0.5637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73a836cbb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd668ab",
   "metadata": {},
   "source": [
    "We evaluate the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d60260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/196 [..............................] - ETA: 2:25 - rating_binary/binary_classification_task/precision: 0.7307 - rating_binary/binary_classification_task/recall: 0.8037 - rating_binary/binary_classification_task/binary_accuracy: 0.7109 - rating_binary/binary_classification_task/auc: 0.7813 - loss: 0.5439 - regularization_loss: 0.0000e+00 - total_loss: 0.5439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 16:24:20.062458: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: cond/then/_0/cond/cond/branch_executed/_101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 2s 7ms/step - rating_binary/binary_classification_task/precision: 0.7329 - rating_binary/binary_classification_task/recall: 0.8211 - rating_binary/binary_classification_task/binary_accuracy: 0.7247 - rating_binary/binary_classification_task/auc: 0.7884 - loss: 0.5430 - regularization_loss: 0.0000e+00 - total_loss: 0.5430\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(valid, batch_size=1024, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9afe7",
   "metadata": {},
   "source": [
    "... and check the evaluation metrics. We use by default typical binary classification metrics -- Precision, Recall, Accuracy and AUC. But you can also provide your own metrics list by setting `BinaryClassificationTask(..., metrics=[])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d415278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rating_binary/binary_classification_task/precision': 0.7329489588737488,\n",
       " 'rating_binary/binary_classification_task/recall': 0.8210552930831909,\n",
       " 'rating_binary/binary_classification_task/binary_accuracy': 0.7246914505958557,\n",
       " 'rating_binary/binary_classification_task/auc': 0.7884241342544556,\n",
       " 'loss': 0.5135267972946167,\n",
       " 'regularization_loss': 0.0,\n",
       " 'total_loss': 0.5135267972946167}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ad327",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba861b",
   "metadata": {},
   "source": [
    "Merlin Models enables users to define and train a deep learning recommeder model with only 3 commands.\n",
    "\n",
    "```python\n",
    "model = mm.DLRMModel(\n",
    "    train.schema,\n",
    "    embedding_dim=64,\n",
    "    bottom_block=mm.MLPBlock([128, 64]),\n",
    "    top_block=mm.MLPBlock([128, 64, 32]),\n",
    "    prediction_tasks=mm.BinaryClassificationTask(\n",
    "        train.schema.select_by_tag(Tags.TARGET).column_names[0]\n",
    "    ),\n",
    ")\n",
    "model.compile(optimizer=\"adam\")\n",
    "model.fit(train, batch_size=1024)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9180e84",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba3102",
   "metadata": {},
   "source": [
    "In the next example notebooks, we will show how the integration with NVTabular and how to explore different recommender models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
