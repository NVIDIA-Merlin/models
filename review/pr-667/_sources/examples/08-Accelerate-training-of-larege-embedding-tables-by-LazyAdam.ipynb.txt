{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e493825",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b423f1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Accelerate Training on Large Embedding Tables by LazyAdam \n",
    "\n",
    "This notebook is created using the latest stable [merlin-tensorflow](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags) container. \n",
    "\n",
    "Merlin Models provide various model APIs for training, as shown in Notebook [Iterating over Deep Learning Models using Merlin Models](https://nvidia-merlin.github.io/models/main/examples/03-Exploring-different-models.html). We can create a model, such as [Two Tower](https://nvidia-merlin.github.io/models/main/models_overview.html?highlight=two%20tower#two-tower), [DLRM](https://nvidia-merlin.github.io/models/main/examples/03-Exploring-different-models.html#dlrm-model) and so on, by simply one line: `model=mm.DLRMModel(schema)`. Some models contain large embedding tables, and training could be slow on such large sparse embeddings. However, this process could be accelerated by using a special optimizer, LazyAdam.\n",
    "\n",
    "In this example, we utilize LazyAdam for large embedding tables and nomal Adam for other trainable weights to accelerate the whole training process.\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "- Training a model with multiple optimizers\n",
    "- Utilizing LazyAdam for training on large embedding tables\n",
    "- Utilizing `find_blocks_by_name` to get a layer inside a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381c615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-14 06:05:07.036450: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-14 06:05:09.554587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16255 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#import merlin\n",
    "from merlin.datasets.synthetic import generate_data\n",
    "import merlin.models.tf as ml\n",
    "from merlin.schema import Schema, Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d1408",
   "metadata": {},
   "source": [
    "## Generate Synthetic Dataset\n",
    "To generate the synthetic dataset for our example, we can use `generate_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36681a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS = 1000000\n",
    "train, valid = generate_data(\"e-commerce-large\", int(NUM_ROWS), set_sizes=(0.7, 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c62e9b",
   "metadata": {},
   "source": [
    "We can print out the feature column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3c1894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_categories',\n",
       " 'user_shops',\n",
       " 'user_brands',\n",
       " 'user_intentions',\n",
       " 'user_profile',\n",
       " 'user_group',\n",
       " 'user_gender',\n",
       " 'user_age',\n",
       " 'user_consumption_1',\n",
       " 'user_consumption_2',\n",
       " 'user_is_occupied',\n",
       " 'user_geography',\n",
       " 'user_id',\n",
       " 'item_category',\n",
       " 'item_shop',\n",
       " 'item_intention',\n",
       " 'item_brand',\n",
       " 'item_id',\n",
       " 'user_item_categories',\n",
       " 'user_item_shops',\n",
       " 'user_item_brands',\n",
       " 'user_item_intentions',\n",
       " 'position',\n",
       " 'click',\n",
       " 'conversion']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = train.schema\n",
    "schema.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a197d69",
   "metadata": {},
   "source": [
    "## Building a Two-Tower Model with Merlin Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b31f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings = ml.Embeddings(schema.select_by_tag(Tags.ITEM), infer_embedding_sizes=True)\n",
    "query_embeddings = ml.Embeddings(schema.select_by_tag(Tags.USER), infer_embedding_sizes=True)\n",
    "model = ml.TwoTowerModel(schema, \n",
    "                         item_tower=ml.InputBlockV2(schema.select_by_tag(Tags.ITEM), embeddings=item_embeddings).connect(ml.MLPBlock([64])), \n",
    "                         query_tower=ml.InputBlockV2(schema.select_by_tag(Tags.USER), embeddings=query_embeddings).connect(ml.MLPBlock([64])),\n",
    "                         samplers=[ml.InBatchSampler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99674d",
   "metadata": {},
   "source": [
    "The model initializer would infer the embedding table size from the schema, where the first dimension (`input_dim`) of each embedding table is the same as the cardinalities (categories) of each feature, and the second dimension is specified by the user. By setting `infer_embedding_sizes=True`, the initializer would infer the size based on the cardinalities: \n",
    "$$output\\_dim=\\left \\lfloor cardinality^{0.25}\\times multiplier \\right \\rfloor$$\n",
    "The multiplier is 8 by default.To achieve the best performance with GPU operators, we adjust the embedding dimensions to multiples of 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed1f36-68f5-4c03-be97-f59957ea66ff",
   "metadata": {},
   "source": [
    "## Apply Multiple Optimizers to the Model\n",
    "\n",
    "We usually set one optimizer to train a model, but for large embedding tables, at each batch, the weights to be updated could be really sparse, in other words, each time we only update the model based on a small batch of training data, so for a large embedding table (first dimension >>  batch size), at most batch_size rows would be updated. Thus in order to acceleate training on large embedding tables, we want to utilize the Lazy Adam for those large tables. \n",
    "\n",
    "Compared with Adam, Lazy Adam is optimized for sparse updates. It only update sparse variables indices for current batch. However it may result in slight difference in experiment results compared with Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555f84d-040f-432e-bd26-772761aadea3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split Embedding Tables based on the First Dimension (`input_dim`)\n",
    "Since we want to apply LazyAdam to these large tables, we have to split all tables into two sets. The result of `split_embeddings_on_size` (i.e. `item_large_tables` and `item_small_tables`) are two lists of embedding tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ab5d2a-6493-4bbf-9e31-94f5b545733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_large_tables, item_small_tables = ml.split_embeddings_on_size(item_embeddings, threshold=1000)\n",
    "query_large_tables, query_small_tables = ml.split_embeddings_on_size(query_embeddings, threshold=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f6af11-37a0-4cae-8443-997ede87c523",
   "metadata": {},
   "source": [
    "We can print out the size of each embedding table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705e2a95-37c9-4bc6-9092-cd2c1c1cff61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large embedding tables of query tower:\n",
      "user_categories first dimension:  6087 second dimension 24\n",
      "user_shops first dimension:  116742 second dimension 40\n",
      "user_brands first dimension:  58016 second dimension 32\n",
      "user_intentions first dimension:  33787 second dimension 32\n",
      "user_id first dimension:  294737 second dimension 48\n",
      "Small embedding tables of query tower:\n",
      "user_profile first dimension:  99 second dimension 8\n",
      "user_group first dimension:  15 second dimension 8\n",
      "user_gender first dimension:  4 second dimension 8\n",
      "user_age first dimension:  9 second dimension 8\n",
      "user_consumption_1 first dimension:  5 second dimension 8\n",
      "user_consumption_2 first dimension:  5 second dimension 8\n",
      "user_is_occupied first dimension:  4 second dimension 8\n",
      "user_geography first dimension:  6 second dimension 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Large embedding tables of query tower:\")\n",
    "for t in query_large_tables:\n",
    "    print(t.name, \"first dimension: \", t.input_dim, \"second dimension\", t.dim)\n",
    "print(\"Small embedding tables of query tower:\")\n",
    "for t in  query_small_tables:\n",
    "    print(t.name, \"first dimension: \", t.input_dim, \"second dimension\", t.dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb23734-e2ea-4cec-8cc9-5109be0d08b7",
   "metadata": {},
   "source": [
    "### Set MultiOptimizer\n",
    "\n",
    "The `MultiOptimizer` module enables multiple optimizers [(e.g. Adam, SGD, RMSProp, Adagrad)](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) to be used in different layers in parallel. Here we want to apply Lazy Adam for large embedding tables, while small embedding tables and all other layers with Adam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de3b8aac-44c1-4237-b31b-f025461ed2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ml.MultiOptimizer(\n",
    "                default_optimizer=\"adam\",\n",
    "                optimizers_and_blocks=[ml.OptimizerBlocks(ml.LazyAdam(), item_large_tables + query_large_tables),\n",
    "                                       ml.OptimizerBlocks(\"adam\", item_small_tables + query_small_tables)]\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c1351-1585-44ea-885b-e250d9e5c161",
   "metadata": {},
   "source": [
    "Note all other trainable parameters not specified an optimizer would use the `default_optimizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee6def-8d78-40bc-8072-53ba74853fc8",
   "metadata": {},
   "source": [
    "## Train the Model and Evaluate Training Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791e06ec-c0cb-4c0f-9e41-7e5c8fa1dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f84eb5a9100>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f84eb5a9100>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "684/684 [==============================] - 30s 18ms/step - loss: 6.9128 - recall_at_10: 0.0268 - mrr_at_10: 0.0217 - ndcg_at_10: 0.0229 - map_at_10: 0.0217 - precision_at_10: 0.0027 - regularization_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f807f26a040>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer)\n",
    "model.fit(train, batch_size=1024, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e9ab8-e27a-46e3-b006-7a494d1141f8",
   "metadata": {},
   "source": [
    "### Compare Training Time with Adam\n",
    "\n",
    "Now we create another same model and compile it with Adam optimizer. For this notebook, we use a single Tesla V100-SXM2-32GB-LS. The training result shows that for each step, it costs about 71ms. And as shown in above experiment, the training time with Lazy Adam is about 18 ms, it achieves about 4X speed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "822e3c73-dfa9-4da6-9b1a-41c9adb10617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 56s 71ms/step - loss: 6.9128 - recall_at_10: 0.0271 - mrr_at_10: 0.0197 - ndcg_at_10: 0.0214 - map_at_10: 0.0197 - precision_at_10: 0.0027 - regularization_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f807d5dab80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embeddings = ml.Embeddings(schema.select_by_tag(Tags.ITEM), infer_embedding_sizes=True)\n",
    "query_embeddings = ml.Embeddings(schema.select_by_tag(Tags.USER), infer_embedding_sizes=True)\n",
    "model = ml.TwoTowerModel(schema, \n",
    "                         item_tower=ml.InputBlockV2(schema.select_by_tag(Tags.ITEM), embeddings=item_embeddings).connect(ml.MLPBlock([64])), \n",
    "                         query_tower=ml.InputBlockV2(schema.select_by_tag(Tags.USER), embeddings=query_embeddings).connect(ml.MLPBlock([64])),\n",
    "                         samplers=[ml.InBatchSampler()],\n",
    ")\n",
    "model.compile(optimizer=\"adam\")\n",
    "model.fit(train, batch_size=1024, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4799a038-1903-4613-b727-44076d374a02",
   "metadata": {},
   "source": [
    "## Retrieve Layers Inside a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29823f29-6e2b-4364-82a2-12acde7c4710",
   "metadata": {},
   "source": [
    "If the embeddings are created by default and inside the model initialization, like the example model shown below. In order to get the embedding layer (first layer) inside the model, we can first print the whole architecture of the model by `model.summary(expand_nested=True, show_trainable=True, line_length=80)`.\n",
    "\n",
    "Now we create a Wide and Deep Model as an example, since the embedding layer is created inside the initialization of the class `ml.WideAndDeepModel`, we have to print out the model and find the name of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfafca49-df84-4cd2-bb6c-99700ffa2598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "___________________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                    Param #     Trainable  \n",
      "===========================================================================================\n",
      " parallel_block_6 (ParallelBlock)   multiple                        285393428   Y          \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| sequential_block_25 (SequentialBlo  multiple                     3           Y          |\n",
      "| ck)                                                                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| parallel_block_5 (ParallelBlock)  multiple                     0           Y          ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| tabular_block_5 (TabularBlock)  multiple                     0           Y          |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| sequential_block_24 (SequentialBlo  multiple                   3           Y          ||\n",
      "|| ck)                                                                                   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| private__dense_11 (_Dense)   multiple                        3           Y          |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| sequential_block_23 (SequentialBlo  multiple                     285393425   Y          |\n",
      "| ck)                                                                                     |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| sequential_block_21 (SequentialBlo  multiple                   285393408   Y          ||\n",
      "|| ck)                                                                                   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| sequential_block_20 (SequentialBlo  multiple                 285390448   Y          |||\n",
      "||| ck)                                                                                 |||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||| as_ragged_features_8 (AsRaggedFeat  multiple               0           Y          ||||\n",
      "|||| ures)                                                                             ||||\n",
      "||||                                                                                   ||||\n",
      "|||| parallel_block_4 (ParallelBlock)  multiple                 285390448   Y          ||||\n",
      "|||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||||\n",
      "||||| embeddings (ParallelBlock)  multiple                     285390448   Y          |||||\n",
      "||||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||||\n",
      "|||||| user_categories (EmbeddingTable)  multiple             146088      Y          ||||||\n",
      "||||||                                                                               ||||||\n",
      "|||||| item_category (EmbeddingTable)  multiple               205968      Y          ||||||\n",
      "||||||                                                                               ||||||\n",
      "|||||| item_id (EmbeddingTable)  multiple                     270891016   Y          ||||||\n",
      "||||||                                                                               ||||||\n",
      "|||||| user_id (EmbeddingTable)  multiple                     14147376    Y          ||||||\n",
      "|||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| sequential_block_19 (SequentialBlo  multiple                 2960        Y          |||\n",
      "||| ck)                                                                                 |||\n",
      "||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||\n",
      "|||| private__dense_9 (_Dense)  multiple                        2960        Y          ||||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| sequential_block_22 (SequentialBlo  multiple                   17          Y          ||\n",
      "|| ck)                                                                                   ||\n",
      "|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||\n",
      "||| private__dense_10 (_Dense)   multiple                        17          Y          |||\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " click/binary_classification_task (  multiple                       2           Y          \n",
      " BinaryClassificationTask)                                                                 \n",
      "                                                                                           \n",
      " model_context_2 (ModelContext)     multiple                        0           Y          \n",
      "                                                                                           \n",
      "===========================================================================================\n",
      "Total params: 285,393,431\n",
      "Trainable params: 285,393,430\n",
      "Non-trainable params: 1\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "example_schema = train.schema.select_by_name(names=[\"user_categories\", \"item_category\", \"item_id\", \"user_id\", \"click\"])\n",
    "wide_schema = example_schema.select_by_name(names=[\"user_categories\", \"item_category\"])\n",
    "example_model = ml.WideAndDeepModel(\n",
    "        example_schema,\n",
    "        wide_schema=wide_schema,\n",
    "        deep_schema=example_schema,\n",
    "        deep_block=ml.MLPBlock([16]),\n",
    "        prediction_tasks=ml.BinaryClassificationTask(\"click\"),\n",
    "    )\n",
    "\n",
    "# Build the model before summary\n",
    "example_model.compile(optimizer=\"adam\")\n",
    "example_model.predict(train, batch_size=1024, steps=1)\n",
    "\n",
    "example_model.summary(expand_nested=True, show_trainable=True, line_length=80)   \n",
    "                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85825697-af5b-45a5-bb83-6f2b8620deb6",
   "metadata": {},
   "source": [
    "Above summary result shows the entire structure of the model, including name, style, number of parameters, and trainable argument of each layer, you can see some layers are nexted. For example, a `ParallelBlock` contains several sub-layers, they do not have order and data pass them in parallel. And a `SequentialBlcok` contain a sequence of blocks, data pass them one by one. A `ParallelBlock` block can also contain `ParallelBlcok` or `SequentialBlock`.\n",
    "\n",
    "```\n",
    "||||| embeddings (ParallelBlock)  multiple             285390448   Y           |||||\n",
    "||||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||||||\n",
    "|||||| user_categories (EmbeddingTable)  multiple      146088      Y          ||||||\n",
    "||||||                                                                        ||||||\n",
    "|||||| item_category (EmbeddingTable)  multiple        205968      Y          ||||||\n",
    "||||||                                                                        ||||||\n",
    "|||||| item_id (EmbeddingTable)  multiple              270891016   Y          ||||||\n",
    "||||||                                                                        ||||||\n",
    "|||||| user_id (EmbeddingTable)  multiple               14147376    Y         ||||||\n",
    "|||||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||||\n",
    "```\n",
    "\n",
    "We can find out that the `embeddings` contains all embedding tables, and it is a `ParallelBlock`. Now in order to get the this layer, we can call `model.get_blocks_by_name(\"embeddings\")` and set different optimizer for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389e9a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d190bf1-8ff6-44bd-a48e-fa472c74037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = example_model.get_blocks_by_name(\"embeddings\")\n",
    "optimizer = ml.MultiOptimizer(\n",
    "                default_optimizer=\"adam\",\n",
    "                optimizers_and_blocks=[ml.OptimizerBlocks(ml.LazyAdam(), embedding_layer)]\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('merlin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c78a7de67f1468ee33d22a76790123f2989400fa0e73ac6b45f15b09432f615d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
